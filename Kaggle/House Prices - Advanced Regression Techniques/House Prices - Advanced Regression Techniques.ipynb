{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('House Prices - Advanced Regression Techniques/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('House Prices - Advanced Regression Techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "2914  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "2915  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "2916  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "2917  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "2918  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "2914         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2915         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2916         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2917         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
       "2918         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal   208500.0  \n",
       "1         5   2007        WD         Normal   181500.0  \n",
       "2         9   2008        WD         Normal   223500.0  \n",
       "3         2   2006        WD        Abnorml   140000.0  \n",
       "4        12   2008        WD         Normal   250000.0  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "2914      6   2006        WD         Normal        NaN  \n",
       "2915      4   2006        WD        Abnorml        NaN  \n",
       "2916      9   2006        WD        Abnorml        NaN  \n",
       "2917      7   2006        WD         Normal        NaN  \n",
       "2918     11   2006        WD         Normal        NaN  \n",
       "\n",
       "[2919 rows x 81 columns]"
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2919 entries, 0 to 2918\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             2919 non-null   int64  \n",
      " 1   MSSubClass     2919 non-null   int64  \n",
      " 2   MSZoning       2915 non-null   object \n",
      " 3   LotFrontage    2433 non-null   float64\n",
      " 4   LotArea        2919 non-null   int64  \n",
      " 5   Street         2919 non-null   object \n",
      " 6   Alley          198 non-null    object \n",
      " 7   LotShape       2919 non-null   object \n",
      " 8   LandContour    2919 non-null   object \n",
      " 9   Utilities      2917 non-null   object \n",
      " 10  LotConfig      2919 non-null   object \n",
      " 11  LandSlope      2919 non-null   object \n",
      " 12  Neighborhood   2919 non-null   object \n",
      " 13  Condition1     2919 non-null   object \n",
      " 14  Condition2     2919 non-null   object \n",
      " 15  BldgType       2919 non-null   object \n",
      " 16  HouseStyle     2919 non-null   object \n",
      " 17  OverallQual    2919 non-null   int64  \n",
      " 18  OverallCond    2919 non-null   int64  \n",
      " 19  YearBuilt      2919 non-null   int64  \n",
      " 20  YearRemodAdd   2919 non-null   int64  \n",
      " 21  RoofStyle      2919 non-null   object \n",
      " 22  RoofMatl       2919 non-null   object \n",
      " 23  Exterior1st    2918 non-null   object \n",
      " 24  Exterior2nd    2918 non-null   object \n",
      " 25  MasVnrType     1153 non-null   object \n",
      " 26  MasVnrArea     2896 non-null   float64\n",
      " 27  ExterQual      2919 non-null   object \n",
      " 28  ExterCond      2919 non-null   object \n",
      " 29  Foundation     2919 non-null   object \n",
      " 30  BsmtQual       2838 non-null   object \n",
      " 31  BsmtCond       2837 non-null   object \n",
      " 32  BsmtExposure   2837 non-null   object \n",
      " 33  BsmtFinType1   2840 non-null   object \n",
      " 34  BsmtFinSF1     2918 non-null   float64\n",
      " 35  BsmtFinType2   2839 non-null   object \n",
      " 36  BsmtFinSF2     2918 non-null   float64\n",
      " 37  BsmtUnfSF      2918 non-null   float64\n",
      " 38  TotalBsmtSF    2918 non-null   float64\n",
      " 39  Heating        2919 non-null   object \n",
      " 40  HeatingQC      2919 non-null   object \n",
      " 41  CentralAir     2919 non-null   object \n",
      " 42  Electrical     2918 non-null   object \n",
      " 43  1stFlrSF       2919 non-null   int64  \n",
      " 44  2ndFlrSF       2919 non-null   int64  \n",
      " 45  LowQualFinSF   2919 non-null   int64  \n",
      " 46  GrLivArea      2919 non-null   int64  \n",
      " 47  BsmtFullBath   2917 non-null   float64\n",
      " 48  BsmtHalfBath   2917 non-null   float64\n",
      " 49  FullBath       2919 non-null   int64  \n",
      " 50  HalfBath       2919 non-null   int64  \n",
      " 51  BedroomAbvGr   2919 non-null   int64  \n",
      " 52  KitchenAbvGr   2919 non-null   int64  \n",
      " 53  KitchenQual    2918 non-null   object \n",
      " 54  TotRmsAbvGrd   2919 non-null   int64  \n",
      " 55  Functional     2917 non-null   object \n",
      " 56  Fireplaces     2919 non-null   int64  \n",
      " 57  FireplaceQu    1499 non-null   object \n",
      " 58  GarageType     2762 non-null   object \n",
      " 59  GarageYrBlt    2760 non-null   float64\n",
      " 60  GarageFinish   2760 non-null   object \n",
      " 61  GarageCars     2918 non-null   float64\n",
      " 62  GarageArea     2918 non-null   float64\n",
      " 63  GarageQual     2760 non-null   object \n",
      " 64  GarageCond     2760 non-null   object \n",
      " 65  PavedDrive     2919 non-null   object \n",
      " 66  WoodDeckSF     2919 non-null   int64  \n",
      " 67  OpenPorchSF    2919 non-null   int64  \n",
      " 68  EnclosedPorch  2919 non-null   int64  \n",
      " 69  3SsnPorch      2919 non-null   int64  \n",
      " 70  ScreenPorch    2919 non-null   int64  \n",
      " 71  PoolArea       2919 non-null   int64  \n",
      " 72  PoolQC         10 non-null     object \n",
      " 73  Fence          571 non-null    object \n",
      " 74  MiscFeature    105 non-null    object \n",
      " 75  MiscVal        2919 non-null   int64  \n",
      " 76  MoSold         2919 non-null   int64  \n",
      " 77  YrSold         2919 non-null   int64  \n",
      " 78  SaleType       2918 non-null   object \n",
      " 79  SaleCondition  2919 non-null   object \n",
      " 80  SalePrice      1460 non-null   float64\n",
      "dtypes: float64(12), int64(26), object(43)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
      "\n",
      "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
      "        30\t1-STORY 1945 & OLDER\n",
      "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
      "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
      "        50\t1-1/2 STORY FINISHED ALL AGES\n",
      "        60\t2-STORY 1946 & NEWER\n",
      "        70\t2-STORY 1945 & OLDER\n",
      "        75\t2-1/2 STORY ALL AGES\n",
      "        80\tSPLIT OR MULTI-LEVEL\n",
      "        85\tSPLIT FOYER\n",
      "        90\tDUPLEX - ALL STYLES AND AGES\n",
      "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
      "       150\t1-1/2 STORY PUD - ALL AGES\n",
      "       160\t2-STORY PUD - 1946 & NEWER\n",
      "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
      "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
      "\n",
      "MSZoning: Identifies the general zoning classification of the sale.\n",
      "\t\t\n",
      "       A\tAgriculture\n",
      "       C\tCommercial\n",
      "       FV\tFloating Village Residential\n",
      "       I\tIndustrial\n",
      "       RH\tResidential High Density\n",
      "       RL\tResidential Low Density\n",
      "       RP\tResidential Low Density Park \n",
      "       RM\tResidential Medium Density\n",
      "\t\n",
      "LotFrontage: Linear feet of street connected to property\n",
      "\n",
      "LotArea: Lot size in square feet\n",
      "\n",
      "Street: Type of road access to property\n",
      "\n",
      "       Grvl\tGravel\t\n",
      "       Pave\tPaved\n",
      "       \t\n",
      "Alley: Type of alley access to property\n",
      "\n",
      "       Grvl\tGravel\n",
      "       Pave\tPaved\n",
      "       NA \tNo alley access\n",
      "\t\t\n",
      "LotShape: General shape of property\n",
      "\n",
      "       Reg\tRegular\t\n",
      "       IR1\tSlightly irregular\n",
      "       IR2\tModerately Irregular\n",
      "       IR3\tIrregular\n",
      "       \n",
      "LandContour: Flatness of the property\n",
      "\n",
      "       Lvl\tNear Flat/Level\t\n",
      "       Bnk\tBanked - Quick and significant rise from street grade to building\n",
      "       HLS\tHillside - Significant slope from side to side\n",
      "       Low\tDepression\n",
      "\t\t\n",
      "Utilities: Type of utilities available\n",
      "\t\t\n",
      "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
      "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
      "       NoSeWa\tElectricity and Gas Only\n",
      "       ELO\tElectricity only\t\n",
      "\t\n",
      "LotConfig: Lot configuration\n",
      "\n",
      "       Inside\tInside lot\n",
      "       Corner\tCorner lot\n",
      "       CulDSac\tCul-de-sac\n",
      "       FR2\tFrontage on 2 sides of property\n",
      "       FR3\tFrontage on 3 sides of property\n",
      "\t\n",
      "LandSlope: Slope of property\n",
      "\t\t\n",
      "       Gtl\tGentle slope\n",
      "       Mod\tModerate Slope\t\n",
      "       Sev\tSevere Slope\n",
      "\t\n",
      "Neighborhood: Physical locations within Ames city limits\n",
      "\n",
      "       Blmngtn\tBloomington Heights\n",
      "       Blueste\tBluestem\n",
      "       BrDale\tBriardale\n",
      "       BrkSide\tBrookside\n",
      "       ClearCr\tClear Creek\n",
      "       CollgCr\tCollege Creek\n",
      "       Crawfor\tCrawford\n",
      "       Edwards\tEdwards\n",
      "       Gilbert\tGilbert\n",
      "       IDOTRR\tIowa DOT and Rail Road\n",
      "       MeadowV\tMeadow Village\n",
      "       Mitchel\tMitchell\n",
      "       Names\tNorth Ames\n",
      "       NoRidge\tNorthridge\n",
      "       NPkVill\tNorthpark Villa\n",
      "       NridgHt\tNorthridge Heights\n",
      "       NWAmes\tNorthwest Ames\n",
      "       OldTown\tOld Town\n",
      "       SWISU\tSouth & West of Iowa State University\n",
      "       Sawyer\tSawyer\n",
      "       SawyerW\tSawyer West\n",
      "       Somerst\tSomerset\n",
      "       StoneBr\tStone Brook\n",
      "       Timber\tTimberland\n",
      "       Veenker\tVeenker\n",
      "\t\t\t\n",
      "Condition1: Proximity to various conditions\n",
      "\t\n",
      "       Artery\tAdjacent to arterial street\n",
      "       Feedr\tAdjacent to feeder street\t\n",
      "       Norm\tNormal\t\n",
      "       RRNn\tWithin 200' of North-South Railroad\n",
      "       RRAn\tAdjacent to North-South Railroad\n",
      "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
      "       PosA\tAdjacent to postive off-site feature\n",
      "       RRNe\tWithin 200' of East-West Railroad\n",
      "       RRAe\tAdjacent to East-West Railroad\n",
      "\t\n",
      "Condition2: Proximity to various conditions (if more than one is present)\n",
      "\t\t\n",
      "       Artery\tAdjacent to arterial street\n",
      "       Feedr\tAdjacent to feeder street\t\n",
      "       Norm\tNormal\t\n",
      "       RRNn\tWithin 200' of North-South Railroad\n",
      "       RRAn\tAdjacent to North-South Railroad\n",
      "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
      "       PosA\tAdjacent to postive off-site feature\n",
      "       RRNe\tWithin 200' of East-West Railroad\n",
      "       RRAe\tAdjacent to East-West Railroad\n",
      "\t\n",
      "BldgType: Type of dwelling\n",
      "\t\t\n",
      "       1Fam\tSingle-family Detached\t\n",
      "       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
      "       Duplx\tDuplex\n",
      "       TwnhsE\tTownhouse End Unit\n",
      "       TwnhsI\tTownhouse Inside Unit\n",
      "\t\n",
      "HouseStyle: Style of dwelling\n",
      "\t\n",
      "       1Story\tOne story\n",
      "       1.5Fin\tOne and one-half story: 2nd level finished\n",
      "       1.5Unf\tOne and one-half story: 2nd level unfinished\n",
      "       2Story\tTwo story\n",
      "       2.5Fin\tTwo and one-half story: 2nd level finished\n",
      "       2.5Unf\tTwo and one-half story: 2nd level unfinished\n",
      "       SFoyer\tSplit Foyer\n",
      "       SLvl\tSplit Level\n",
      "\t\n",
      "OverallQual: Rates the overall material and finish of the house\n",
      "\n",
      "       10\tVery Excellent\n",
      "       9\tExcellent\n",
      "       8\tVery Good\n",
      "       7\tGood\n",
      "       6\tAbove Average\n",
      "       5\tAverage\n",
      "       4\tBelow Average\n",
      "       3\tFair\n",
      "       2\tPoor\n",
      "       1\tVery Poor\n",
      "\t\n",
      "OverallCond: Rates the overall condition of the house\n",
      "\n",
      "       10\tVery Excellent\n",
      "       9\tExcellent\n",
      "       8\tVery Good\n",
      "       7\tGood\n",
      "       6\tAbove Average\t\n",
      "       5\tAverage\n",
      "       4\tBelow Average\t\n",
      "       3\tFair\n",
      "       2\tPoor\n",
      "       1\tVery Poor\n",
      "\t\t\n",
      "YearBuilt: Original construction date\n",
      "\n",
      "YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n",
      "\n",
      "RoofStyle: Type of roof\n",
      "\n",
      "       Flat\tFlat\n",
      "       Gable\tGable\n",
      "       Gambrel\tGabrel (Barn)\n",
      "       Hip\tHip\n",
      "       Mansard\tMansard\n",
      "       Shed\tShed\n",
      "\t\t\n",
      "RoofMatl: Roof material\n",
      "\n",
      "       ClyTile\tClay or Tile\n",
      "       CompShg\tStandard (Composite) Shingle\n",
      "       Membran\tMembrane\n",
      "       Metal\tMetal\n",
      "       Roll\tRoll\n",
      "       Tar&Grv\tGravel & Tar\n",
      "       WdShake\tWood Shakes\n",
      "       WdShngl\tWood Shingles\n",
      "\t\t\n",
      "Exterior1st: Exterior covering on house\n",
      "\n",
      "       AsbShng\tAsbestos Shingles\n",
      "       AsphShn\tAsphalt Shingles\n",
      "       BrkComm\tBrick Common\n",
      "       BrkFace\tBrick Face\n",
      "       CBlock\tCinder Block\n",
      "       CemntBd\tCement Board\n",
      "       HdBoard\tHard Board\n",
      "       ImStucc\tImitation Stucco\n",
      "       MetalSd\tMetal Siding\n",
      "       Other\tOther\n",
      "       Plywood\tPlywood\n",
      "       PreCast\tPreCast\t\n",
      "       Stone\tStone\n",
      "       Stucco\tStucco\n",
      "       VinylSd\tVinyl Siding\n",
      "       Wd Sdng\tWood Siding\n",
      "       WdShing\tWood Shingles\n",
      "\t\n",
      "Exterior2nd: Exterior covering on house (if more than one material)\n",
      "\n",
      "       AsbShng\tAsbestos Shingles\n",
      "       AsphShn\tAsphalt Shingles\n",
      "       BrkComm\tBrick Common\n",
      "       BrkFace\tBrick Face\n",
      "       CBlock\tCinder Block\n",
      "       CemntBd\tCement Board\n",
      "       HdBoard\tHard Board\n",
      "       ImStucc\tImitation Stucco\n",
      "       MetalSd\tMetal Siding\n",
      "       Other\tOther\n",
      "       Plywood\tPlywood\n",
      "       PreCast\tPreCast\n",
      "       Stone\tStone\n",
      "       Stucco\tStucco\n",
      "       VinylSd\tVinyl Siding\n",
      "       Wd Sdng\tWood Siding\n",
      "       WdShing\tWood Shingles\n",
      "\t\n",
      "MasVnrType: Masonry veneer type\n",
      "\n",
      "       BrkCmn\tBrick Common\n",
      "       BrkFace\tBrick Face\n",
      "       CBlock\tCinder Block\n",
      "       None\tNone\n",
      "       Stone\tStone\n",
      "\t\n",
      "MasVnrArea: Masonry veneer area in square feet\n",
      "\n",
      "ExterQual: Evaluates the quality of the material on the exterior \n",
      "\t\t\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tAverage/Typical\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "\t\t\n",
      "ExterCond: Evaluates the present condition of the material on the exterior\n",
      "\t\t\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tAverage/Typical\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "\t\t\n",
      "Foundation: Type of foundation\n",
      "\t\t\n",
      "       BrkTil\tBrick & Tile\n",
      "       CBlock\tCinder Block\n",
      "       PConc\tPoured Contrete\t\n",
      "       Slab\tSlab\n",
      "       Stone\tStone\n",
      "       Wood\tWood\n",
      "\t\t\n",
      "BsmtQual: Evaluates the height of the basement\n",
      "\n",
      "       Ex\tExcellent (100+ inches)\t\n",
      "       Gd\tGood (90-99 inches)\n",
      "       TA\tTypical (80-89 inches)\n",
      "       Fa\tFair (70-79 inches)\n",
      "       Po\tPoor (<70 inches\n",
      "       NA\tNo Basement\n",
      "\t\t\n",
      "BsmtCond: Evaluates the general condition of the basement\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tTypical - slight dampness allowed\n",
      "       Fa\tFair - dampness or some cracking or settling\n",
      "       Po\tPoor - Severe cracking, settling, or wetness\n",
      "       NA\tNo Basement\n",
      "\t\n",
      "BsmtExposure: Refers to walkout or garden level walls\n",
      "\n",
      "       Gd\tGood Exposure\n",
      "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
      "       Mn\tMimimum Exposure\n",
      "       No\tNo Exposure\n",
      "       NA\tNo Basement\n",
      "\t\n",
      "BsmtFinType1: Rating of basement finished area\n",
      "\n",
      "       GLQ\tGood Living Quarters\n",
      "       ALQ\tAverage Living Quarters\n",
      "       BLQ\tBelow Average Living Quarters\t\n",
      "       Rec\tAverage Rec Room\n",
      "       LwQ\tLow Quality\n",
      "       Unf\tUnfinshed\n",
      "       NA\tNo Basement\n",
      "\t\t\n",
      "BsmtFinSF1: Type 1 finished square feet\n",
      "\n",
      "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
      "\n",
      "       GLQ\tGood Living Quarters\n",
      "       ALQ\tAverage Living Quarters\n",
      "       BLQ\tBelow Average Living Quarters\t\n",
      "       Rec\tAverage Rec Room\n",
      "       LwQ\tLow Quality\n",
      "       Unf\tUnfinshed\n",
      "       NA\tNo Basement\n",
      "\n",
      "BsmtFinSF2: Type 2 finished square feet\n",
      "\n",
      "BsmtUnfSF: Unfinished square feet of basement area\n",
      "\n",
      "TotalBsmtSF: Total square feet of basement area\n",
      "\n",
      "Heating: Type of heating\n",
      "\t\t\n",
      "       Floor\tFloor Furnace\n",
      "       GasA\tGas forced warm air furnace\n",
      "       GasW\tGas hot water or steam heat\n",
      "       Grav\tGravity furnace\t\n",
      "       OthW\tHot water or steam heat other than gas\n",
      "       Wall\tWall furnace\n",
      "\t\t\n",
      "HeatingQC: Heating quality and condition\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tAverage/Typical\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "\t\t\n",
      "CentralAir: Central air conditioning\n",
      "\n",
      "       N\tNo\n",
      "       Y\tYes\n",
      "\t\t\n",
      "Electrical: Electrical system\n",
      "\n",
      "       SBrkr\tStandard Circuit Breakers & Romex\n",
      "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
      "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
      "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
      "       Mix\tMixed\n",
      "\t\t\n",
      "1stFlrSF: First Floor square feet\n",
      " \n",
      "2ndFlrSF: Second floor square feet\n",
      "\n",
      "LowQualFinSF: Low quality finished square feet (all floors)\n",
      "\n",
      "GrLivArea: Above grade (ground) living area square feet\n",
      "\n",
      "BsmtFullBath: Basement full bathrooms\n",
      "\n",
      "BsmtHalfBath: Basement half bathrooms\n",
      "\n",
      "FullBath: Full bathrooms above grade\n",
      "\n",
      "HalfBath: Half baths above grade\n",
      "\n",
      "Bedroom: Bedrooms above grade (does NOT include basement bedrooms)\n",
      "\n",
      "Kitchen: Kitchens above grade\n",
      "\n",
      "KitchenQual: Kitchen quality\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tTypical/Average\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "       \t\n",
      "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
      "\n",
      "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
      "\n",
      "       Typ\tTypical Functionality\n",
      "       Min1\tMinor Deductions 1\n",
      "       Min2\tMinor Deductions 2\n",
      "       Mod\tModerate Deductions\n",
      "       Maj1\tMajor Deductions 1\n",
      "       Maj2\tMajor Deductions 2\n",
      "       Sev\tSeverely Damaged\n",
      "       Sal\tSalvage only\n",
      "\t\t\n",
      "Fireplaces: Number of fireplaces\n",
      "\n",
      "FireplaceQu: Fireplace quality\n",
      "\n",
      "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
      "       Gd\tGood - Masonry Fireplace in main level\n",
      "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
      "       Fa\tFair - Prefabricated Fireplace in basement\n",
      "       Po\tPoor - Ben Franklin Stove\n",
      "       NA\tNo Fireplace\n",
      "\t\t\n",
      "GarageType: Garage location\n",
      "\t\t\n",
      "       2Types\tMore than one type of garage\n",
      "       Attchd\tAttached to home\n",
      "       Basment\tBasement Garage\n",
      "       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n",
      "       CarPort\tCar Port\n",
      "       Detchd\tDetached from home\n",
      "       NA\tNo Garage\n",
      "\t\t\n",
      "GarageYrBlt: Year garage was built\n",
      "\t\t\n",
      "GarageFinish: Interior finish of the garage\n",
      "\n",
      "       Fin\tFinished\n",
      "       RFn\tRough Finished\t\n",
      "       Unf\tUnfinished\n",
      "       NA\tNo Garage\n",
      "\t\t\n",
      "GarageCars: Size of garage in car capacity\n",
      "\n",
      "GarageArea: Size of garage in square feet\n",
      "\n",
      "GarageQual: Garage quality\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tTypical/Average\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "       NA\tNo Garage\n",
      "\t\t\n",
      "GarageCond: Garage condition\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tTypical/Average\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "       NA\tNo Garage\n",
      "\t\t\n",
      "PavedDrive: Paved driveway\n",
      "\n",
      "       Y\tPaved \n",
      "       P\tPartial Pavement\n",
      "       N\tDirt/Gravel\n",
      "\t\t\n",
      "WoodDeckSF: Wood deck area in square feet\n",
      "\n",
      "OpenPorchSF: Open porch area in square feet\n",
      "\n",
      "EnclosedPorch: Enclosed porch area in square feet\n",
      "\n",
      "3SsnPorch: Three season porch area in square feet\n",
      "\n",
      "ScreenPorch: Screen porch area in square feet\n",
      "\n",
      "PoolArea: Pool area in square feet\n",
      "\n",
      "PoolQC: Pool quality\n",
      "\t\t\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tAverage/Typical\n",
      "       Fa\tFair\n",
      "       NA\tNo Pool\n",
      "\t\t\n",
      "Fence: Fence quality\n",
      "\t\t\n",
      "       GdPrv\tGood Privacy\n",
      "       MnPrv\tMinimum Privacy\n",
      "       GdWo\tGood Wood\n",
      "       MnWw\tMinimum Wood/Wire\n",
      "       NA\tNo Fence\n",
      "\t\n",
      "MiscFeature: Miscellaneous feature not covered in other categories\n",
      "\t\t\n",
      "       Elev\tElevator\n",
      "       Gar2\t2nd Garage (if not described in garage section)\n",
      "       Othr\tOther\n",
      "       Shed\tShed (over 100 SF)\n",
      "       TenC\tTennis Court\n",
      "       NA\tNone\n",
      "\t\t\n",
      "MiscVal: $Value of miscellaneous feature\n",
      "\n",
      "MoSold: Month Sold (MM)\n",
      "\n",
      "YrSold: Year Sold (YYYY)\n",
      "\n",
      "SaleType: Type of sale\n",
      "\t\t\n",
      "       WD \tWarranty Deed - Conventional\n",
      "       CWD\tWarranty Deed - Cash\n",
      "       VWD\tWarranty Deed - VA Loan\n",
      "       New\tHome just constructed and sold\n",
      "       COD\tCourt Officer Deed/Estate\n",
      "       Con\tContract 15% Down payment regular terms\n",
      "       ConLw\tContract Low Down payment and low interest\n",
      "       ConLI\tContract Low Interest\n",
      "       ConLD\tContract Low Down\n",
      "       Oth\tOther\n",
      "\t\t\n",
      "SaleCondition: Condition of sale\n",
      "\n",
      "       Normal\tNormal Sale\n",
      "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
      "       AdjLand\tAdjoining Land Purchase\n",
      "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
      "       Family\tSale between family members\n",
      "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('House Prices - Advanced Regression Techniques/data_description.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_missing(df):\n",
    "    percent_nan = df.isnull().sum() * 100 / len(df)\n",
    "    return percent_nan[percent_nan > 0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior2nd      0.034258\n",
       "Exterior1st      0.034258\n",
       "BsmtUnfSF        0.034258\n",
       "BsmtFinSF2       0.034258\n",
       "BsmtFinSF1       0.034258\n",
       "KitchenQual      0.034258\n",
       "Electrical       0.034258\n",
       "TotalBsmtSF      0.034258\n",
       "GarageArea       0.034258\n",
       "GarageCars       0.034258\n",
       "SaleType         0.034258\n",
       "Functional       0.068517\n",
       "BsmtFullBath     0.068517\n",
       "Utilities        0.068517\n",
       "BsmtHalfBath     0.068517\n",
       "MSZoning         0.137033\n",
       "MasVnrArea       0.787941\n",
       "BsmtFinType1     2.706406\n",
       "BsmtFinType2     2.740665\n",
       "BsmtQual         2.774923\n",
       "BsmtCond         2.809181\n",
       "BsmtExposure     2.809181\n",
       "GarageType       5.378554\n",
       "GarageFinish     5.447071\n",
       "GarageCond       5.447071\n",
       "GarageYrBlt      5.447071\n",
       "GarageQual       5.447071\n",
       "LotFrontage     16.649538\n",
       "FireplaceQu     48.646797\n",
       "SalePrice       49.982871\n",
       "MasVnrType      60.500171\n",
       "Fence           80.438506\n",
       "Alley           93.216855\n",
       "MiscFeature     96.402878\n",
       "PoolQC          99.657417\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=percent_nan, y=percent_nan.index)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior2nd     0.034258\n",
       "Exterior1st     0.034258\n",
       "BsmtUnfSF       0.034258\n",
       "BsmtFinSF2      0.034258\n",
       "BsmtFinSF1      0.034258\n",
       "KitchenQual     0.034258\n",
       "Electrical      0.034258\n",
       "TotalBsmtSF     0.034258\n",
       "GarageArea      0.034258\n",
       "GarageCars      0.034258\n",
       "SaleType        0.034258\n",
       "Functional      0.068517\n",
       "BsmtFullBath    0.068517\n",
       "Utilities       0.068517\n",
       "BsmtHalfBath    0.068517\n",
       "MSZoning        0.137033\n",
       "MasVnrArea      0.787941\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan[percent_nan < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Exterior1st'].isnull()].index == df[df['Exterior2nd'].isnull()].index\n",
    "\n",
    "#only one row contains single missing value of Exterior1st column and Exterior2nd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior2nd\n",
       "VinylSd    1014\n",
       "MetalSd     447\n",
       "HdBoard     406\n",
       "Wd Sdng     391\n",
       "Plywood     270\n",
       "CmentBd     126\n",
       "Wd Shng      81\n",
       "BrkFace      47\n",
       "Stucco       47\n",
       "AsbShng      38\n",
       "Brk Cmn      22\n",
       "ImStucc      15\n",
       "Stone         6\n",
       "AsphShn       4\n",
       "CBlock        3\n",
       "Other         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exterior2nd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior1st\n",
       "VinylSd    1025\n",
       "MetalSd     450\n",
       "HdBoard     442\n",
       "Wd Sdng     411\n",
       "Plywood     221\n",
       "CemntBd     126\n",
       "BrkFace      87\n",
       "WdShing      56\n",
       "AsbShng      44\n",
       "Stucco       43\n",
       "BrkComm       6\n",
       "AsphShn       2\n",
       "Stone         2\n",
       "CBlock        2\n",
       "ImStucc       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exterior1st'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([2120], dtype='int64') Index([2120], dtype='int64') Index([2120], dtype='int64') Index([2120], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df[df['BsmtFinSF1'].isnull()].index, df[df['BsmtFinSF2'].isnull()].index,\n",
    "df[df['BsmtUnfSF'].isnull()].index, df[df['TotalBsmtSF'].isnull()].index)\n",
    "\n",
    "#only one row contains single missing value of BsmtFinSF1 column, BsmtFinSF2 column,BsmtUnfSF column\n",
    "#and TotalBsmtSF column\n",
    "#that is row 2120\n",
    "#that means that there is no basement in this house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 1177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['BsmtFullBath'].isnull()].index == df[df['BsmtHalfBath'].isnull()].index\n",
    "\n",
    "#same rows with missing values of BsmtFullBath column and BsmtHalfBath column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FullBath in the houses BsmtFullBath\n",
      "0.0    1705\n",
      "1.0    1172\n",
      "2.0      38\n",
      "3.0       2\n",
      "Name: count, dtype: int64\n",
      "Number of HalfBath in the houses BsmtHalfBath\n",
      "0.0    2742\n",
      "1.0     171\n",
      "2.0       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of FullBath in the houses', df['BsmtFullBath'].value_counts())\n",
    "print('Number of HalfBath in the houses', df['BsmtHalfBath'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>1556</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10632</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "1555  1556          50       RL         72.0    10632   Pave   NaN      IR1   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "1555         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "1555      1   2010       COD         Normal        NaN  \n",
       "\n",
       "[1 rows x 81 columns]"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['KitchenQual'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenQual\n",
       "TA    1492\n",
       "Gd    1151\n",
       "Ex     205\n",
       "Fa      70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KitchenQual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>1380</td>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9735</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "1379  1380          80       RL         73.0     9735   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "1379         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "1379      5   2008        WD         Normal   167500.0  \n",
       "\n",
       "[1 rows x 81 columns]"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Electrical'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electrical\n",
       "SBrkr    2671\n",
       "FuseA     188\n",
       "FuseF      50\n",
       "FuseP       8\n",
       "Mix         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Electrical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([2576], dtype='int64'), Index([2576], dtype='int64'))"
      ]
     },
     "execution_count": 1183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['GarageArea'].isnull()].index, df[df['GarageCars'].isnull()].index\n",
    "#No garage area means no garage cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SaleType\n",
       "WD       2525\n",
       "New       239\n",
       "COD        87\n",
       "ConLD      26\n",
       "CWD        12\n",
       "ConLI       9\n",
       "ConLw       8\n",
       "Oth         7\n",
       "Con         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SaleType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>2217</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>14584</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2474</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10320</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "2216  2217          20      NaN         80.0    14584   Pave   NaN      Reg   \n",
       "2473  2474          50       RM         60.0    10320   Pave  Grvl      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "2216         Low    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "2473         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "2216      2   2008        WD        Abnorml        NaN  \n",
       "2473      9   2007       COD        Abnorml        NaN  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 1185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Functional'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Functional\n",
       "Typ     2717\n",
       "Min2      70\n",
       "Min1      65\n",
       "Mod       35\n",
       "Maj1      19\n",
       "Maj2       9\n",
       "Sev        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Functional'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915    GasA\n",
       "1945    GasA\n",
       "Name: Heating, dtype: object"
      ]
     },
     "execution_count": 1187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Utilities'].isnull()]['Heating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utilities\n",
       "AllPub    2916\n",
       "NoSeWa       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>1916</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>21780</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>2217</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>14584</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2251</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>2905</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>31250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "1915  1916          30      NaN        109.0    21780   Grvl   NaN      Reg   \n",
       "2216  2217          20      NaN         80.0    14584   Pave   NaN      Reg   \n",
       "2250  2251          70      NaN          NaN    56600   Pave   NaN      IR1   \n",
       "2904  2905          20      NaN        125.0    31250   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "1915         Lvl       NaN  ...        0    NaN   NaN         NaN       0   \n",
       "2216         Low    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "2250         Low    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "2904         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "1915      3   2009     ConLD         Normal        NaN  \n",
       "2216      2   2008        WD        Abnorml        NaN  \n",
       "2250      1   2008        WD         Normal        NaN  \n",
       "2904      5   2006        WD         Normal        NaN  \n",
       "\n",
       "[4 rows x 81 columns]"
      ]
     },
     "execution_count": 1189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['MSZoning'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning\n",
       "RL         2265\n",
       "RM          460\n",
       "FV          139\n",
       "RH           26\n",
       "C (all)      25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrArea\n",
       "0.0      1738\n",
       "120.0      15\n",
       "200.0      13\n",
       "176.0      13\n",
       "216.0      12\n",
       "         ... \n",
       "355.0       1\n",
       "405.0       1\n",
       "327.0       1\n",
       "257.0       1\n",
       "382.0       1\n",
       "Name: count, Length: 444, dtype: int64"
      ]
     },
     "execution_count": 1191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MasVnrArea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrType\n",
       "BrkFace    879\n",
       "Stone      249\n",
       "BrkCmn      25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MasVnrType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1766)"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 corresponds to MasVnrType nan\n",
      "529 corresponds to MasVnrType nan\n",
      "650 corresponds to MasVnrType nan\n",
      "936 corresponds to MasVnrType nan\n",
      "973 corresponds to MasVnrType nan\n",
      "977 corresponds to MasVnrType nan\n",
      "1243 corresponds to MasVnrType nan\n",
      "1278 corresponds to MasVnrType nan\n",
      "1691 corresponds to MasVnrType nan\n",
      "1706 corresponds to MasVnrType nan\n",
      "1882 corresponds to MasVnrType nan\n",
      "1992 corresponds to MasVnrType nan\n",
      "2004 corresponds to MasVnrType nan\n",
      "2041 corresponds to MasVnrType nan\n",
      "2311 corresponds to MasVnrType nan\n",
      "2325 corresponds to MasVnrType nan\n",
      "2340 corresponds to MasVnrType nan\n",
      "2349 corresponds to MasVnrType nan\n",
      "2368 corresponds to MasVnrType nan\n",
      "2592 corresponds to MasVnrType nan\n",
      "2657 corresponds to MasVnrType nan\n",
      "2686 corresponds to MasVnrType nan\n",
      "2862 corresponds to MasVnrType nan\n"
     ]
    }
   ],
   "source": [
    "for n in df[df['MasVnrArea'].isnull()].index:\n",
    "\n",
    "    if n not in df[df['MasVnrType'].isnull()].index:\n",
    "        print('oh')\n",
    "        break\n",
    "    print(f'{n} corresponds to MasVnrType {df.loc[n, \"MasVnrType\"]}')\n",
    "\n",
    "#MasVnrType nan corresponds to MasVnrType 'None'\n",
    "#every row from MasVnrArea[234, 529, ..., 2862] with missing value maps to MasVnrArea ('None') value or nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrType\n",
       "BrkFace    2\n",
       "Stone      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['MasVnrArea'] == 0]['MasVnrType'].value_counts()\n",
    "#there are 1766 rows with MasVnrArea = 0\n",
    "#there is mistake in the dataset, because with MasVnrArea = 0 there is 2 BrkFace and 1 Stone\n",
    "#the values must have been 'None'(nan)\n",
    "\n",
    "#or maybe on the areas, approximately 0 square feet of masonry veneer (2 brick faces and 1 of stone,) \n",
    "# was installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'TotalBsmtSF': 0, 'BsmtFullBath':0, 'BsmtHalfBath': 0, 'BsmtFinSF1': 0, 'BsmtFinSF2': 0,\n",
    "            'Functional': 'Typ', 'Exterior1st': 'VinylSd',\n",
    "            'Exterior2nd': 'MetalSd', 'BsmtUnfSF': 0, 'KitchenQual': 'TA', 'Electrical': 'SBrkr', \n",
    "            'GarageArea': 0, 'GarageCars': 0, 'SaleType': 'WD', 'Utilities': 'AllPub',\n",
    "            'MSZoning': 'RL', 'MasVnrArea': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan[percent_nan < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=percent_nan, y=percent_nan.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinType1    2.706406\n",
       "BsmtFinType2    2.740665\n",
       "BsmtQual        2.774923\n",
       "BsmtExposure    2.809181\n",
       "BsmtCond        2.809181\n",
       "GarageType      5.378554\n",
       "GarageYrBlt     5.447071\n",
       "GarageFinish    5.447071\n",
       "GarageCond      5.447071\n",
       "GarageQual      5.447071\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan[percent_nan<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(157)"
      ]
     },
     "execution_count": 1201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GarageType'].isnull().sum()\n",
    "#there are 157 houses without garage, as NA is corresponding to no garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].mean())\n",
    "\n",
    "#as we use linear regression, we can use mean\n",
    "#0 would be maleficent for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_cols = ['BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtExposure']\n",
    "df[bsmt_cols] = df[bsmt_cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_str_cols = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "\n",
    "df[garage_str_cols] = df[garage_str_cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    16.649538\n",
       "FireplaceQu    48.646797\n",
       "SalePrice      49.982871\n",
       "MasVnrType     60.500171\n",
       "Fence          80.438506\n",
       "Alley          93.216855\n",
       "MiscFeature    96.402878\n",
       "PoolQC         99.657417\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=percent_nan, y=percent_nan.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'] = df['MasVnrType'].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Fence', 'Alley', 'MiscFeature', 'PoolQC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu'] = df['FireplaceQu'].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    16.649538\n",
       "SalePrice      49.982871\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=percent_nan, y=percent_nan.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "Blmngtn    46.900000\n",
       "Blueste    27.300000\n",
       "BrDale     21.500000\n",
       "BrkSide    55.789474\n",
       "ClearCr    88.150000\n",
       "CollgCr    71.336364\n",
       "Crawfor    69.951807\n",
       "Edwards    66.910112\n",
       "Gilbert    74.207207\n",
       "IDOTRR     62.241379\n",
       "MeadowV    25.606061\n",
       "Mitchel    75.144444\n",
       "NAmes      75.210667\n",
       "NPkVill    28.142857\n",
       "NWAmes     81.517647\n",
       "NoRidge    91.629630\n",
       "NridgHt    84.184049\n",
       "OldTown    61.777293\n",
       "SWISU      59.068182\n",
       "Sawyer     74.551020\n",
       "SawyerW    70.669811\n",
       "Somerst    64.549383\n",
       "StoneBr    62.173913\n",
       "Timber     81.157895\n",
       "Veenker    72.000000\n",
       "Name: LotFrontage, dtype: float64"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Neighborhood')['LotFrontage'].mean(numeric_only=True)\n",
    "# Calculate the mean LotFrontage for each Neighborhood\n",
    "# We will use these means to fill in the missing values in LotFrontage\n",
    "\n",
    "#the code below fills in the missing values in LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda lots: lots.fillna(lots.mean()))\n",
    "# Fill missing values with the mean LotFrontage of the neighborhood\n",
    "# The transform method returns a Series with the same index as the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice    49.982871\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping dictionaries for ordinal categorical variables with order inherent in the categories \n",
    "# (e.g. Ex > Gd > TA > Fa > Po)\n",
    "bsmt_dict = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "exterior_dict = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond'] = df['BsmtCond'].map(bsmt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtQual'] = df['BsmtQual'].map(bsmt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ExterQual'] = df['ExterQual'].map(exterior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ExterCond'] = df['ExterCond'].map(exterior_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_variable? - X['BsmtExposure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSSubClass'] = df['MSSubClass'].astype(str)\n",
    "# Convert MSSubClass to string to treat it as a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass\n",
      "20     1079\n",
      "60      575\n",
      "50      287\n",
      "120     182\n",
      "30      139\n",
      "70      128\n",
      "160     128\n",
      "80      118\n",
      "90      109\n",
      "190      61\n",
      "85       48\n",
      "75       23\n",
      "45       18\n",
      "180      17\n",
      "40        6\n",
      "150       1\n",
      "Name: count, dtype: int64\n",
      "MSZoning\n",
      "RL         2269\n",
      "RM          460\n",
      "FV          139\n",
      "RH           26\n",
      "C (all)      25\n",
      "Name: count, dtype: int64\n",
      "Street\n",
      "Pave    2907\n",
      "Grvl      12\n",
      "Name: count, dtype: int64\n",
      "LotShape\n",
      "Reg    1859\n",
      "IR1     968\n",
      "IR2      76\n",
      "IR3      16\n",
      "Name: count, dtype: int64\n",
      "LandContour\n",
      "Lvl    2622\n",
      "HLS     120\n",
      "Bnk     117\n",
      "Low      60\n",
      "Name: count, dtype: int64\n",
      "Utilities\n",
      "AllPub    2918\n",
      "NoSeWa       1\n",
      "Name: count, dtype: int64\n",
      "LotConfig\n",
      "Inside     2133\n",
      "Corner      511\n",
      "CulDSac     176\n",
      "FR2          85\n",
      "FR3          14\n",
      "Name: count, dtype: int64\n",
      "LandSlope\n",
      "Gtl    2778\n",
      "Mod     125\n",
      "Sev      16\n",
      "Name: count, dtype: int64\n",
      "Neighborhood\n",
      "NAmes      443\n",
      "CollgCr    267\n",
      "OldTown    239\n",
      "Edwards    194\n",
      "Somerst    182\n",
      "NridgHt    166\n",
      "Gilbert    165\n",
      "Sawyer     151\n",
      "NWAmes     131\n",
      "SawyerW    125\n",
      "Mitchel    114\n",
      "BrkSide    108\n",
      "Crawfor    103\n",
      "IDOTRR      93\n",
      "Timber      72\n",
      "NoRidge     71\n",
      "StoneBr     51\n",
      "SWISU       48\n",
      "ClearCr     44\n",
      "MeadowV     37\n",
      "BrDale      30\n",
      "Blmngtn     28\n",
      "Veenker     24\n",
      "NPkVill     23\n",
      "Blueste     10\n",
      "Name: count, dtype: int64\n",
      "Condition1\n",
      "Norm      2511\n",
      "Feedr      164\n",
      "Artery      92\n",
      "RRAn        50\n",
      "PosN        39\n",
      "RRAe        28\n",
      "PosA        20\n",
      "RRNn         9\n",
      "RRNe         6\n",
      "Name: count, dtype: int64\n",
      "Condition2\n",
      "Norm      2889\n",
      "Feedr       13\n",
      "Artery       5\n",
      "PosN         4\n",
      "PosA         4\n",
      "RRNn         2\n",
      "RRAn         1\n",
      "RRAe         1\n",
      "Name: count, dtype: int64\n",
      "BldgType\n",
      "1Fam      2425\n",
      "TwnhsE     227\n",
      "Duplex     109\n",
      "Twnhs       96\n",
      "2fmCon      62\n",
      "Name: count, dtype: int64\n",
      "HouseStyle\n",
      "1Story    1471\n",
      "2Story     872\n",
      "1.5Fin     314\n",
      "SLvl       128\n",
      "SFoyer      83\n",
      "2.5Unf      24\n",
      "1.5Unf      19\n",
      "2.5Fin       8\n",
      "Name: count, dtype: int64\n",
      "RoofStyle\n",
      "Gable      2310\n",
      "Hip         551\n",
      "Gambrel      22\n",
      "Flat         20\n",
      "Mansard      11\n",
      "Shed          5\n",
      "Name: count, dtype: int64\n",
      "RoofMatl\n",
      "CompShg    2876\n",
      "Tar&Grv      23\n",
      "WdShake       9\n",
      "WdShngl       7\n",
      "Metal         1\n",
      "Membran       1\n",
      "Roll          1\n",
      "ClyTile       1\n",
      "Name: count, dtype: int64\n",
      "Exterior1st\n",
      "VinylSd    1026\n",
      "MetalSd     450\n",
      "HdBoard     442\n",
      "Wd Sdng     411\n",
      "Plywood     221\n",
      "CemntBd     126\n",
      "BrkFace      87\n",
      "WdShing      56\n",
      "AsbShng      44\n",
      "Stucco       43\n",
      "BrkComm       6\n",
      "AsphShn       2\n",
      "Stone         2\n",
      "CBlock        2\n",
      "ImStucc       1\n",
      "Name: count, dtype: int64\n",
      "Exterior2nd\n",
      "VinylSd    1014\n",
      "MetalSd     448\n",
      "HdBoard     406\n",
      "Wd Sdng     391\n",
      "Plywood     270\n",
      "CmentBd     126\n",
      "Wd Shng      81\n",
      "BrkFace      47\n",
      "Stucco       47\n",
      "AsbShng      38\n",
      "Brk Cmn      22\n",
      "ImStucc      15\n",
      "Stone         6\n",
      "AsphShn       4\n",
      "CBlock        3\n",
      "Other         1\n",
      "Name: count, dtype: int64\n",
      "MasVnrType\n",
      "none       1766\n",
      "BrkFace     879\n",
      "Stone       249\n",
      "BrkCmn       25\n",
      "Name: count, dtype: int64\n",
      "Foundation\n",
      "PConc     1308\n",
      "CBlock    1235\n",
      "BrkTil     311\n",
      "Slab        49\n",
      "Stone       11\n",
      "Wood         5\n",
      "Name: count, dtype: int64\n",
      "BsmtExposure\n",
      "No    1904\n",
      "Av     418\n",
      "Gd     276\n",
      "Mn     239\n",
      "NA      82\n",
      "Name: count, dtype: int64\n",
      "BsmtFinType1\n",
      "Unf    851\n",
      "GLQ    849\n",
      "ALQ    429\n",
      "Rec    288\n",
      "BLQ    269\n",
      "LwQ    154\n",
      "NA      79\n",
      "Name: count, dtype: int64\n",
      "BsmtFinType2\n",
      "Unf    2493\n",
      "Rec     105\n",
      "LwQ      87\n",
      "NA       80\n",
      "BLQ      68\n",
      "ALQ      52\n",
      "GLQ      34\n",
      "Name: count, dtype: int64\n",
      "Heating\n",
      "GasA     2874\n",
      "GasW       27\n",
      "Grav        9\n",
      "Wall        6\n",
      "OthW        2\n",
      "Floor       1\n",
      "Name: count, dtype: int64\n",
      "HeatingQC\n",
      "Ex    1493\n",
      "TA     857\n",
      "Gd     474\n",
      "Fa      92\n",
      "Po       3\n",
      "Name: count, dtype: int64\n",
      "CentralAir\n",
      "Y    2723\n",
      "N     196\n",
      "Name: count, dtype: int64\n",
      "Electrical\n",
      "SBrkr    2672\n",
      "FuseA     188\n",
      "FuseF      50\n",
      "FuseP       8\n",
      "Mix         1\n",
      "Name: count, dtype: int64\n",
      "KitchenQual\n",
      "TA    1493\n",
      "Gd    1151\n",
      "Ex     205\n",
      "Fa      70\n",
      "Name: count, dtype: int64\n",
      "Functional\n",
      "Typ     2719\n",
      "Min2      70\n",
      "Min1      65\n",
      "Mod       35\n",
      "Maj1      19\n",
      "Maj2       9\n",
      "Sev        2\n",
      "Name: count, dtype: int64\n",
      "FireplaceQu\n",
      "none    1420\n",
      "Gd       744\n",
      "TA       592\n",
      "Fa        74\n",
      "Po        46\n",
      "Ex        43\n",
      "Name: count, dtype: int64\n",
      "GarageType\n",
      "Attchd     1723\n",
      "Detchd      779\n",
      "BuiltIn     186\n",
      "NA          157\n",
      "Basment      36\n",
      "2Types       23\n",
      "CarPort      15\n",
      "Name: count, dtype: int64\n",
      "GarageFinish\n",
      "Unf    1230\n",
      "RFn     811\n",
      "Fin     719\n",
      "NA      159\n",
      "Name: count, dtype: int64\n",
      "GarageQual\n",
      "TA    2604\n",
      "NA     159\n",
      "Fa     124\n",
      "Gd      24\n",
      "Po       5\n",
      "Ex       3\n",
      "Name: count, dtype: int64\n",
      "GarageCond\n",
      "TA    2654\n",
      "NA     159\n",
      "Fa      74\n",
      "Gd      15\n",
      "Po      14\n",
      "Ex       3\n",
      "Name: count, dtype: int64\n",
      "PavedDrive\n",
      "Y    2641\n",
      "N     216\n",
      "P      62\n",
      "Name: count, dtype: int64\n",
      "SaleType\n",
      "WD       2526\n",
      "New       239\n",
      "COD        87\n",
      "ConLD      26\n",
      "CWD        12\n",
      "ConLI       9\n",
      "ConLw       8\n",
      "Oth         7\n",
      "Con         5\n",
      "Name: count, dtype: int64\n",
      "SaleCondition\n",
      "Normal     2402\n",
      "Partial     245\n",
      "Abnorml     190\n",
      "Family       46\n",
      "Alloca       24\n",
      "AdjLand      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Utilities', axis=1, inplace=True)\n",
    "# Drop Utilities due to lack of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Street', axis=1, inplace=True)\n",
    "# Drop Street due to lack of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVING OUTLIERS FROM DF_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenAbvGr    -0.135907\n",
       "EnclosedPorch   -0.128578\n",
       "OverallCond     -0.077856\n",
       "YrSold          -0.028923\n",
       "LowQualFinSF    -0.025606\n",
       "MiscVal         -0.021190\n",
       "BsmtHalfBath    -0.016844\n",
       "BsmtFinSF2      -0.011378\n",
       "ExterCond        0.018899\n",
       "3SsnPorch        0.044584\n",
       "MoSold           0.046432\n",
       "PoolArea         0.092404\n",
       "ScreenPorch      0.111447\n",
       "BedroomAbvGr     0.168213\n",
       "BsmtCond         0.212607\n",
       "BsmtUnfSF        0.214479\n",
       "BsmtFullBath     0.227122\n",
       "LotArea          0.263843\n",
       "HalfBath         0.284108\n",
       "OpenPorchSF      0.315856\n",
       "2ndFlrSF         0.319334\n",
       "WoodDeckSF       0.324413\n",
       "LotFrontage      0.348056\n",
       "BsmtFinSF1       0.386420\n",
       "Fireplaces       0.466929\n",
       "GarageYrBlt      0.471062\n",
       "MasVnrArea       0.472614\n",
       "YearRemodAdd     0.507101\n",
       "YearBuilt        0.522897\n",
       "TotRmsAbvGrd     0.533723\n",
       "FullBath         0.560664\n",
       "BsmtQual         0.585207\n",
       "1stFlrSF         0.605852\n",
       "TotalBsmtSF      0.613581\n",
       "GarageArea       0.623431\n",
       "GarageCars       0.640409\n",
       "ExterQual        0.682639\n",
       "GrLivArea        0.708624\n",
       "OverallQual      0.790982\n",
       "SalePrice        1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(numeric_only=True)['SalePrice'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscVal          21.958480\n",
       "PoolArea         16.907017\n",
       "LotArea          12.829025\n",
       "LowQualFinSF     12.094977\n",
       "3SsnPorch        11.381914\n",
       "KitchenAbvGr      4.304467\n",
       "BsmtFinSF2        4.148275\n",
       "EnclosedPorch     4.005950\n",
       "ScreenPorch       3.948723\n",
       "BsmtHalfBath      3.933616\n",
       "MasVnrArea        2.614936\n",
       "OpenPorchSF       2.536417\n",
       "SalePrice         1.882876\n",
       "WoodDeckSF        1.843380\n",
       "1stFlrSF          1.470360\n",
       "LotFrontage       1.461180\n",
       "BsmtFinSF1        1.425963\n",
       "ExterCond         1.316590\n",
       "GrLivArea         1.270010\n",
       "TotalBsmtSF       1.157489\n",
       "BsmtUnfSF         0.919812\n",
       "2ndFlrSF          0.862118\n",
       "ExterQual         0.786786\n",
       "TotRmsAbvGrd      0.758757\n",
       "Fireplaces        0.733872\n",
       "HalfBath          0.694924\n",
       "BsmtFullBath      0.625153\n",
       "OverallCond       0.570605\n",
       "BedroomAbvGr      0.326492\n",
       "GarageArea        0.239380\n",
       "OverallQual       0.197212\n",
       "MoSold            0.195985\n",
       "FullBath          0.167692\n",
       "YrSold            0.132467\n",
       "GarageCars       -0.219694\n",
       "GarageYrBlt      -0.392992\n",
       "YearRemodAdd     -0.451252\n",
       "YearBuilt        -0.600114\n",
       "BsmtQual         -1.269195\n",
       "BsmtCond         -3.605964\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = df.skew(numeric_only=True).sort_values(ascending=False)\n",
    "skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolArea\n",
       "0      2906\n",
       "512       1\n",
       "648       1\n",
       "576       1\n",
       "555       1\n",
       "480       1\n",
       "519       1\n",
       "738       1\n",
       "144       1\n",
       "368       1\n",
       "444       1\n",
       "228       1\n",
       "561       1\n",
       "800       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num['PoolArea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('PoolArea', axis=1)\n",
    "#Drop PoolArea due to lack of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscVal          21.958480\n",
       "LotArea          12.829025\n",
       "LowQualFinSF     12.094977\n",
       "3SsnPorch        11.381914\n",
       "KitchenAbvGr      4.304467\n",
       "BsmtFinSF2        4.148275\n",
       "EnclosedPorch     4.005950\n",
       "ScreenPorch       3.948723\n",
       "BsmtHalfBath      3.933616\n",
       "MasVnrArea        2.614936\n",
       "OpenPorchSF       2.536417\n",
       "SalePrice         1.882876\n",
       "WoodDeckSF        1.843380\n",
       "1stFlrSF          1.470360\n",
       "LotFrontage       1.461180\n",
       "BsmtFinSF1        1.425963\n",
       "ExterCond         1.316590\n",
       "GrLivArea         1.270010\n",
       "TotalBsmtSF       1.157489\n",
       "BsmtUnfSF         0.919812\n",
       "2ndFlrSF          0.862118\n",
       "ExterQual         0.786786\n",
       "TotRmsAbvGrd      0.758757\n",
       "Fireplaces        0.733872\n",
       "HalfBath          0.694924\n",
       "BsmtFullBath      0.625153\n",
       "OverallCond       0.570605\n",
       "BedroomAbvGr      0.326492\n",
       "GarageArea        0.239380\n",
       "OverallQual       0.197212\n",
       "MoSold            0.195985\n",
       "FullBath          0.167692\n",
       "YrSold            0.132467\n",
       "GarageCars       -0.219694\n",
       "GarageYrBlt      -0.392992\n",
       "YearRemodAdd     -0.451252\n",
       "YearBuilt        -0.600114\n",
       "BsmtQual         -1.269195\n",
       "BsmtCond         -3.605964\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew(numeric_only=True).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='LotArea', ylabel='Count'>"
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['LotArea'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotArea'] = np.log1p(df['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='LotArea', ylabel='Count'>"
      ]
     },
     "execution_count": 1247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['LotArea'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='MiscVal', ylabel='Count'>"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['MiscVal'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscVal\n",
       "0        2816\n",
       "400        18\n",
       "500        13\n",
       "450         9\n",
       "600         8\n",
       "700         7\n",
       "2000        7\n",
       "1500        3\n",
       "650         3\n",
       "1200        3\n",
       "4500        2\n",
       "480         2\n",
       "2500        2\n",
       "3000        2\n",
       "350         1\n",
       "54          1\n",
       "560         1\n",
       "620         1\n",
       "1300        1\n",
       "800         1\n",
       "3500        1\n",
       "15500       1\n",
       "12500       1\n",
       "1150        1\n",
       "8300        1\n",
       "1400        1\n",
       "490         1\n",
       "900         1\n",
       "80          1\n",
       "300         1\n",
       "6500        1\n",
       "750         1\n",
       "1000        1\n",
       "17000       1\n",
       "1512        1\n",
       "455         1\n",
       "460         1\n",
       "420         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MiscVal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop MiscVal due to lack of variance\n",
    "df = df.drop('MiscVal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='LowQualFinSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['LowQualFinSF'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LowQualFinSF\n",
       "0       2879\n",
       "80         4\n",
       "205        2\n",
       "360        2\n",
       "234        1\n",
       "513        1\n",
       "144        1\n",
       "528        1\n",
       "371        1\n",
       "390        1\n",
       "420        1\n",
       "572        1\n",
       "473        1\n",
       "156        1\n",
       "515        1\n",
       "53         1\n",
       "232        1\n",
       "481        1\n",
       "120        1\n",
       "392        1\n",
       "514        1\n",
       "397        1\n",
       "479        1\n",
       "384        1\n",
       "362        1\n",
       "1064       1\n",
       "431        1\n",
       "436        1\n",
       "259        1\n",
       "312        1\n",
       "108        1\n",
       "697        1\n",
       "512        1\n",
       "114        1\n",
       "140        1\n",
       "450        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LowQualFinSF'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('LowQualFinSF', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='3SsnPorch', ylabel='Count'>"
      ]
     },
     "execution_count": 1254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['3SsnPorch'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3SsnPorch\n",
       "0      2882\n",
       "168       3\n",
       "153       3\n",
       "144       2\n",
       "180       2\n",
       "216       2\n",
       "407       1\n",
       "140       1\n",
       "508       1\n",
       "245       1\n",
       "238       1\n",
       "196       1\n",
       "182       1\n",
       "130       1\n",
       "320       1\n",
       "23        1\n",
       "162       1\n",
       "96        1\n",
       "290       1\n",
       "304       1\n",
       "224       1\n",
       "255       1\n",
       "225       1\n",
       "360       1\n",
       "150       1\n",
       "174       1\n",
       "120       1\n",
       "219       1\n",
       "176       1\n",
       "86        1\n",
       "323       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['3SsnPorch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 3SsnPorch due to lack of variance\n",
    "df = df.drop('3SsnPorch', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='KitchenAbvGr', ylabel='Count'>"
      ]
     },
     "execution_count": 1257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['KitchenAbvGr'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenAbvGr\n",
       "1    2785\n",
       "2     129\n",
       "0       3\n",
       "3       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KitchenAbvGr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='KitchenAbvGr', ylabel='SalePrice'>"
      ]
     },
     "execution_count": 1259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df['KitchenAbvGr'], y=df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop KitchenAbvGr due to lack of variance\n",
    "#The relationship between KitchenAbvGr and SalePrice is weak\n",
    "df = df.drop('KitchenAbvGr', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinSF2       4.148275\n",
       "EnclosedPorch    4.005950\n",
       "ScreenPorch      3.948723\n",
       "BsmtHalfBath     3.933616\n",
       "MasVnrArea       2.614936\n",
       "OpenPorchSF      2.536417\n",
       "SalePrice        1.882876\n",
       "WoodDeckSF       1.843380\n",
       "1stFlrSF         1.470360\n",
       "LotFrontage      1.461180\n",
       "BsmtFinSF1       1.425963\n",
       "ExterCond        1.316590\n",
       "GrLivArea        1.270010\n",
       "TotalBsmtSF      1.157489\n",
       "BsmtUnfSF        0.919812\n",
       "2ndFlrSF         0.862118\n",
       "ExterQual        0.786786\n",
       "TotRmsAbvGrd     0.758757\n",
       "Fireplaces       0.733872\n",
       "HalfBath         0.694924\n",
       "BsmtFullBath     0.625153\n",
       "OverallCond      0.570605\n",
       "BedroomAbvGr     0.326492\n",
       "GarageArea       0.239380\n",
       "OverallQual      0.197212\n",
       "MoSold           0.195985\n",
       "FullBath         0.167692\n",
       "YrSold           0.132467\n",
       "GarageCars      -0.219694\n",
       "GarageYrBlt     -0.392992\n",
       "YearRemodAdd    -0.451252\n",
       "LotArea         -0.505010\n",
       "YearBuilt       -0.600114\n",
       "BsmtQual        -1.269195\n",
       "BsmtCond        -3.605964\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = df.skew(numeric_only=True).sort_values(ascending=False)\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='BsmtFinSF2', ylabel='Count'>"
      ]
     },
     "execution_count": 1262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['BsmtFinSF2'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinSF2\n",
       "0.0       2572\n",
       "180.0        5\n",
       "294.0        5\n",
       "435.0        3\n",
       "144.0        3\n",
       "          ... \n",
       "869.0        1\n",
       "150.0        1\n",
       "215.0        1\n",
       "28.0         1\n",
       "1080.0       1\n",
       "Name: count, Length: 272, dtype: int64"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtFinSF2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop BsmtFinSF2 due to lack of variance\n",
    "#most of the values are 0\n",
    "df = df.drop('BsmtFinSF2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  272,  228,  205,  176,   87,  172,  102,   37,  144,   64,\n",
       "        114,  202,  128,  156,   44,   77,  192,  140,  180,  183,   39,\n",
       "        184,   40,  552,   30,  126,   96,   60,  150,  120,  112,  252,\n",
       "         52,  224,  234,  244,  268,  137,   24,  108,  294,  177,  218,\n",
       "        242,   91,  160,  130,  169,  105,   34,  248,  236,   32,   80,\n",
       "        115,  291,  116,  158,  210,   36,  200,   84,  148,  136,  240,\n",
       "         54,  100,  189,  293,  164,  216,  239,   67,   90,   56,  129,\n",
       "         98,  143,   70,  386,  154,  185,  134,  196,  264,  275,  230,\n",
       "        254,   68,  194,  318,   48,   94,  138,  226,  174,   19,  170,\n",
       "        220,  214,  280,  190,  330,  208,  145,  259,   81,   42,  123,\n",
       "        162,  286,  168,   20,  301,  198,  221,  212,   50,   99,  186,\n",
       "        113,  135,  334,  246,   18,   41,   35,  364,   45,   86,  265,\n",
       "        222,  209,  260,  203,  432,   25,  238,   51,  213,  288,  211,\n",
       "         55,   57,   78,   72,  368,  165,   92,   16,   66,  109,  139,\n",
       "        219,  101,  117,  204,  122,  231,  121,  207,  249,  290,  175,\n",
       "         26,   88, 1012,   43,  584,  133,  324,  161,   75,  167,   28,\n",
       "        104,  296,  256,  225,  429,  132,   23])"
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EnclosedPorch'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('EnclosedPorch', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScreenPorch\n",
       "0      2663\n",
       "144      13\n",
       "192      11\n",
       "168      10\n",
       "120       9\n",
       "       ... \n",
       "270       1\n",
       "162       1\n",
       "348       1\n",
       "113       1\n",
       "104       1\n",
       "Name: count, Length: 121, dtype: int64"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ScreenPorch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('ScreenPorch', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtHalfBath\n",
       "0.0    2744\n",
       "1.0     171\n",
       "2.0       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtHalfBath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BsmtHalfBath = pd.get_dummies(df['BsmtHalfBath'], prefix='BsmtHalfBath', drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_BsmtHalfBath], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrArea\n",
       "0.0      1761\n",
       "120.0      15\n",
       "200.0      13\n",
       "176.0      13\n",
       "216.0      12\n",
       "         ... \n",
       "355.0       1\n",
       "405.0       1\n",
       "327.0       1\n",
       "257.0       1\n",
       "382.0       1\n",
       "Name: count, Length: 444, dtype: int64"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MasVnrArea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrArea'] = np.log1p(df['MasVnrArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='MasVnrArea', ylabel='Count'>"
      ]
     },
     "execution_count": 1274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['MasVnrArea'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='OpenPorchSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPAhJREFUeJzt3Ql4VOX59/F7JpN9JUAIYRcRENkERdxahbJZC4rWBRUVwQWqaEWlKiLaYpGiIghqFbTi+n+FIkVkdQHDLqBIAQUhBUKAELKvc97rfnDGTMSIkmSW8/1cPZ055zyZeU4SMz+e7Tgsy7IEAADAxpz+rgAAAIC/EYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtufxdgWDgdrtl//79Eh8fLw6Hw9/VAQAAJ0GXWszLy5O0tDRxOqtvAyIQnQQNQ82aNfN3NQAAwK+QkZEhTZs2rbYMgegkaMuQ5xuakJDg7+oAAICTkJubaxo0PJ/j1SEQnQRPN5mGIQIRAADB5WSGuzCoGgAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2B6BCAAA2J7L3xWAyMzOL0r+gbxqy8Q1jpc7Nt9eZ3UCAMBOCEQBQMPQFdNurLbM3FH/qrP6AABgN3SZAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2/NrIPr000/l8ssvl7S0NHE4HDJv3jzvubKyMnnwwQelY8eOEhsba8rcdNNNsn//fp/XyM7OliFDhkhCQoIkJSXJsGHDJD8/36fMli1b5KKLLpKoqChp1qyZTJo0qc6uEQAABD6/BqKCggLp3LmzTJ8+/UfnCgsLZePGjfLoo4+ax/fff1+2b98uf/jDH3zKaRjaunWrLFmyRBYsWGBC1ogRI7znc3NzpU+fPtKiRQvZsGGDPP300zJ+/Hh56aWX6uQaAQBA4HP588379+9vthNJTEw0IaeyadOmybnnnit79+6V5s2by7Zt22TRokWybt066d69uynz/PPPy4ABA2Ty5MmmVWnOnDlSWloqr776qkREREiHDh1k06ZNMmXKFJ/gBAAA7CuoxhAdO3bMdK1p15hKT083zz1hSPXu3VucTqesWbPGW+biiy82Ycijb9++prXp6NGjJ3yfkpIS07JUeQMAAKEraAJRcXGxGVN03XXXmfFCKjMzU1JSUnzKuVwuSU5ONuc8ZRo1auRTxrPvKVPVxIkTTQuVZ9NxRwAAIHQFRSDSAdZ//OMfxbIsmTFjRq2/39ixY01rlGfLyMio9fcEAAA2HUP0S8LQnj17ZPny5d7WIZWamipZWVk+5cvLy83MMz3nKXPw4EGfMp59T5mqIiMjzQYAAOzBGQxhaOfOnbJ06VKpX7++z/mePXtKTk6OmT3moaHJ7XZLjx49vGV05pm+locO1m7btq3Uq1evDq8GAAAEKr8GIl0vSGd86aZ2795tnussMg0wV111laxfv97MFKuoqDBjfnTTWWOqffv20q9fPxk+fLisXbtWVq1aJaNGjZJrr73WzDBT119/vRlQresT6fT8d955R5577jm57777/HnpAAAggPi1y0zDziWXXOLd94SUoUOHmrWC5s+fb/a7dOni83UrVqyQ3/72t+a5hiUNQb169TKzywYPHixTp071ltVB0YsXL5aRI0dKt27dpEGDBjJu3Dim3AMAgMAIRBpqdKD0T6nunIfOKHvzzTerLdOpUyf57LPPflUdAQBA6AvoMUQAAAB1gUAEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsz6+B6NNPP5XLL79c0tLSxOFwyLx583zOW5Yl48aNk8aNG0t0dLT07t1bdu7c6VMmOztbhgwZIgkJCZKUlCTDhg2T/Px8nzJbtmyRiy66SKKioqRZs2YyadKkOrk+AAAQHPwaiAoKCqRz584yffr0E57X4DJ16lSZOXOmrFmzRmJjY6Vv375SXFzsLaNhaOvWrbJkyRJZsGCBCVkjRozwns/NzZU+ffpIixYtZMOGDfL000/L+PHj5aWXXqqTawQAAIHP5c8379+/v9lORFuHnn32WXnkkUdk4MCB5tjrr78ujRo1Mi1J1157rWzbtk0WLVok69atk+7du5syzz//vAwYMEAmT55sWp7mzJkjpaWl8uqrr0pERIR06NBBNm3aJFOmTPEJTpWVlJSYrXKoAgAAoStgxxDt3r1bMjMzTTeZR2JiovTo0UPS09PNvj5qN5knDCkt73Q6TYuSp8zFF19swpCHtjJt375djh49esL3njhxonkvz6bdbAAAIHQFbCDSMKS0Ragy3fec08eUlBSf8y6XS5KTk33KnOg1Kr9HVWPHjpVjx455t4yMjBq8MgAAEGj82mUWqCIjI80GAADsIWBbiFJTU83jwYMHfY7rvuecPmZlZfmcLy8vNzPPKpc50WtUfg8AAGBvARuIWrVqZQLLsmXLfAY369ignj17mn19zMnJMbPHPJYvXy5ut9uMNfKU0ZlnZWVl3jI6I61t27ZSr169Or0mAAAQmPwaiHS9IJ3xpZtnILU+37t3r1mXaPTo0fLkk0/K/Pnz5csvv5SbbrrJzBwbNGiQKd++fXvp16+fDB8+XNauXSurVq2SUaNGmRloWk5df/31ZkC1rk+k0/Pfeecdee655+S+++7z56UDAIAA4tcxROvXr5dLLrnEu+8JKUOHDpXZs2fLAw88YNYq0unx2hJ04YUXmmn2usCih06r1xDUq1cvM7ts8ODBZu0iD50ltnjxYhk5cqR069ZNGjRoYBZ7/Kkp9wAAwH4cli74g2ppV50GK51xpiti17TJKZPlimk3Vltm7qh/yf1Z99f4ewMAEKp+yed3wI4hAgAAqCsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsBHYgqKirk0UcflVatWkl0dLS0bt1annjiCbEsy1tGn48bN04aN25syvTu3Vt27tzp8zrZ2dkyZMgQSUhIkKSkJBk2bJjk5+f74YoAAEAgCuhA9Pe//11mzJgh06ZNk23btpn9SZMmyfPPP+8to/tTp06VmTNnypo1ayQ2Nlb69u0rxcXF3jIahrZu3SpLliyRBQsWyKeffiojRozw01UBAIBA45IA9vnnn8vAgQPlsssuM/stW7aUt956S9auXettHXr22WflkUceMeXU66+/Lo0aNZJ58+bJtddea4LUokWLZN26ddK9e3dTRgPVgAEDZPLkyZKWlubHKwQAAIEgoFuIzj//fFm2bJns2LHD7G/evFlWrlwp/fv3N/u7d++WzMxM003mkZiYKD169JD09HSzr4/aTeYJQ0rLO51O06J0IiUlJZKbm+uzAQCA0BXQLUQPPfSQCSPt2rWTsLAwM6bor3/9q+kCUxqGlLYIVab7nnP6mJKS4nPe5XJJcnKyt0xVEydOlMcff7yWrgoAAASagG4hevfdd2XOnDny5ptvysaNG+W1114z3Vz6WJvGjh0rx44d824ZGRm1+n4AAMC/ArqFaMyYMaaVSMcCqY4dO8qePXtMC87QoUMlNTXVHD948KCZZeah+126dDHPtUxWVpbP65aXl5uZZ56vryoyMtJsAADAHgK6haiwsNCM9alMu87cbrd5rtPxNdToOCMP7WLTsUE9e/Y0+/qYk5MjGzZs8JZZvny5eQ0dawQAABDQLUSXX365GTPUvHlz6dChg3zxxRcyZcoUufXWW815h8Mho0ePlieffFLatGljApKuW6QzxwYNGmTKtG/fXvr16yfDhw83U/PLyspk1KhRptWJGWYAACDgA5FOj9eAc9ddd5luLw0wt99+u1mI0eOBBx6QgoICs66QtgRdeOGFZpp9VFSUt4yOQ9IQ1KtXL9PiNHjwYLN2EQAAgHJYlZd9xglpN5xO59cB1rradU2bnDJZrph2Y7Vl5o76l9yfdX+NvzcAAKHql3x+B/QYIgAAgLpAIAIAALZHIAIAALZHIAIAALZHIAIAALb3qwLRaaedJkeOHPnRcZ32rucAAABCPhB999135karJ7pL/L59+2qiXgAAAIG5MOP8+fO9zz/66CMzt99DA5LeQqNly5Y1W0MAAIBACkSe22HoLTP05qqVhYeHmzD0j3/8o2ZrCAAAEEiBqPJNVdetWycNGjSorXoBAAAE9r3Mdu/eXfM1AQAACLabu+p4Id30pqueliOPV199tSbqBgAAELiB6PHHH5cJEyZI9+7dpXHjxmZMEQAAgK0C0cyZM2X27Nly443V36EdAAAgZNchKi0tlfPPP7/mawMAABAsgei2226TN998s+ZrAwAAECxdZsXFxfLSSy/J0qVLpVOnTmYNosqmTJlSU/UDAAAIzEC0ZcsW6dKli3n+1Vdf+ZxjgDUAALBFIFqxYkXN1wQAACCYxhABAACI3VuILrnkkmq7xpYvX34qdQIAAAj8QOQZP+RRVlYmmzZtMuOJqt70FQAAICQD0TPPPHPC4+PHj5f8/PxTrRMAAEDwjiG64YYbuI8ZAACwdyBKT0+XqKiomnxJAACAwOwyu/LKK332LcuSAwcOyPr16+XRRx+tqboBAAAEbiBKTEz02Xc6ndK2bVuZMGGC9OnTp6bqBgAAELiBaNasWTVfEwAAgGAKRB4bNmyQbdu2mecdOnSQrl271lS9AAAAAjsQZWVlybXXXisff/yxJCUlmWM5OTlmwca3335bGjZsWNP1BAAACKxZZn/6058kLy9Ptm7dKtnZ2WbTRRlzc3Pl7rvvrvlaAgAABFoL0aJFi2Tp0qXSvn1777EzzzxTpk+fzqBqAABgjxYit9st4eHhPzqux/QcAABAyAeiSy+9VO655x7Zv3+/99i+ffvk3nvvlV69etVk/QAAAAIzEE2bNs2MF2rZsqW0bt3abK1atTLHnn/++ZqvJQAAQKCNIWrWrJls3LjRjCP673//a47peKLevXvXdP0AAAACq4Vo+fLlZvC0tgQ5HA753e9+Z2ac6XbOOeeYtYg+++yz2qstAACAvwPRs88+K8OHD5eEhIQT3s7j9ttvlylTptRk/QAAAAIrEG3evFn69ev3k+d1yr2uXg0AABCygejgwYMnnG7v4XK55NChQzVRLwAAgMAMRE2aNDErUv+ULVu2SOPGjWuiXgAAAIEZiAYMGCCPPvqoFBcX/+hcUVGRPPbYY/L73/++JusHAAAQWNPuH3nkEXn//ffljDPOkFGjRknbtm3NcZ16r7ftqKiokIcffri26goAAOD/FqJGjRrJ559/LmeddZaMHTtWrrjiCrP95S9/McdWrlxpytQkXQH7hhtukPr160t0dLR07NhR1q9f7z1vWZaMGzfOdNXpeV0LaefOnT6voTefHTJkiJkdl5SUJMOGDZP8/PwarScAALDRwowtWrSQhQsXytGjR+Wbb74xgaRNmzZSr169Gq+cvscFF1wgl1xyiXz44YfSsGFDE3Yqv9ekSZNk6tSp8tprr5nVsrVLr2/fvvL1119LVFSUKaNh6MCBA7JkyRIpKyuTW265RUaMGCFvvvlmjdcZAADYZKVqpaFEF2OsTX//+9/NqtizZs3yHtPQ46FhTNdG0q68gQMHmmOvv/66aaWaN2+eXHvttbJt2zZZtGiRrFu3Trp3727K6O1FdDzU5MmTJS0trVavAQAAhOi9zOrK/PnzTYi5+uqrJSUlRbp27Sovv/yy9/zu3bslMzPT55YhukBkjx49JD093ezro3aTecKQ0vJOp1PWrFlzwvctKSkxq3FX3gAAQOgK6EC0a9cumTFjhumS++ijj+TOO++Uu+++23SPKQ1Dquq4Jd33nNNHDVNV10tKTk72lqlq4sSJJlh5Nm2lqi0HVuZIRFR0rb0+AAAI8kDkdrvl7LPPlr/97W+mdUjH/eitQ2bOnFmr76sDxo8dO+bdMjIyauV9ig6VytYX9knbcy+Sw5vypaLEXSvvAwAAgjgQ6cwxvZlsZe3bt5e9e/ea56mpqd4VtCvTfc85fczKyvI5X15ebmaeecpUFRkZaWakVd5qg1VhSXKHWNN9l/tNkfxvcbaUFxOKAACoawEdiHSG2fbt232O7dixw8x08wyw1lCzbNky73kd76Njg3r27Gn29TEnJ8fnHmvLly83rU861sifYlIj5eyHW8q3m9eJK8YpFSWWFO4v8WudAACwo4AORPfee6+sXr3adJnpFH+dJv/SSy/JyJEjzXmHwyGjR4+WJ5980gzA/vLLL+Wmm24yM8cGDRrkbVHSG9JqV9vatWtl1apVZlFJnYEWKDPM8o8ekbjmx5cIKD5S5u/qAABgO7962n1d0Gn9c+fONWN6JkyYYFqEdJq9rivk8cADD0hBQYEZX6QtQRdeeKGZZu9Zg0jNmTPHhKBevXqZ7qnBgwebtYsCSVSD4zfNLT5MIAIAoK4FdCBSem+06u6Ppq1EGpZ0+yk6oyzQF2GMqn/8R1Fe4DbjiFxRAd14BwBASOFTN0A4w50SkRhmnpfQbQYAQJ0iEAWQyPp0mwEA4A8EogDCOCIAAPyDQBRAor5vISrJKRd3ueXv6gAAYBsEogCiaxGF6WBqS6TkKK1EAADUFQJRANEZc95usyPl/q4OAAC2QSAKMJFJx6ffl+USiAAAqCsEogDjijs+9b4sv8LfVQEAwDYIRAEmIv77QJRXIZbFwGoAAOoCgShAW4jcZZa4SwlEAADUBQJRgHGGOcxsM08rEQAAqH0EogAUzjgiAADqFIEoAIV7xxEx0wwAgLpAIApAtBABAFC3CEQBiEAEAEDdIhAFoPD47xdnzGfqPQAAdYFAFIDMLDOHiFUhUlHk9nd1AAAIeQSiAORwOn7oNmPqPQAAtY5AFKAYRwQAQN0hEAV4ICqlhQgAgFpHIAr0tYhoIQIAoNYRiAK8hai8gEAEAEBtIxAFKFfs9y1EBUy9BwCgthGIApQr+vjUe3Ez9R4AgNpGIArgqffeu97TbQYAQK0iEAWw8O+7zcoLaCECAKA2EYgCmMuzFhEtRAAA1CoCUVC0EBGIAACoTQSiIJlpBgAAag+BKICFxx7/8TCGCACA2kUgCoIWoopitzic/KgAAKgtfMoGsLAIpzjDdTEikYioGH9XBwCAkEUgCpJWosjoaH9XBQCAkEUgCpJxRLQQAQBQewhEQdJCFEELEQAAtYZAFCR3vaeFCACA2kMgCnCMIQIAoPYRiIJktWptIbIsy9/VAQAgJBGIApy5471DxBkWJiVHy/1dHQAAQhKBKMA5nI7joUhECjNL/V0dAABCEoEoiAZWFx4o8XdVAAAISQSiIBAe7zKPRQdoIQIAoDYQiIKohaiAFiIAAGpFUAWip556ShwOh4wePdp7rLi4WEaOHCn169eXuLg4GTx4sBw8eNDn6/bu3SuXXXaZxMTESEpKiowZM0bKy4NngLK3y4wxRAAA2DsQrVu3Tl588UXp1KmTz/F7771XPvjgA3nvvffkk08+kf3798uVV17pPV9RUWHCUGlpqXz++efy2muvyezZs2XcuHESbIGoKLNULDdT7wEAsGUgys/PlyFDhsjLL78s9erV8x4/duyYvPLKKzJlyhS59NJLpVu3bjJr1iwTfFavXm3KLF68WL7++mt54403pEuXLtK/f3954oknZPr06SYknUhJSYnk5ub6bP6ks8zcbre4yywpzi7za10AAAhFQRGItEtMW3l69+7tc3zDhg1SVlbmc7xdu3bSvHlzSU9PN/v62LFjR2nUqJG3TN++fU3I2bp16wnfb+LEiZKYmOjdmjVrJv6eel9aXGieFzKwGgAA+wWit99+WzZu3GhCSlWZmZkSEREhSUlJPsc1/Og5T5nKYchz3nPuRMaOHWtanzxbRkaG+FtJIYEIAIDacnw+d4DSIHLPPffIkiVLJCoqqs7eNzIy0myBpLTIE4iYaQYAgK1aiLRLLCsrS84++2xxuVxm04HTU6dONc+1pUfHAeXk5Ph8nc4yS01NNc/1seqsM8++p0wwKCkqMI+0EAEAYLNA1KtXL/nyyy9l06ZN3q179+5mgLXneXh4uCxbtsz7Ndu3bzfT7Hv27Gn29VFfQ4OVh7Y4JSQkyJlnninBosTTQpRJCxEAALbqMouPj5ezzjrL51hsbKxZc8hzfNiwYXLfffdJcnKyCTl/+tOfTAg677zzzPk+ffqY4HPjjTfKpEmTzLihRx55xAzUDrRuseqUFB5vISo6WCbuCkucYQ5/VwkAgJAR0IHoZDzzzDPidDrNgow6XV5nkL3wwgve82FhYbJgwQK58847TVDSQDV06FCZMGGCBJOykmJxhjuOT70/XCYxjSL8XSUAAEJG0AWijz/+2GdfB1vrmkK6/ZQWLVrIwoULJdhFp0ZIQUaJGVhNIAIAwCZjiOArrsnxLr78vcX+rgoAACGFQBRE4lseX3og7zsCEQAANYlAFETiWkabRwIRAAA1i0AUhC1EBftKpKLU7e/qAAAQMghEQSSynkvCE8JELMYRAQBQkwhEQcThcDCOCACAWkAgCjLxjCMCAKDGEYiCjLeFaA+BCACAmkIgCtJAlP9dsVhuy9/VAQAgJBCIgkxM40hzC4+KErcUHuTO9wAA1AQCUZDRm7rGNf+hlQgAAJw6AlEQd5vl7i7yd1UAAAgJBKIglHhGjHnM/qrA31UBACAkEIiCUP3OceYx99siKc0t93d1AAAIegSiIBSVHC5xLaLMitVHtuT7uzoAAAQ9AlGQatDleCvRkS/y/F0VAACCHoEoSNXvGm8eD2/OZz0iAABOketUXwD+kXRGjIRFO6Ust0JydxdLYutomdn5Rck/UH2LUVzjeLlj8+11Vk8AAIIBgShIOV0Oqd8xTrLW5ppuMw1EGoaumHZjtV83d9S/6qyOAAAEC7rMglj978cRHdqQJ5ZFtxkAAL8WgSiINeweb27jodPvj25lTSIAAH4tAlEQi0wKlya96pnn376X5e/qAAAQtAhEQa7loIamlShnW6HEJSX7uzoAAAQlAlEILNLoaSVKbdWGsUQAAPwKBKIQaiWKTawnRzblE4oAAPiFCEQh0krUfkSaCUK53xbLkc0FhCIAAH4BAlGISPtNPcnY/pV5nvtNkez/OEdKcrjxKwAAJ4NAFEKOZu6ThufEiyNMpORIuexbelQOf5EnFaVuf1cNAICARiAKMfEtoqRZ32SJbRpp9rULLeOjbMnfW+zvqgEAELC4dUcIcsWESaPzEqToYKkc3pQvZXkVkrU2T0pzK/xdNQAAAhItRCEsulGENP1dPUlqG232c/5bKM3bdxJ3BQOuAQCojEAU4hxOhyR3jJMG3eJEHCL1GqXJjtcO+LtaAAAEFAKRTSS0ipaUHgnmecaibMn46Ii/qwQAQMAgENlIXNNIObBrh3m+fdYByd6a7+8qAQAQEAhENpO1d5c0vjhJLLfI1un7pLyQgdYAABCIbKjdbY0lOiVcig+XyfbXM/1dHQAA/I5p9zZTnFMszzZ/xtz3rHWXc2X/8qOy8rmlknfkkLdMXON4uWPz7X6tJwAAdYlAZDOW25Irpt1onh/ZnC/HdhZJm3PPMYs5Ol0Oc3zuqH/5uZYAANQtusxsrF6HWHHFOKWiyG3WKAIAwK4IRDamLUL1O8eZ5zk7CqUsj5vBAgDsiUBkczFpERLdKFzELXJ4c4FYFqtYAwDsh0Bkcw6HQ+p3Ob6KdVFmqRQeKPV3lQAAqHMBHYgmTpwo55xzjsTHx0tKSooMGjRItm/f7lOmuLhYRo4cKfXr15e4uDgZPHiwHDx40KfM3r175bLLLpOYmBjzOmPGjJHycrqHPCLiXZJ4RrR3oLXDGdC/FgAA1LiA/uT75JNPTNhZvXq1LFmyRMrKyqRPnz5SUFDgLXPvvffKBx98IO+9954pv3//frnyyiu95ysqKkwYKi0tlc8//1xee+01mT17towbN85PVxWY6rWPlbBop5QXuCWlWSt/VwcAgDoV0NPuFy1a5LOvQUZbeDZs2CAXX3yxHDt2TF555RV588035dJLLzVlZs2aJe3btzch6rzzzpPFixfL119/LUuXLpVGjRpJly5d5IknnpAHH3xQxo8fLxEREX66ugAcYN0pVrLW5ElK89OkKKtUolP43gAA7CGgW4iq0gCkkpOTzaMGI2016t27t7dMu3btpHnz5pKenm729bFjx44mDHn07dtXcnNzZevWrSd8n5KSEnO+8mYHsU0jJaphuDjDwuS/rx5ggDUAwDYCuoWoMrfbLaNHj5YLLrhAzjrrLHMsMzPTtPAkJSX5lNXwo+c8ZSqHIc95z7mfGrv0+OOPS6CtMD05ZfLPljnVAdYNusbJ3kVH5PDGPDm0Lk9Szk04pdcEACAYBE0g0rFEX331laxcubLW32vs2LFy3333efe1hahZs2YSKCtM/5Q3r3/plN8nIsElhzJ2S6MWrWX7rANSv1OchEUFVUMiAAC/WFB80o0aNUoWLFggK1askKZNm3qPp6ammsHSOTk5PuV1lpme85SpOuvMs+8pU1VkZKQkJCT4bHZycM+3puus+EiZ7Pp/Wf6uDgAA9g5EOoZFw9DcuXNl+fLl0qqV7+ynbt26SXh4uCxbtsx7TKfl6zT7nj17mn19/PLLLyUr64cPdp2xpiHnzDPPrMOrCR6W2y3tbmlsnu9ZcFjy/3dqXXEAAAQ6V6B3k+kMsn//+99mLSLPmJ/ExESJjo42j8OGDTPdWzrQWkPOn/70JxOCdIaZ0mn6GnxuvPFGmTRpknmNRx55xLy2tgThxGORXhvwkrQ8q6skNmgkS25dK99uWutTJq5xvNyx+Xa/1REAANsEohkzZpjH3/72tz7HdWr9zTffbJ4/88wz4nQ6zYKMOjtMZ5C98MIL3rJhYWGmu+3OO+80QSk2NlaGDh0qEyZMqOOrCR6e8UplBRXyv8XZEpeULL3HXC3xLaK8ZeaO+pdf6wgAgG0C0clM+46KipLp06eb7ae0aNFCFi5cWMO1C33hsWFmwcbsrwrMCtbRjSLExQBrAEAI4tMN1dJbekQkucRdasnhDXmsTQQACEkEIlTL4XRIyjnx5jdFb/yav6fE31UCAKDGEYjwsyISXZJ8Zqx5fnhTvpTlcWNcAEBoIRDhpCS2jZaoBuFilVtycHWuOJz86gAAQgefajjp23qk9IgXZ6RDSo9VSJPT2/u7SgAA1BgCEU6aKzrMe2+z+mnN5H9Lsv1dJQAAagSBCL9ITKMIqdchxjz/7yv75fCmPH9XCQCAU0Ygwi+W1C5GsjP3ieUW2fJMhuR9V+TvKgEAcEoIRPhV44n+t/0rqdchViqK3LLhie8kbw/3OwMABC8CEX4VXaCx8/3NJaF1tJTlVciGCbsJRQCAoEUgwind2uPsR1p6Q9H6x3bJkS35/q4WAAC/GIEINRKKdFxReaFbvvjbd5Kx6Ai3+AAABBUCEWokFHV7tKU0vjjJDLT+76sHZMs/MqSUFa0BAEGCQIQa4Qx3SoeRTaTNjaniCHNI1tpcSb//GzmYfozWIgBAwCMQoUZnn7W8vIGc+7fTJLZJpJQeLTfT8jc++Z3k/48B1wCAwOXydwUQnIpzimVyyuSfPK/3Omt6Zjtp0LiFZH9ZIOl//kaaXFpPWv8xRSLrhddpXQEA+DkEIvwqltuSK6bdWG2Zt254WQ6m7pbGrdtKUsNU2bfsqOxdfEgOZXwnhzJ2i7uiQuIax8sdm2+vs3oDAHAiBCLUami6bPJV5nnx4TIzJb8kWyS15enSpN0ZUu/MGFn2zP/zdzUBAGAMEepGVINwSbskSVLOSxBXrFMqit1yeGO+tO1+gRxan8vAawCAX9FChDoddB3XNFJi0yIk99siObqtUKIkTjZN2mtai9re3FjiW0b7u5oAABuihQh1zuF0SGKbGGnWL1my9u4SZ7hDjn5dKGvGfivfvH1Q3GVuf1cRAGAzBCL4TViEUw7s2iHnP9dGUnokiFUhsvv9Q7L6wW/l2M5Cf1cPAGAjBCL4XXSDCOn85+bS6b5mEpEYJgX/K5G1j+yS7a8fkIoSWosAALWPMUQIqPWMwlzhknZ6O0lObSJ7FxyRne/ulcOHv5WbV1/v13oCAEIbgQgBuZ5R4YESObQhXyIlVtKadTStRadf00jCImnUBADUPD5dEJBiGkdK0z71JK5FpJmdpq1Fqx/4RnL+W+DvqgEAQhCBCAE96DrlnATZtWW9RNZzSeGBUln32G7GFgEAahxdZgh4h3b9TwpyF0mT1u0kuXHT42OL3tsr+7/dLrmHs0wZbgECADgVBCIExTijgc9e98PYoo3Hxxa1OutsswJ2/c6xsvDRt/1dTQBAEKPLDEE3tqhZ32RJahcjDufxe6TtW5Yjzdp1lMKDpf6uHgAgSBGIEHScLocknxVrVrqOax5pjuk0/VV375AtU/bKsW9Y1BEA8MvQZYag5YoJk5RzEyTh9DL57//tlITkhnJwda7Z9N5ozS9rIA26xpsABQBAdQhECHpRyeGye8sGuX3dKNnzwWHJXJVj7o129Ou9Eh4fJqkXJErji5MkoXW0mcIPAEBVBCKEzIrXL54zzTwPj4ySBk1aSL3UNJG8SMlYlG220tIiaTO4mdTvFCtJ7WPNtH4AABSBCCG74rUeK8oqk/w9xVKwv0QiIqJNC5JuznCHGZid3CFW4k+LloTToiUigf8cAMCu+ARAyHI4HRKTGmE2d5lbPpm4THre9Vs5siVfSrLLJfvLArN5RCa7JHtvluQfOSrFhflSUlBgHi237yKQrHkEAKGHQARbcIY7JScrUzrc1VQsy5KCfSWSvSVfcnYUSd7uIrMKtoak2Lhks1XminVKRLxLwhPCTCvSqhcXS3lRhbiiw/x2PQCAmkUggq3GGU1OmXzCc86wMImOSxBXWLR0HHSulOVWSGluubhLLSkvcEt5QalI5vGyZ3TrKSuGbpPI+i6JaxolsU0iJbZppMQ11ccoCY8jKAFAsCEQwdbjjKp68/qX5NKze3n39Z5pGow8Aak0t0Jy9+ZKRHS0lBwpl5Ij+XJkc77Pa5QWF0lZeZF0vLmtxLeMlviWURLVMJwZbgAQwAhEQDXCIp0S3TBCohv+cOzj69+Va2bfdjwk5f0QlsryKqS80C0RUdESIdGy6/8O+XS7ecJRfKso8zw2LZI1kgAgQBCIgF9Bp+yHNXCae6lVpoO3S3LKZf0/0+Wc4edL3nfFkp9RYrrdjm4tMJuHznTTAd9RGrhSws1jVP1wccU4xRXllDDdosNMOb1NiQ4SP759/zxMxOFy0PIEADWAQATU8OBtbVH639Ydcnj8XnNMA0tkbJwZoxQdF//9Y4L5z0/Dkm6/ltvtFre7XBKax0l4bJiEx7skuqGGq3CJaqAtW8eDVkRiGMEJAKpBIAL8MF5JZ7otHPP/ZMgHN0nRoTIpyio1ayaVHC2TiiK3lBe7zWNRdrGEuVwi1olfx+l0itMZIYX7q7+xrdtdIXFNok2LlrZCmUfv8wiJqOcSV7ST0ATAtmwViKZPny5PP/20ZGZmSufOneX555+Xc88919/Vgg1p8MjNPCqzfvfiz86Mu+6N4d4QpcFIH8yj2xKr3JIFf35P+j5+pbjLLDMIvLzg+FimssLjjxqsnM4ws7SAbtW1NsWkREpEouv7LazSc5dExIeJK/b4pq1Rei85xkABCBW2CUTvvPOO3HfffTJz5kzp0aOHPPvss9K3b1/Zvn27pKSk+Lt6sKGTnfXmYVpvjv/Pc0QkQqTwWK5Ep0RU+z7vj5gjAyb+0QSkcg1K2gr1/XMNTBqmtLWp+HCZ2X7JoHMdMK6PTh1XFeH48WO4U5yRWsZxfOxV1Pfldd8cr7p5vlZf8/i4KQCobbYJRFOmTJHhw4fLLbfcYvY1GP3nP/+RV199VR566CF/Vw+oNRooSgoLzdimn+KusGTuHXMktkGChEdEiCsiUlzh+nj8eXh4hISFh4vT6TLHTDfe98sS6Far9Q/TgOT4IVyFHw9MJ9M65WlV+6Fl7ftWNnPSc9xzwDNw/fh7ilPXp3L8MIDdPP5wvnJZ73FPme/L62uYWlYOs/p/Dt+Qe3zneDH5ifI+r+N9DZ+E7P3SE38jT1zG0+Lo+7xSa6TS1sjK3zPvc+tHr/GzTra+P1Wg+t0fH/jZ8j9XoPri1VbgF1/rz5X/mbqe4vdGqhz4+Wut5r2r7Ht/R6r+t1jpv0P9B1HT3r4L49YlWwSi0tJS2bBhg4wdO9Z7TP813Lt3b0lPT/9R+ZKSErN5HDt2zDzm5ubWSv2K3cWSV5hXfRmLMpSp3TLH8rOlz3MDqy3z3rBZcvUrt3i767RlyV3qNoHKcotYFZakz/xEIuMivx/fFCaOsO8fHWFmAUxnmFOsCpG0Ts2Pf12FHH8t8/z4o1TOWNpgVVxttQCEgIryUkk4t0uNvqbnc9v8w+fnWDawb98+k0E///xzn+Njxoyxzj333B+Vf+yxxyplWTY2NjY2NjYJ4i0jI+Nns4ItWoh+KW1J0vFGlQebZmdnS/369Wt8Fo6m12bNmklGRoYkJOhU7NBnt2u22/UqrplrDlV2u+bcIL9ebRnKy8uTtLS0ny1ri0DUoEEDCQsLk4MHD/oc1/3U1NQflY+MjDRbZUlJSbVaR/1FC8ZftlNht2u22/UqrtkeuObQlxDE15uYmHhS5ZxiAxEREdKtWzdZtmyZT6uP7vfs2dOvdQMAAP5nixYipV1gQ4cOle7du5u1h3TafUFBgXfWGQAAsC/bBKJrrrlGDh06JOPGjTMLM3bp0kUWLVokjRo18mu9tGvuscce+1EXXSiz2zXb7XoV12wPXHPoi7TR9Tp0ZLW/KwEAAOBPthhDBAAAUB0CEQAAsD0CEQAAsD0CEQAAsD0CkR9Nnz5dWrZsKVFRUdKjRw9Zu3atBKtPP/1ULr/8crMaqK7mPW/ePJ/zOnZfZ/g1btxYoqOjzX3kdu7c6VNGVwMfMmSIWfxLF8IcNmyY5OfnSyCaOHGinHPOORIfHy8pKSkyaNAg2b59u0+Z4uJiGTlypFnhPC4uTgYPHvyjxUH37t0rl112mcTExJjXGTNmjJSXl0sgmjFjhnTq1Mm7QJuu4fXhhx+G7PWeyFNPPWV+v0ePHh2y1z1+/HhzjZW3du3ahez1qn379skNN9xgrkn/PnXs2FHWr18fsn+/9HOn6s/Y4XCYn2uo/oxPSk3eMwwn7+2337YiIiKsV1991dq6das1fPhwKykpyTp48KAVjBYuXGg9/PDD1vvvv2/uGzN37lyf80899ZSVmJhozZs3z9q8ebP1hz/8wWrVqpVVVFTkLdOvXz+rc+fO1urVq63PPvvMOv30063rrrvOCkR9+/a1Zs2aZX311VfWpk2brAEDBljNmze38vPzvWXuuOMOq1mzZtayZcus9evXW+edd551/vnne8+Xl5dbZ511ltW7d2/riy++MN/DBg0aWGPHjrUC0fz5863//Oc/1o4dO6zt27dbf/nLX6zw8HDzPQjF661q7dq1VsuWLa1OnTpZ99xzj/d4qF233suxQ4cO1oEDB7zboUOHQvZ6s7OzrRYtWlg333yztWbNGmvXrl3WRx99ZH3zzTch+/crKyvL5+e7ZMkS83d7xYoVIfkzPlkEIj/Rm8qOHDnSu19RUWGlpaVZEydOtIJd1UDkdrut1NRU6+mnn/Yey8nJsSIjI6233nrL7H/99dfm69atW+ct8+GHH1oOh8PcnDfQ6R8Yrf8nn3zivT4NC++99563zLZt20yZ9PR0s69/RJxOp5WZmektM2PGDCshIcEqKSmxgkG9evWsf/7znyF/vXl5eVabNm3MB8dvfvMbbyAKxevWQKQf7CcSitf74IMPWhdeeOFPnrfD3y/9fW7durW51lD8GZ8susz8oLS0VDZs2GCaXT2cTqfZT09Pl1Cze/dusxhm5evVe8toN6HnevVRm5l1JXEPLa/flzVr1kigO3bsmHlMTk42j/rzLSsr87lm7XZo3ry5zzVr03zlxUH79u1rbqa4detWCWQVFRXy9ttvm9Xetess1K9Xuw+0e6Dy9alQvW7tDtLu79NOO810A2n3SKhe7/z5883fnauvvtp0/XTt2lVefvll2/z90s+jN954Q2699VbTbRaKP+OTRSDyg8OHD5sPlKqrZOu+/ocXajzXVN316qP+MarM5XKZgBHo3xO9L56OKbngggvkrLPOMse0znoPvao3Ba56zSf6nnjOBaIvv/zSjCnQVWvvuOMOmTt3rpx55pkhe71Kg9/GjRvNuLGqQvG69YN+9uzZZiV/HTemgeCiiy4ydwwPxevdtWuXuc42bdrIRx99JHfeeafcfffd8tprr9ni75eO98zJyZGbb77Z7Ifiz/hk2ebWHUBtth589dVXsnLlSgl1bdu2lU2bNpkWsf/7v/8z9wf85JNPJFRlZGTIPffcI0uWLDGTH+ygf//+3uc6iF4DUosWLeTdd981A4pDjf6DRlt2/va3v5l9bSHS/55nzpxpfr9D3SuvvGJ+5mlpaWJ3tBD5QYMGDSQsLOxHo/Z1PzU1VUKN55qqu159zMrK8jmvMxZ05kYgf09GjRolCxYskBUrVkjTpk29x7XO2hSt//Kq7ppP9D3xnAtE+i/H008/Xbp162ZaTDp37izPPfdcyF6vdh/o7+XZZ59t/sWvmwbAqVOnmuf6r+JQvO7KtKXgjDPOkG+++SYkf846c0xbOStr3769t5swlP9+7dmzR5YuXSq33Xab91go/oxPFoHITx8q+oGybNkyn3+l6L6Oxwg1rVq1Mv+RVL5e7WvWvnXP9eqj/geoH0Aey5cvN98X/RdqoNGx4xqGtMtI66nXWJn+fMPDw32uWafl6x/ZytesXVCV/5BqS4RO2636BzpQ6c+npKQkZK+3V69eps7aKubZtDVBx9V4nofidVemU8e//fZbExxC8eesXd1Vl8zYsWOHaRUL1b9fHrNmzTJdfTo+ziMUf8Ynzd+juu087V5nKcyePdvMUBgxYoSZdl951H4w0Vk4Ov1SN/21mjJlinm+Z88e77RVvb5///vf1pYtW6yBAweecNpq165dzdTXlStXmlk9gTpt9c477zTTcD/++GOf6auFhYXeMjp1VafiL1++3Exd7dmzp9mqTl3t06ePmbq/aNEiq2HDhgE7dfWhhx4ys+h2795tfoa6r7NoFi9eHJLX+1MqzzILxev+85//bH6v9ee8atUqM7Vap1TrTMpQvF5dTsHlcll//etfrZ07d1pz5syxYmJirDfeeMNbJtT+fnlmNuvPUWfZVXVHiP2MTxaByI+ef/5580un6xHpNHxdvyJY6foVGoSqbkOHDjXndTrno48+ajVq1MgEwV69epm1bCo7cuSI+QMSFxdnpm/ecsstJmgFohNdq266NpGH/rG86667zNR0/QN7xRVXmNBU2XfffWf179/fio6ONh86+mFUVlZmBaJbb73VrNeiv6/6x09/hp4wFIrXe7KBKNSu+5prrrEaN25sfs5NmjQx+5XX5Am161UffPCB+YDXv03t2rWzXnrpJZ/zofb3S+laS/o3q+p1hOrP+GQ49P/83UoFAADgT4whAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAoBa8PHHH4vD4fjRTTIBBCYCEYBakZGRIbfeequkpaWZGxrrzTLvueceOXLkSJ3X5eabbzbhRDety+mnny4TJkwwdyT3p4qKCnnqqaekXbt2Eh0dLcnJyeZmoP/85z9PWPfKm959HkDNcdXgawGAsWvXLnNH7DPOOEPeeustc8fwrVu3ypgxY+TDDz+U1atXmw//utSvXz9zd++SkhJZuHChjBw50tzVe+zYsb8qyGgocTpP7d+Ujz/+uLz44osybdo06d69u7mL+vr16+Xo0aMnrHtlDRs2PKX3BuCLFiIANU7DhrbELF68WH7zm99I8+bNpX///rJ06VLZt2+fPPzww6Zcy5Yt5YknnpDrrrtOYmNjpUmTJjJ9+nSf19Iup9tuu80EgISEBLn00ktl8+bN3vPjx4+XLl26yL/+9S/zeomJiXLttddKXl6ez+tERkZKamqqaam68847pXfv3jJ//nxzTgPITTfdJPXq1ZOYmBhT1507d3q/dvbs2ZKUlGTKn3nmmea19u7da8LVgw8+KM2aNTPHtOXplVde8XnfDRs2mLCjr3v++efL9u3bvef09e666y65+uqrTWjs3LmzDBs2TO6///4T1r3yFhYWViM/KwDHEYgA1Kjs7Gz56KOPzAe9dgNVph/kQ4YMkXfeeUc895V++umnTRD44osv5KGHHjLdakuWLPF+jYaFrKws07Kk4eLss8+WXr16mffx+Pbbb2XevHmyYMECs33yySemK6o6WrfS0lJvt5S2zGhASU9PN3UbMGCAlJWVecsXFhbK3//+d9Odpa1dKSkpJkRpC9jUqVNl27ZtprUnLi7O5300/P3jH/8wr+9yuUw3YuXvx/Lly+XQoUO/+vsNoIb8cON7ADh1q1ev1qRjzZ0794Tnp0yZYs4fPHjQatGihdWvXz+f89dcc43Vv39/8/yzzz6zEhISrOLiYp8yrVu3tl588UXz/LHHHrNiYmKs3Nxc7/kxY8ZYPXr08O4PHTrUGjhwoHnudrutJUuWWJGRkdb9999v7dixw9Rn1apV3vKHDx+2oqOjrXfffdfsz5o1y5TZtGmTt8z27dvNMX2tE1mxYoU5v3TpUu+x//znP+ZYUVGR2d+6davVvn17y+l0Wh07drRuv/12a+HChT6vo3UPCwuzYmNjvdtVV131k99/AL8OY4gA1ApPC9DP0bFGVfefffZZ81y7xvLz86V+/fo+ZYqKikyrkId2lcXHx3v3GzdubFqVKtOWI2290VYft9st119/veluW7ZsmWm50cHMHvp+bdu2Na0+HtoF2KlTJ+/+pk2bTLeVdglWp/LXaL2U1k27EbX77auvvjItX6tWrZJPP/1ULr/8ctNiVXlg9SWXXCIzZszw7mv3IoCaRSACUKN0HI0OONYwccUVV/zovB7XsTonMyhYw5CGCJ3CXpWO6fHQwdGV6ftr6KnMEyo02OjMNw1Bv4R2senrVt4/GZXr5vn6ynXTgdnnnHOO2UaPHi1vvPGG3HjjjaarTccVeQKQfl8B1B7GEAGoUdq68rvf/U5eeOEF05JTWWZmpsyZM0euueYabzjQGWeV6X779u3Ncx0vpF+j4UUDQeWtQYMGv6henlChLTOVw5C+l06/X7NmjfeYLg2gg5+1BeendOzY0QQbHa9UkzzvWVBQUKOvC6B6BCIANU6nkesMrL59+5puIF2TaNGiRSYo6Uyyv/71r96y2lU0adIk2bFjh5lh9t5775mB1UpngmkX2qBBg8yMte+++04+//xz03qig5RrQps2bWTgwIEyfPhwWblypemmu+GGG0w99fhP0W66oUOHmkHSOqB79+7dpiXr3XffPen3vuqqq+SZZ54xYWzPnj3m63WGni5XoGsTAag7BCIANU5DhgaW0047Tf74xz9K69atZcSIEabbSmdxVV6D6M9//rMp27VrV3nyySdlypQpJkgpbUXSNYMuvvhiueWWW0xQ0Cn1Gh4aNWpUY/XVNX66desmv//9700A0/FP+r5Vu+Kq0i44DTU6o04DjIaqX9Kyo9f5wQcfmHFDem0asPR1NPz90i49AKfGoSOrT/E1AOBX0VYWHTejGwD4Ey1EAADA9ghEAADA9ugyAwAAtkcLEQAAsD0CEQAAsD0CEQAAsD0CEQAAsD0CEQAAsD0CEQAAsD0CEQAAsD0CEQAAELv7/8VSI38m8VHGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['OpenPorchSF'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OpenPorchSF'] = np.log1p(df['OpenPorchSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='OpenPorchSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(np.log1p(df['OpenPorchSF']), bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WoodDeckSF'] = np.log1p(df['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='WoodDeckSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(np.log1p(df['WoodDeckSF']), bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1stFlrSF\n",
       "864     46\n",
       "1040    28\n",
       "912     19\n",
       "816     18\n",
       "960     18\n",
       "        ..\n",
       "1286     1\n",
       "1921     1\n",
       "665      1\n",
       "834      1\n",
       "1017     1\n",
       "Name: count, Length: 1083, dtype: int64"
      ]
     },
     "execution_count": 1280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1stFlrSF'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1stFlrSF'] = np.log1p(df['1stFlrSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='1stFlrSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['1stFlrSF'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='BsmtFinSF1', ylabel='Count'>"
      ]
     },
     "execution_count": 1283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['BsmtFinSF1'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinSF1'] = np.log1p(df['BsmtFinSF1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='BsmtFinSF1', ylabel='Count'>"
      ]
     },
     "execution_count": 1285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['BsmtFinSF1'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtHalfBath_2.0    26.972189\n",
       "BsmtHalfBath         3.933616\n",
       "BsmtHalfBath_1.0     3.761242\n",
       "SalePrice            1.882876\n",
       "LotFrontage          1.461180\n",
       "ExterCond            1.316590\n",
       "GrLivArea            1.270010\n",
       "TotalBsmtSF          1.157489\n",
       "BsmtUnfSF            0.919812\n",
       "2ndFlrSF             0.862118\n",
       "ExterQual            0.786786\n",
       "TotRmsAbvGrd         0.758757\n",
       "Fireplaces           0.733872\n",
       "HalfBath             0.694924\n",
       "BsmtFullBath         0.625153\n",
       "OverallCond          0.570605\n",
       "MasVnrArea           0.537294\n",
       "BedroomAbvGr         0.326492\n",
       "GarageArea           0.239380\n",
       "OverallQual          0.197212\n",
       "MoSold               0.195985\n",
       "FullBath             0.167692\n",
       "WoodDeckSF           0.158114\n",
       "YrSold               0.132467\n",
       "1stFlrSF             0.064861\n",
       "OpenPorchSF         -0.041819\n",
       "GarageCars          -0.219694\n",
       "GarageYrBlt         -0.392992\n",
       "YearRemodAdd        -0.451252\n",
       "LotArea             -0.505010\n",
       "YearBuilt           -0.600114\n",
       "BsmtFinSF1          -0.616949\n",
       "BsmtQual            -1.269195\n",
       "BsmtCond            -3.605964\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = df.skew(numeric_only=True).sort_values(ascending=False)\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ExterCond'] is a categorical variable with 5 categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='GrLivArea', ylabel='Count'>"
      ]
     },
     "execution_count": 1288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['GrLivArea'], bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GrLivArea'] = np.log1p(df['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TotalBsmtSF', ylabel='Count'>"
      ]
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(np.log1p(df['TotalBsmtSF']), bins=50, kde=True, color='mediumorchid', edgecolor='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-4.958842187588636)"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(df['TotalBsmtSF']).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6110.0,\n",
       " 5095.0,\n",
       " 3206.0,\n",
       " 3200.0,\n",
       " 3138.0,\n",
       " 3094.0,\n",
       " 2846.0,\n",
       " 2660.0,\n",
       " 2633.0,\n",
       " 2630.0,\n",
       " 2552.0,\n",
       " 2535.0,\n",
       " 2524.0,\n",
       " 2492.0,\n",
       " 2461.0,\n",
       " 2458.0,\n",
       " 2452.0,\n",
       " 2444.0,\n",
       " 2418.0,\n",
       " 2396.0,\n",
       " 2392.0,\n",
       " 2330.0,\n",
       " 2320.0,\n",
       " 2271.0,\n",
       " 2223.0,\n",
       " 2220.0,\n",
       " 2217.0,\n",
       " 2216.0,\n",
       " 2208.0,\n",
       " 2200.0,\n",
       " 2190.0,\n",
       " 2171.0,\n",
       " 2158.0,\n",
       " 2153.0,\n",
       " 2140.0,\n",
       " 2136.0,\n",
       " 2136.0,\n",
       " 2121.0,\n",
       " 2110.0,\n",
       " 2109.0,\n",
       " 2108.0,\n",
       " 2078.0,\n",
       " 2077.0,\n",
       " 2076.0,\n",
       " 2062.0,\n",
       " 2048.0,\n",
       " 2046.0,\n",
       " 2042.0,\n",
       " 2036.0,\n",
       " 2035.0,\n",
       " 2033.0,\n",
       " 2024.0,\n",
       " 2020.0,\n",
       " 2014.0,\n",
       " 2006.0,\n",
       " 2002.0,\n",
       " 2002.0,\n",
       " 2000.0,\n",
       " 1994.0,\n",
       " 1992.0,\n",
       " 1986.0,\n",
       " 1982.0,\n",
       " 1980.0,\n",
       " 1978.0,\n",
       " 1978.0,\n",
       " 1976.0,\n",
       " 1967.0,\n",
       " 1966.0,\n",
       " 1964.0,\n",
       " 1958.0,\n",
       " 1952.0,\n",
       " 1950.0,\n",
       " 1949.0,\n",
       " 1947.0,\n",
       " 1935.0,\n",
       " 1934.0,\n",
       " 1932.0,\n",
       " 1930.0,\n",
       " 1930.0,\n",
       " 1926.0,\n",
       " 1922.0,\n",
       " 1922.0,\n",
       " 1921.0,\n",
       " 1910.0,\n",
       " 1907.0,\n",
       " 1905.0,\n",
       " 1902.0,\n",
       " 1898.0,\n",
       " 1896.0,\n",
       " 1884.0,\n",
       " 1884.0,\n",
       " 1884.0,\n",
       " 1869.0,\n",
       " 1868.0,\n",
       " 1868.0,\n",
       " 1866.0,\n",
       " 1865.0,\n",
       " 1860.0,\n",
       " 1858.0,\n",
       " 1856.0,\n",
       " 1851.0,\n",
       " 1850.0,\n",
       " 1850.0,\n",
       " 1848.0,\n",
       " 1848.0,\n",
       " 1845.0,\n",
       " 1844.0,\n",
       " 1844.0,\n",
       " 1844.0,\n",
       " 1842.0,\n",
       " 1840.0,\n",
       " 1838.0,\n",
       " 1838.0,\n",
       " 1838.0,\n",
       " 1838.0,\n",
       " 1836.0,\n",
       " 1836.0,\n",
       " 1836.0,\n",
       " 1836.0,\n",
       " 1833.0,\n",
       " 1832.0,\n",
       " 1829.0,\n",
       " 1824.0,\n",
       " 1824.0,\n",
       " 1822.0,\n",
       " 1822.0,\n",
       " 1822.0,\n",
       " 1814.0,\n",
       " 1809.0,\n",
       " 1803.0,\n",
       " 1802.0,\n",
       " 1800.0,\n",
       " 1800.0,\n",
       " 1800.0,\n",
       " 1800.0,\n",
       " 1800.0,\n",
       " 1795.0,\n",
       " 1792.0,\n",
       " 1792.0,\n",
       " 1790.0,\n",
       " 1782.0,\n",
       " 1782.0,\n",
       " 1780.0,\n",
       " 1779.0,\n",
       " 1778.0,\n",
       " 1777.0,\n",
       " 1776.0,\n",
       " 1776.0,\n",
       " 1774.0,\n",
       " 1768.0,\n",
       " 1766.0,\n",
       " 1765.0,\n",
       " 1763.0,\n",
       " 1760.0,\n",
       " 1753.0,\n",
       " 1753.0,\n",
       " 1752.0,\n",
       " 1751.0,\n",
       " 1748.0,\n",
       " 1746.0,\n",
       " 1742.0,\n",
       " 1742.0,\n",
       " 1740.0,\n",
       " 1740.0,\n",
       " 1739.0,\n",
       " 1738.0,\n",
       " 1736.0,\n",
       " 1734.0,\n",
       " 1734.0,\n",
       " 1734.0,\n",
       " 1733.0,\n",
       " 1732.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1728.0,\n",
       " 1726.0,\n",
       " 1726.0,\n",
       " 1722.0,\n",
       " 1721.0,\n",
       " 1721.0,\n",
       " 1720.0,\n",
       " 1720.0,\n",
       " 1719.0,\n",
       " 1714.0,\n",
       " 1713.0,\n",
       " 1712.0,\n",
       " 1710.0,\n",
       " 1710.0,\n",
       " 1710.0,\n",
       " 1709.0,\n",
       " 1706.0,\n",
       " 1705.0,\n",
       " 1705.0,\n",
       " 1704.0,\n",
       " 1704.0,\n",
       " 1702.0,\n",
       " 1702.0,\n",
       " 1700.0,\n",
       " 1700.0,\n",
       " 1698.0,\n",
       " 1698.0,\n",
       " 1698.0,\n",
       " 1696.0,\n",
       " 1696.0,\n",
       " 1694.0,\n",
       " 1694.0,\n",
       " 1694.0,\n",
       " 1694.0,\n",
       " 1689.0,\n",
       " 1689.0,\n",
       " 1686.0,\n",
       " 1686.0,\n",
       " 1686.0,\n",
       " 1686.0,\n",
       " 1685.0,\n",
       " 1684.0,\n",
       " 1683.0,\n",
       " 1682.0,\n",
       " 1682.0,\n",
       " 1680.0,\n",
       " 1680.0,\n",
       " 1680.0,\n",
       " 1680.0,\n",
       " 1680.0,\n",
       " 1679.0,\n",
       " 1678.0,\n",
       " 1675.0,\n",
       " 1673.0,\n",
       " 1673.0,\n",
       " 1671.0,\n",
       " 1670.0,\n",
       " 1670.0,\n",
       " 1666.0,\n",
       " 1666.0,\n",
       " 1664.0,\n",
       " 1664.0,\n",
       " 1660.0,\n",
       " 1660.0,\n",
       " 1657.0,\n",
       " 1657.0,\n",
       " 1656.0,\n",
       " 1656.0,\n",
       " 1654.0,\n",
       " 1652.0,\n",
       " 1652.0,\n",
       " 1652.0,\n",
       " 1650.0,\n",
       " 1650.0,\n",
       " 1649.0,\n",
       " 1645.0,\n",
       " 1643.0,\n",
       " 1643.0,\n",
       " 1643.0,\n",
       " 1642.0,\n",
       " 1641.0,\n",
       " 1638.0,\n",
       " 1638.0,\n",
       " 1632.0,\n",
       " 1632.0,\n",
       " 1632.0,\n",
       " 1630.0,\n",
       " 1629.0,\n",
       " 1629.0,\n",
       " 1626.0,\n",
       " 1626.0,\n",
       " 1626.0,\n",
       " 1625.0,\n",
       " 1625.0,\n",
       " 1625.0,\n",
       " 1624.0,\n",
       " 1624.0,\n",
       " 1623.0,\n",
       " 1622.0,\n",
       " 1621.0,\n",
       " 1620.0,\n",
       " 1620.0,\n",
       " 1620.0,\n",
       " 1618.0,\n",
       " 1617.0,\n",
       " 1617.0,\n",
       " 1616.0,\n",
       " 1616.0,\n",
       " 1615.0,\n",
       " 1614.0,\n",
       " 1614.0,\n",
       " 1614.0,\n",
       " 1614.0,\n",
       " 1614.0,\n",
       " 1612.0,\n",
       " 1610.0,\n",
       " 1606.0,\n",
       " 1606.0,\n",
       " 1604.0,\n",
       " 1604.0,\n",
       " 1604.0,\n",
       " 1603.0,\n",
       " 1602.0,\n",
       " 1602.0,\n",
       " 1602.0,\n",
       " 1600.0,\n",
       " 1598.0,\n",
       " 1598.0,\n",
       " 1596.0,\n",
       " 1596.0,\n",
       " 1595.0,\n",
       " 1595.0,\n",
       " 1595.0,\n",
       " 1594.0,\n",
       " 1594.0,\n",
       " 1594.0,\n",
       " 1594.0,\n",
       " 1594.0,\n",
       " 1593.0,\n",
       " 1592.0,\n",
       " 1590.0,\n",
       " 1588.0,\n",
       " 1588.0,\n",
       " 1587.0,\n",
       " 1587.0,\n",
       " 1584.0,\n",
       " 1584.0,\n",
       " 1584.0,\n",
       " 1582.0,\n",
       " 1582.0,\n",
       " 1582.0,\n",
       " 1582.0,\n",
       " 1581.0,\n",
       " 1580.0,\n",
       " 1580.0,\n",
       " 1580.0,\n",
       " 1580.0,\n",
       " 1578.0,\n",
       " 1578.0,\n",
       " 1577.0,\n",
       " 1575.0,\n",
       " 1574.0,\n",
       " 1574.0,\n",
       " 1573.0,\n",
       " 1573.0,\n",
       " 1573.0,\n",
       " 1573.0,\n",
       " 1573.0,\n",
       " 1572.0,\n",
       " 1572.0,\n",
       " 1571.0,\n",
       " 1570.0,\n",
       " 1569.0,\n",
       " 1568.0,\n",
       " 1568.0,\n",
       " 1568.0,\n",
       " 1568.0,\n",
       " 1567.0,\n",
       " 1566.0,\n",
       " 1566.0,\n",
       " 1565.0,\n",
       " 1564.0,\n",
       " 1563.0,\n",
       " 1562.0,\n",
       " 1561.0,\n",
       " 1561.0,\n",
       " 1560.0,\n",
       " 1560.0,\n",
       " 1560.0,\n",
       " 1560.0,\n",
       " 1560.0,\n",
       " 1559.0,\n",
       " 1557.0,\n",
       " 1556.0,\n",
       " 1556.0,\n",
       " 1555.0,\n",
       " 1554.0,\n",
       " 1554.0,\n",
       " 1553.0,\n",
       " 1552.0,\n",
       " 1550.0,\n",
       " 1546.0,\n",
       " 1546.0,\n",
       " 1544.0,\n",
       " 1542.0,\n",
       " 1542.0,\n",
       " 1541.0,\n",
       " 1541.0,\n",
       " 1540.0,\n",
       " 1538.0,\n",
       " 1536.0,\n",
       " 1533.0,\n",
       " 1531.0,\n",
       " 1530.0,\n",
       " 1530.0,\n",
       " 1530.0,\n",
       " 1529.0,\n",
       " 1528.0,\n",
       " 1528.0,\n",
       " 1528.0,\n",
       " 1525.0,\n",
       " 1524.0,\n",
       " 1524.0,\n",
       " 1524.0,\n",
       " 1522.0,\n",
       " 1520.0,\n",
       " 1519.0,\n",
       " 1518.0,\n",
       " 1518.0,\n",
       " 1518.0,\n",
       " 1517.0,\n",
       " 1517.0,\n",
       " 1516.0,\n",
       " 1512.0,\n",
       " 1511.0,\n",
       " 1510.0,\n",
       " 1510.0,\n",
       " 1510.0,\n",
       " 1509.0,\n",
       " 1508.0,\n",
       " 1508.0,\n",
       " 1505.0,\n",
       " 1504.0,\n",
       " 1504.0,\n",
       " 1504.0,\n",
       " 1502.0,\n",
       " 1502.0,\n",
       " 1501.0,\n",
       " 1501.0,\n",
       " 1501.0,\n",
       " 1500.0,\n",
       " 1499.0,\n",
       " 1498.0,\n",
       " 1498.0,\n",
       " 1498.0,\n",
       " 1496.0,\n",
       " 1496.0,\n",
       " 1495.0,\n",
       " 1494.0,\n",
       " 1494.0,\n",
       " 1494.0,\n",
       " 1494.0,\n",
       " 1494.0,\n",
       " 1494.0,\n",
       " 1492.0,\n",
       " 1492.0,\n",
       " 1491.0,\n",
       " 1491.0,\n",
       " 1490.0,\n",
       " 1489.0,\n",
       " 1489.0,\n",
       " 1489.0,\n",
       " 1488.0,\n",
       " 1488.0,\n",
       " 1488.0,\n",
       " 1488.0,\n",
       " 1487.0,\n",
       " 1486.0,\n",
       " 1485.0,\n",
       " 1484.0,\n",
       " 1484.0,\n",
       " 1482.0,\n",
       " 1482.0,\n",
       " 1482.0,\n",
       " 1480.0,\n",
       " 1479.0,\n",
       " 1479.0,\n",
       " 1478.0,\n",
       " 1478.0,\n",
       " 1478.0,\n",
       " 1477.0,\n",
       " 1476.0,\n",
       " 1475.0,\n",
       " 1473.0,\n",
       " 1470.0,\n",
       " 1470.0,\n",
       " 1470.0,\n",
       " 1468.0,\n",
       " 1468.0,\n",
       " 1468.0,\n",
       " 1468.0,\n",
       " 1466.0,\n",
       " 1466.0,\n",
       " 1466.0,\n",
       " 1463.0,\n",
       " 1463.0,\n",
       " 1462.0,\n",
       " 1462.0,\n",
       " 1462.0,\n",
       " 1461.0,\n",
       " 1461.0,\n",
       " 1461.0,\n",
       " 1460.0,\n",
       " 1459.0,\n",
       " 1455.0,\n",
       " 1454.0,\n",
       " 1454.0,\n",
       " 1453.0,\n",
       " 1453.0,\n",
       " 1453.0,\n",
       " 1453.0,\n",
       " 1452.0,\n",
       " 1451.0,\n",
       " 1450.0,\n",
       " 1449.0,\n",
       " 1445.0,\n",
       " 1444.0,\n",
       " 1444.0,\n",
       " 1444.0,\n",
       " 1442.0,\n",
       " 1442.0,\n",
       " 1441.0,\n",
       " 1440.0,\n",
       " 1440.0,\n",
       " 1440.0,\n",
       " 1440.0,\n",
       " 1440.0,\n",
       " 1438.0,\n",
       " 1437.0,\n",
       " 1437.0,\n",
       " 1436.0,\n",
       " 1436.0,\n",
       " 1436.0,\n",
       " 1434.0,\n",
       " 1434.0,\n",
       " 1433.0,\n",
       " 1432.0,\n",
       " 1431.0,\n",
       " 1431.0,\n",
       " 1430.0,\n",
       " 1430.0,\n",
       " 1430.0,\n",
       " 1428.0,\n",
       " 1427.0,\n",
       " 1427.0,\n",
       " 1426.0,\n",
       " 1425.0,\n",
       " 1425.0,\n",
       " 1424.0,\n",
       " 1422.0,\n",
       " 1422.0,\n",
       " 1422.0,\n",
       " 1422.0,\n",
       " 1420.0,\n",
       " 1420.0,\n",
       " 1420.0,\n",
       " 1420.0,\n",
       " 1419.0,\n",
       " 1419.0,\n",
       " 1418.0,\n",
       " 1418.0,\n",
       " 1417.0,\n",
       " 1417.0,\n",
       " 1416.0,\n",
       " 1415.0,\n",
       " 1414.0,\n",
       " 1414.0,\n",
       " 1413.0,\n",
       " 1410.0,\n",
       " 1409.0,\n",
       " 1408.0,\n",
       " 1408.0,\n",
       " 1406.0,\n",
       " 1406.0,\n",
       " 1405.0,\n",
       " 1405.0,\n",
       " 1405.0,\n",
       " 1405.0,\n",
       " 1405.0,\n",
       " 1405.0,\n",
       " 1402.0,\n",
       " 1401.0,\n",
       " 1400.0,\n",
       " 1398.0,\n",
       " 1398.0,\n",
       " 1398.0,\n",
       " 1396.0,\n",
       " 1396.0,\n",
       " 1395.0,\n",
       " 1395.0,\n",
       " 1394.0,\n",
       " 1393.0,\n",
       " 1393.0,\n",
       " 1392.0,\n",
       " 1392.0,\n",
       " 1392.0,\n",
       " 1392.0,\n",
       " 1392.0,\n",
       " 1392.0,\n",
       " 1391.0,\n",
       " 1391.0,\n",
       " 1390.0,\n",
       " 1390.0,\n",
       " 1390.0,\n",
       " 1390.0,\n",
       " 1389.0,\n",
       " 1389.0,\n",
       " 1388.0,\n",
       " 1386.0,\n",
       " 1386.0,\n",
       " 1385.0,\n",
       " 1383.0,\n",
       " 1383.0,\n",
       " 1382.0,\n",
       " 1381.0,\n",
       " 1380.0,\n",
       " 1379.0,\n",
       " 1378.0,\n",
       " 1377.0,\n",
       " 1376.0,\n",
       " 1375.0,\n",
       " 1374.0,\n",
       " 1373.0,\n",
       " 1373.0,\n",
       " 1372.0,\n",
       " 1372.0,\n",
       " 1372.0,\n",
       " 1372.0,\n",
       " 1370.0,\n",
       " 1370.0,\n",
       " 1370.0,\n",
       " 1369.0,\n",
       " 1368.0,\n",
       " 1368.0,\n",
       " 1368.0,\n",
       " 1367.0,\n",
       " 1367.0,\n",
       " 1365.0,\n",
       " 1365.0,\n",
       " 1364.0,\n",
       " 1364.0,\n",
       " 1363.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1362.0,\n",
       " 1361.0,\n",
       " 1360.0,\n",
       " 1360.0,\n",
       " 1358.0,\n",
       " 1358.0,\n",
       " 1358.0,\n",
       " 1357.0,\n",
       " 1356.0,\n",
       " 1352.0,\n",
       " 1352.0,\n",
       " 1351.0,\n",
       " 1350.0,\n",
       " 1350.0,\n",
       " 1350.0,\n",
       " 1350.0,\n",
       " 1349.0,\n",
       " 1348.0,\n",
       " 1348.0,\n",
       " 1347.0,\n",
       " 1347.0,\n",
       " 1346.0,\n",
       " 1346.0,\n",
       " 1344.0,\n",
       " 1344.0,\n",
       " 1344.0,\n",
       " 1344.0,\n",
       " 1342.0,\n",
       " 1342.0,\n",
       " 1342.0,\n",
       " 1342.0,\n",
       " 1341.0,\n",
       " 1341.0,\n",
       " 1340.0,\n",
       " 1339.0,\n",
       " 1338.0,\n",
       " 1338.0,\n",
       " 1338.0,\n",
       " 1337.0,\n",
       " 1337.0,\n",
       " 1337.0,\n",
       " 1337.0,\n",
       " 1336.0,\n",
       " 1336.0,\n",
       " 1335.0,\n",
       " 1334.0,\n",
       " 1334.0,\n",
       " 1332.0,\n",
       " 1332.0,\n",
       " 1331.0,\n",
       " 1330.0,\n",
       " 1330.0,\n",
       " 1329.0,\n",
       " 1329.0,\n",
       " 1328.0,\n",
       " 1326.0,\n",
       " 1326.0,\n",
       " 1325.0,\n",
       " 1324.0,\n",
       " 1324.0,\n",
       " 1324.0,\n",
       " 1324.0,\n",
       " 1319.0,\n",
       " 1319.0,\n",
       " 1318.0,\n",
       " 1317.0,\n",
       " 1316.0,\n",
       " 1316.0,\n",
       " 1314.0,\n",
       " 1314.0,\n",
       " 1314.0,\n",
       " 1314.0,\n",
       " 1313.0,\n",
       " 1313.0,\n",
       " 1313.0,\n",
       " 1313.0,\n",
       " 1312.0,\n",
       " 1312.0,\n",
       " 1311.0,\n",
       " 1310.0,\n",
       " 1310.0,\n",
       " 1310.0,\n",
       " 1309.0,\n",
       " 1308.0,\n",
       " 1306.0,\n",
       " 1306.0,\n",
       " 1306.0,\n",
       " 1304.0,\n",
       " 1304.0,\n",
       " 1302.0,\n",
       " 1302.0,\n",
       " 1302.0,\n",
       " 1302.0,\n",
       " 1302.0,\n",
       " 1302.0,\n",
       " 1300.0,\n",
       " 1300.0,\n",
       " 1300.0,\n",
       " 1299.0,\n",
       " 1298.0,\n",
       " 1298.0,\n",
       " 1297.0,\n",
       " 1296.0,\n",
       " 1296.0,\n",
       " 1296.0,\n",
       " 1295.0,\n",
       " 1293.0,\n",
       " 1292.0,\n",
       " 1291.0,\n",
       " 1290.0,\n",
       " 1290.0,\n",
       " 1288.0,\n",
       " 1288.0,\n",
       " 1288.0,\n",
       " 1288.0,\n",
       " 1286.0,\n",
       " 1286.0,\n",
       " 1284.0,\n",
       " 1284.0,\n",
       " 1284.0,\n",
       " 1282.0,\n",
       " 1281.0,\n",
       " 1280.0,\n",
       " 1280.0,\n",
       " 1280.0,\n",
       " 1278.0,\n",
       " 1278.0,\n",
       " 1277.0,\n",
       " 1277.0,\n",
       " 1276.0,\n",
       " 1276.0,\n",
       " 1274.0,\n",
       " 1273.0,\n",
       " 1273.0,\n",
       " 1272.0,\n",
       " 1272.0,\n",
       " 1271.0,\n",
       " 1270.0,\n",
       " 1269.0,\n",
       " 1268.0,\n",
       " 1268.0,\n",
       " 1268.0,\n",
       " 1267.0,\n",
       " 1267.0,\n",
       " 1266.0,\n",
       " 1266.0,\n",
       " 1265.0,\n",
       " 1264.0,\n",
       " 1264.0,\n",
       " 1262.0,\n",
       " 1262.0,\n",
       " 1261.0,\n",
       " 1260.0,\n",
       " 1260.0,\n",
       " 1259.0,\n",
       " 1258.0,\n",
       " 1258.0,\n",
       " 1258.0,\n",
       " 1257.0,\n",
       " 1257.0,\n",
       " 1256.0,\n",
       " 1256.0,\n",
       " 1256.0,\n",
       " 1256.0,\n",
       " 1254.0,\n",
       " 1253.0,\n",
       " 1252.0,\n",
       " 1252.0,\n",
       " 1251.0,\n",
       " 1251.0,\n",
       " 1250.0,\n",
       " 1249.0,\n",
       " 1249.0,\n",
       " 1248.0,\n",
       " 1248.0,\n",
       " 1248.0,\n",
       " 1248.0,\n",
       " 1248.0,\n",
       " 1248.0,\n",
       " 1247.0,\n",
       " 1246.0,\n",
       " 1246.0,\n",
       " 1246.0,\n",
       " 1244.0,\n",
       " 1244.0,\n",
       " 1244.0,\n",
       " 1243.0,\n",
       " 1242.0,\n",
       " 1242.0,\n",
       " 1242.0,\n",
       " 1242.0,\n",
       " 1241.0,\n",
       " 1240.0,\n",
       " 1240.0,\n",
       " 1240.0,\n",
       " 1240.0,\n",
       " 1237.0,\n",
       " 1237.0,\n",
       " 1237.0,\n",
       " 1236.0,\n",
       " 1235.0,\n",
       " 1235.0,\n",
       " 1234.0,\n",
       " 1234.0,\n",
       " 1232.0,\n",
       " 1232.0,\n",
       " 1232.0,\n",
       " 1232.0,\n",
       " 1231.0,\n",
       " 1230.0,\n",
       " 1228.0,\n",
       " 1228.0,\n",
       " 1228.0,\n",
       " 1228.0,\n",
       " 1226.0,\n",
       " 1226.0,\n",
       " 1225.0,\n",
       " 1224.0,\n",
       " 1224.0,\n",
       " 1224.0,\n",
       " 1223.0,\n",
       " 1223.0,\n",
       " 1222.0,\n",
       " 1221.0,\n",
       " 1220.0,\n",
       " 1220.0,\n",
       " 1220.0,\n",
       " 1220.0,\n",
       " 1220.0,\n",
       " 1219.0,\n",
       " 1218.0,\n",
       " 1218.0,\n",
       " 1218.0,\n",
       " 1218.0,\n",
       " 1218.0,\n",
       " 1217.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1215.0,\n",
       " 1214.0,\n",
       " 1214.0,\n",
       " 1214.0,\n",
       " 1214.0,\n",
       " 1212.0,\n",
       " 1212.0,\n",
       " 1212.0,\n",
       " 1212.0,\n",
       " 1211.0,\n",
       " 1210.0,\n",
       " 1209.0,\n",
       " 1209.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1208.0,\n",
       " 1206.0,\n",
       " 1205.0,\n",
       " 1204.0,\n",
       " 1204.0,\n",
       " 1204.0,\n",
       " 1204.0,\n",
       " 1203.0,\n",
       " 1202.0,\n",
       " 1202.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1200.0,\n",
       " 1199.0,\n",
       " 1199.0,\n",
       " 1198.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1195.0,\n",
       " 1195.0,\n",
       " 1194.0,\n",
       " 1193.0,\n",
       " 1192.0,\n",
       " 1191.0,\n",
       " 1191.0,\n",
       " 1190.0,\n",
       " 1190.0,\n",
       " 1190.0,\n",
       " 1189.0,\n",
       " 1188.0,\n",
       " 1188.0,\n",
       " 1188.0,\n",
       " 1188.0,\n",
       " 1188.0,\n",
       " 1187.0,\n",
       " 1187.0,\n",
       " 1184.0,\n",
       " 1184.0,\n",
       " 1182.0,\n",
       " 1181.0,\n",
       " 1181.0,\n",
       " 1181.0,\n",
       " 1180.0,\n",
       " 1179.0,\n",
       " 1179.0,\n",
       " 1178.0,\n",
       " 1177.0,\n",
       " 1176.0,\n",
       " 1176.0,\n",
       " 1176.0,\n",
       " 1176.0,\n",
       " 1176.0,\n",
       " 1176.0,\n",
       " 1175.0,\n",
       " 1175.0,\n",
       " 1175.0,\n",
       " 1174.0,\n",
       " 1173.0,\n",
       " 1173.0,\n",
       " 1172.0,\n",
       " 1170.0,\n",
       " 1169.0,\n",
       " 1169.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1168.0,\n",
       " 1166.0,\n",
       " 1165.0,\n",
       " 1165.0,\n",
       " 1165.0,\n",
       " 1164.0,\n",
       " 1164.0,\n",
       " 1164.0,\n",
       " 1163.0,\n",
       " 1162.0,\n",
       " 1162.0,\n",
       " 1161.0,\n",
       " 1160.0,\n",
       " 1160.0,\n",
       " 1160.0,\n",
       " 1160.0,\n",
       " 1158.0,\n",
       " 1158.0,\n",
       " 1158.0,\n",
       " 1158.0,\n",
       " 1158.0,\n",
       " 1158.0,\n",
       " 1157.0,\n",
       " 1156.0,\n",
       " 1156.0,\n",
       " 1154.0,\n",
       " ...]"
      ]
     },
     "execution_count": 1293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['TotalBsmtSF'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TotalBsmtSF'>"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=df['TotalBsmtSF'])\n",
    "# 6110.0 and 5095.0 are the most extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalBsmtSF'] = df['TotalBsmtSF'].replace([6110, 5095], df['TotalBsmtSF'].mean())\n",
    "\n",
    "#removing the outliers by replacing them with the mean value in order to avoid skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TotalBsmtSF'>"
      ]
     },
     "execution_count": 1331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=df['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtQual_2</th>\n",
       "      <th>BsmtQual_3</th>\n",
       "      <th>BsmtQual_4</th>\n",
       "      <th>BsmtQual_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BsmtQual_2  BsmtQual_3  BsmtQual_4  BsmtQual_5\n",
       "0           0           0           1           0\n",
       "1           0           0           1           0\n",
       "2           0           0           1           0\n",
       "3           0           1           0           0\n",
       "4           0           0           1           0"
      ]
     },
     "execution_count": 1316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qual = pd.get_dummies(df['BsmtQual'], drop_first=True, dtype=int, prefix='BsmtQual')\n",
    "df_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating the dummy variables\n",
    "\n",
    "df = pd.concat([df, df_qual], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the original column BsmtQual \n",
    "#we don't need it anymore\n",
    "\n",
    "df = df.drop('BsmtQual', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtCond\n",
       "3    2606\n",
       "4     122\n",
       "2     104\n",
       "0      82\n",
       "1       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtCond'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtCond_1</th>\n",
       "      <th>BsmtCond_2</th>\n",
       "      <th>BsmtCond_3</th>\n",
       "      <th>BsmtCond_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BsmtCond_1  BsmtCond_2  BsmtCond_3  BsmtCond_4\n",
       "0           0           0           1           0\n",
       "1           0           0           1           0\n",
       "2           0           0           1           0\n",
       "3           0           0           0           1\n",
       "4           0           0           1           0"
      ]
     },
     "execution_count": 1307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dummy variables for BsmtCond \n",
    "\n",
    "df_bsmt = pd.get_dummies(df['BsmtCond'], drop_first=True, dtype=int, prefix='BsmtCond')\n",
    "df_bsmt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating the dummy variables\n",
    "\n",
    "df = pd.concat([df, df_bsmt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the original column BsmtCond \n",
    "#we don't need it anymore\n",
    "\n",
    "df = df.drop('BsmtCond', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtHalfBath_2.0    26.972189\n",
       "BsmtCond_1          24.112221\n",
       "BsmtQual_2           5.498419\n",
       "BsmtCond_2           5.012991\n",
       "BsmtCond_4           4.581639\n",
       "BsmtHalfBath         3.933616\n",
       "BsmtHalfBath_1.0     3.761242\n",
       "BsmtQual_5           2.901648\n",
       "SalePrice            1.882876\n",
       "LotFrontage          1.461180\n",
       "ExterCond            1.316590\n",
       "BsmtUnfSF            0.919812\n",
       "2ndFlrSF             0.862118\n",
       "ExterQual            0.786786\n",
       "TotRmsAbvGrd         0.758757\n",
       "Fireplaces           0.733872\n",
       "HalfBath             0.694924\n",
       "BsmtFullBath         0.625153\n",
       "OverallCond          0.570605\n",
       "MasVnrArea           0.537294\n",
       "TotalBsmtSF          0.444158\n",
       "BsmtQual_4           0.348618\n",
       "BedroomAbvGr         0.326492\n",
       "BsmtQual_3           0.243777\n",
       "GarageArea           0.239380\n",
       "OverallQual          0.197212\n",
       "MoSold               0.195985\n",
       "FullBath             0.167692\n",
       "WoodDeckSF           0.158114\n",
       "YrSold               0.132467\n",
       "1stFlrSF             0.064861\n",
       "GrLivArea            0.013194\n",
       "OpenPorchSF         -0.041819\n",
       "GarageCars          -0.219694\n",
       "GarageYrBlt         -0.392992\n",
       "YearRemodAdd        -0.451252\n",
       "LotArea             -0.505010\n",
       "YearBuilt           -0.600114\n",
       "BsmtFinSF1          -0.616949\n",
       "BsmtCond_3          -2.540200\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew(numeric_only=True).sort_values(ascending=False)\n",
    "\n",
    "#BsmtHalfBath_2.0, BsmtCond_1, BsmtQual_2, BsmtCond_2, BsmtCond4 are very skewed\n",
    "#but they are dummies, so we can ignore them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>MeadowV</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Twnhs</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>none</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>MeadowV</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>none</td>\n",
       "      <td>CarPort</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>none</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning LotShape LandContour LotConfig LandSlope  \\\n",
       "2914        160       RM      Reg         Lvl    Inside       Gtl   \n",
       "2915        160       RM      Reg         Lvl    Inside       Gtl   \n",
       "2916         20       RL      Reg         Lvl    Inside       Gtl   \n",
       "2917         85       RL      Reg         Lvl    Inside       Gtl   \n",
       "2918         60       RL      Reg         Lvl    Inside       Mod   \n",
       "\n",
       "     Neighborhood Condition1 Condition2 BldgType  ... KitchenQual Functional  \\\n",
       "2914      MeadowV       Norm       Norm    Twnhs  ...          TA        Typ   \n",
       "2915      MeadowV       Norm       Norm   TwnhsE  ...          TA        Typ   \n",
       "2916      Mitchel       Norm       Norm     1Fam  ...          TA        Typ   \n",
       "2917      Mitchel       Norm       Norm     1Fam  ...          TA        Typ   \n",
       "2918      Mitchel       Norm       Norm     1Fam  ...          TA        Typ   \n",
       "\n",
       "     FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive  \\\n",
       "2914        none         NA           NA         NA         NA          Y   \n",
       "2915        none    CarPort          Unf         TA         TA          Y   \n",
       "2916          TA     Detchd          Unf         TA         TA          Y   \n",
       "2917        none         NA           NA         NA         NA          Y   \n",
       "2918          TA     Attchd          Fin         TA         TA          Y   \n",
       "\n",
       "     SaleType SaleCondition  \n",
       "2914       WD        Normal  \n",
       "2915       WD       Abnorml  \n",
       "2916       WD       Abnorml  \n",
       "2917       WD        Normal  \n",
       "2918       WD        Normal  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj = df.select_dtypes(include=['object'])\n",
    "df_num = df.select_dtypes(exclude=['object'])\n",
    "df_obj.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass_150</th>\n",
       "      <th>MSSubClass_160</th>\n",
       "      <th>MSSubClass_180</th>\n",
       "      <th>MSSubClass_190</th>\n",
       "      <th>MSSubClass_20</th>\n",
       "      <th>MSSubClass_30</th>\n",
       "      <th>MSSubClass_40</th>\n",
       "      <th>MSSubClass_45</th>\n",
       "      <th>MSSubClass_50</th>\n",
       "      <th>MSSubClass_60</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass_150  MSSubClass_160  MSSubClass_180  MSSubClass_190  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   MSSubClass_20  MSSubClass_30  MSSubClass_40  MSSubClass_45  MSSubClass_50  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   MSSubClass_60  ...  SaleType_ConLI  SaleType_ConLw  SaleType_New  \\\n",
       "0              1  ...               0               0             0   \n",
       "1              0  ...               0               0             0   \n",
       "2              1  ...               0               0             0   \n",
       "3              0  ...               0               0             0   \n",
       "4              1  ...               0               0             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0             0            1                      0                     0   \n",
       "1             0            1                      0                     0   \n",
       "2             0            1                      0                     0   \n",
       "3             0            1                      0                     0   \n",
       "4             0            1                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to dummy variables\n",
    "df_obj = pd.get_dummies(df_obj, drop_first=True, dtype=int)\n",
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7.568896</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7.546974</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.533389</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>160.0</td>\n",
       "      <td>9.903538</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.253591</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.823046</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>74.0</td>\n",
       "      <td>9.172431</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.632002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows Ã— 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0            65.0  9.042040            7            5       2003   \n",
       "1            80.0  9.169623            6            8       1976   \n",
       "2            68.0  9.328212            7            5       2001   \n",
       "3            60.0  9.164401            7            5       1915   \n",
       "4            84.0  9.565284            8            5       2000   \n",
       "...           ...       ...          ...          ...        ...   \n",
       "2914         21.0  7.568896            4            7       1970   \n",
       "2915         21.0  7.546974            4            5       1970   \n",
       "2916        160.0  9.903538            5            7       1960   \n",
       "2917         62.0  9.253591            5            5       1992   \n",
       "2918         74.0  9.172431            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  ExterQual  ExterCond  BsmtFinSF1  ...  \\\n",
       "0             2003    5.283204          4          3    6.561031  ...   \n",
       "1             1976    0.000000          3          3    6.886532  ...   \n",
       "2             2002    5.093750          4          3    6.188264  ...   \n",
       "3             1970    0.000000          3          3    5.379897  ...   \n",
       "4             2000    5.860786          4          3    6.486161  ...   \n",
       "...            ...         ...        ...        ...         ...  ...   \n",
       "2914          1970    0.000000          3          3    0.000000  ...   \n",
       "2915          1970    0.000000          3          3    5.533389  ...   \n",
       "2916          1996    0.000000          3          3    7.110696  ...   \n",
       "2917          1992    0.000000          3          3    5.823046  ...   \n",
       "2918          1994    4.553877          3          3    6.632002  ...   \n",
       "\n",
       "      SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                  0               0             0             0            1   \n",
       "1                  0               0             0             0            1   \n",
       "2                  0               0             0             0            1   \n",
       "3                  0               0             0             0            1   \n",
       "4                  0               0             0             0            1   \n",
       "...              ...             ...           ...           ...          ...   \n",
       "2914               0               0             0             0            1   \n",
       "2915               0               0             0             0            1   \n",
       "2916               0               0             0             0            1   \n",
       "2917               0               0             0             0            1   \n",
       "2918               0               0             0             0            1   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "2914                      0                     0                     0   \n",
       "2915                      0                     0                     0   \n",
       "2916                      0                     0                     0   \n",
       "2917                      0                     0                     0   \n",
       "2918                      0                     0                     0   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        1                      0  \n",
       "1                        1                      0  \n",
       "2                        1                      0  \n",
       "3                        0                      0  \n",
       "4                        1                      0  \n",
       "...                    ...                    ...  \n",
       "2914                     1                      0  \n",
       "2915                     0                      0  \n",
       "2916                     0                      0  \n",
       "2917                     1                      0  \n",
       "2918                     1                      0  \n",
       "\n",
       "[2919 rows x 248 columns]"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df_num, df_obj], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITTING PREPROCESSED DATAFRAME INTO X, X_final_test and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df['SalePrice'][:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('SalePrice', axis=1)[:1460]\n",
    "X_final_test = final_df.drop('SalePrice', axis=1)[1460:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITTING df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "# Split data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ElasticNet_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid ={\n",
    "    'alpha': [.0001, .001, .01, .1, 0, 1, 5, 10, 20, 50, 100],\n",
    "    'l1_ratio': [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(param_grid=param_grid, estimator=ElasticNet_model, scoring='neg_mean_squared_error', cv=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 121 candidates, totalling 1210 fits\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.040e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.998e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.328e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.818e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.124e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.674e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.960e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.040e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.960e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.847e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.040e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.868e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.784e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.032e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+09, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.486e+08, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.545e+08, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+09, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.371e+09, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+09, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+09, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+11, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+11, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+11, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+11, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+11, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+11, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+11, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+11, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+11, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.026e+11, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+11, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.136e+11, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.675e+11, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.017e+11, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.790e+11, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e+11, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e+11, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.124e+11, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.939e+11, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e+10, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+10, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.220e+10, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e+10, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.552e+10, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+10, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e+10, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e+10, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.729e+10, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.376e+10, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+12, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+12, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+12, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+12, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+12, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+12, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+12, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+12, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+12, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+12, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.799e+09, tolerance: 5.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+08, tolerance: 5.523e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.075e+09, tolerance: 6.036e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.052e+09, tolerance: 5.689e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+10, tolerance: 5.739e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.541e+08, tolerance: 5.724e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.272e+09, tolerance: 5.616e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.469e+09, tolerance: 5.939e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.940e+09, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e+09, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+12, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+12, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+12, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+12, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+12, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+12, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+12, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+12, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+12, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+12, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.142e+08, tolerance: 5.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e+12, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+12, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+12, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.896e+12, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+12, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+12, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+12, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+12, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+12, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+12, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.422e+12, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+12, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+12, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+12, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+12, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e+12, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e+12, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+12, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+12, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e+12, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+12, tolerance: 5.950e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e+12, tolerance: 5.523e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+12, tolerance: 6.036e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+12, tolerance: 5.689e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e+12, tolerance: 5.739e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+12, tolerance: 5.724e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+12, tolerance: 5.616e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+12, tolerance: 5.939e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+12, tolerance: 5.911e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+12, tolerance: 5.915e+08\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">ElasticNet()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;alpha&#x27;: [0.0001, 0.001, ...], &#x27;l1_ratio&#x27;: [0, 0.1, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: ElasticNet</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>ElasticNet(alpha=1, l1_ratio=0.7)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">precompute&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">selection&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 1450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023587877.648809\n",
      "17842.44175638686\n",
      "31993.559940225612\n",
      "180921.19589041095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "print(mean_absolute_error(y_valid, y_pred))\n",
    "\n",
    "print(root_mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "print(y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH log-transformed y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using log transformation to normalize the data \n",
    "# log1p is the natural logarithm plus 1\n",
    "# used as it is more robust to zero values than log [ln(0) is undefined or -infinity]\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "y_train_log, y_valid_log = np.log1p(y_train), np.log1p(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice skewness(raw): 1.8828757597682129\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXl5JREFUeJzt3Qd8U+X6B/Cnabr3HtBSCkKRPaSAiCgIguJCrwMUFUG94sKJe9wLTvSv4kYcqCheRUQEWbI3lE2l0NIC3XumTXL+n+dNE5PuljYnOef39XPMOknek4Tml3e6SJIkEQAAAIBCaeQuAAAAAEBHQtgBAAAARUPYAQAAAEVD2AEAAABFQ9gBAAAARUPYAQAAAEVD2AEAAABFQ9gBAAAARUPYAQAAAEVD2AGQwejRo8Umh7S0NHJxcaEvv/ySHB2X86WXXurw5/nrr7/Ec/GpGb8/ffr0IbW8JxMnTqQZM2aQI7jlllvoX//6l9zFAAVB2AFogUOHDtGNN95IXbp0IU9PT+rUqRNdccUV9P7779u9LHFxceKL0byFh4fTJZdcQr/88gs5MutyazQaCgwMpL59+9LMmTNp586d7fY83333Hb377rvkiBy1bFu3bqU///yTnnrqKXIEXI7//e9/dODAAbmLAgrhgrWxAJq2bds2uuyyyyg2NpamTZtGkZGRlJGRQTt27KCTJ09SSkpKqx/TXKtjXZPQmtAQFBREjz32mLh87tw5+uSTT+jUqVP00Ucf0X333dfk/fmfvE6nIzc3N3J1dSV7qVvu0tJSOnbsGC1dupSysrLo0Ucfpfnz59vcp6qqirRardha6uqrr6bDhw+L2pKWMhqNVF1dTe7u7iKImd+jvLw88VjtpbGyyfWemF133XVUWVlJq1evJkeRmJhIPXv2pK+//lruooACtPwvCIBK/fe//6WAgADavXu3qI2wlpOTI0uZuGZp6tSplst33HEHde/end55551Gw45erxdf6vyFzrVTjlBu9vrrr9Ntt90myn7BBRfQ/fffb7mto8vJYcoccOR6TRjXdsn1/PwZ/v333+njjz9udt/y8nLy8fGxS7m4GevFF1+kDz/8kHx9fe3ynKBcaMYCaAbX3vTu3bte0GHchGRt0aJFdPnll4vrPTw86MILLxS1LS3Bv+z5jzuHFr5vTEwMPfnkk+L65nBtU69evSg1NdWmD8hbb70lmk26desmHvPo0aON9g85fvy4+IIJCwsjLy8v8av62Weftdnn7NmzdPfdd1NERIR4PH5dvvjiCzof/FzffPMNBQcHi2BpXdlct88O1wY98sgjopaIn59fZ25O3Ldvn6U2hr+4T58+bWky432t++UsWbKEnnvuORG8vL29qaSkpME+O2Z79+6lESNGiHJ27dq1Xijg15HvW7e2pu5jNlW2xt6T9evXiyZKDhj8+bv22mtFbZg1fn34vlzDeOedd4r9OJzfddddVFFR0ezrz2XiIDx27NgGj2vjxo3073//W7zWnTt3FrfxMfB1/Bnh1yUkJIRuuukmm9egqKhI1FK99957luu4poyDJe9v/T5zwOXPsDV+XzlcrVmzptljAGgOanYAmsH9dLZv3y6aH5rrsMrBhgPANddcI5pefvvtN/GlwDUqDzzwQKP349v5Plu2bBF9WDi4cD8hru34+++/admyZU0+b01NjWha4y+RuuGLay/4MTkccKDg56rr4MGD4kuVm1F4X/4S5pDH5ecAwrKzs2nYsGHiC3DWrFkiFP3xxx80ffp0ERg4hLQV/3K//vrraeHChSKQ8WvYEK61+umnn8Tzc5DMz88XrxkHgEGDBolwVlxcTGfOnBGvnfmxrb366quiNufxxx8XQZLPN6awsFB03OUQeOutt9KPP/4ovpj5Phz6WqMlZbO2du1amjBhAsXHx4tAw81M3Efs4osvFuHOHJTMuIwcxubNmydu//zzz0VA4Zqz5ppp+XPDn/OG8OeX3+sXXnhBhA/GtZx8P+5IzAGIQw5/9jnQ8fvHIZJDF/972bRpEz300EPifvxe8eenoKDA5n3evHmz+PxZ4/eXgxT3J+LPBsB54T47ANC4P//8U3J1dRXb8OHDpSeffFJavXq1VF1dXW/fioqKeteNHz9eio+Pt7nu0ksvFZvZN998I2k0Gmnz5s02+3388cf881faunWr5bouXbpI48aNk3Jzc8V24MAB6ZZbbhH7Pfjgg2Kf1NRUcdnf31/KycmxeUzzbYsWLbJcN2rUKMnPz086ffq0zb5Go9Fyfvr06VJUVJSUl5dnsw8/d0BAQIPHbo3LfdVVVzV6+zvvvCPK9euvv1qu48svvvii5TI/zwMPPNDk8/Bz8HPVtWHDBvF4/F7ULav5Nj414/eHr3v77bct1+l0OmnAgAFSeHi45f3n15H349e1ucdsrGwNvSfm58nPz7dcx+81f07uuOMOy3X8+vB97777bpvHvP7666WQkBCpOSNHjpQGDx5c73rzcfHter3e5raG3uvt27eL/b/++mvLdfxeRUREWC7Pnj1bfNb4uD766CNxHR+fi4uL9H//93/1HrNHjx7ShAkTmj0GgOagGQugGVydzjU7XPPCo0PeeOMNGj9+vGgGWb58uc2+/EvUjH/Fc7X9pZdeKjoP8+XGcCddrs1JSEgQ9zFv3CTGNmzYYLM/j5zhX9u89e/fX9z/9ttvr/crfvLkyWKfpuTm5opf31xTwZ2wrfGvcMa5g0fHTJo0SZy3LiO/Fnxs5qaktjLXcnBTVWO4toBHbnGn7LbiTubW71NTuHbu3nvvtVzmGh2+zP1cuHmro2RmZlJSUpJoluLaOLN+/fqJz+PKlSvr3aduXy2uKeGaL651awrvwx3HG8PD0et2mrZ+/bhWkR+Dm1/5/bH+HHAZuEYwOTnZUoMzatQocT2fN9f28Geqbs0O43LxZwzgfCHsALTARRddRD///LNo1ti1axfNmTNHfCnzcHSujjfjKnfu+2DuY8FB45lnnhG3NRV2Tpw4QUeOHLEEGPPWo0ePBjtC80gV7svATR3cnMBfCDxqpe6XODdrNIeDGGuqiY4DEffB+PTTT+uVkfuGNFTG1iorKxOnfn5+je7DQZObE7k/09ChQ0Xzjrn8LdWS18QsOjq6Xodc83vSmtFercV9Yhj3iamLQzG/3+YmJbO6QdUcYPgz25ymBuU29Hpxkxo3a/H7wM2joaGh4rPAnxHrz7k5wHCw4fLu379fXMeBxxx2+NTf31+E9obKZQ7cAOcDfXYAWoF/2XPw4Y2/9PiLnmtVuGMx93EZM2aMqJ3hIdT8RcD7869w7qPRUF8ZM76N55ypO/TajB/LGn+51O1Q2pCW1mA0x1x2HknFNSMN4VqH82Ee4s01BI3hfinmOYW4duvNN98UtVkcRLl/S0u012ti1tiXscFgIHtqbMh6c7OLcH+dpgJRQ6/Xgw8+KPqDcT+t4cOHiw7R/DpwHx7rzzmHRQ5LXHPIfYy4LLw/B6OHH35YhDoOO9wB3Dzk3xqXi0foAZwvhB2ANhoyZIilyYFxZ17u8MpNW9a/sus2QTWER0txExmHJXv/kuUOsKyp+WT4y4lrXPgLvCUhqy21OhxgONRxzUVToqKiRKdZ3rg2iTsmcydqc9hpz9ePm8vqDrfmDuPM3EHYXIPCtRoN1c5Ya2nZzJ2Fzc0/dUfNcdhtryHgHM65ibI1uJM4h963337bch13hK/7GjAOpxx2OPQMGDBAfI64FocD0qpVq0Sz18svv1zvfjxCjDvdc/MxwPlCMxZAMzisNPTr2NxvwtzUYP5lbb0vV+nzL+DmcI0FD+v+7LPPGmwyqNtk0Z44yHCzAg8hT09Pt7nNfCx8bNz/h78UGwpF3MzVVnx83N+IR+jwiKWmakrqNgXyaCOuPbAens8hoKkmw9bgL1yesNGMJx7ky/yaDR482BJUGX+hW5eVm/zqamnZONBxMPjqq69sAgS/9lyjxSPE2gvXtHANSmuaA/nzUPffBI8Ua6g2i8MON/n98MMPlmYtrsXh2hyuyeQ+Pw311+HmYQ5QvB/A+ULNDkAzuMqe5yvh4a/8K5i/8LifDP/x5l/35j4r48aNE81W3ImXO7FybQWHF/5CNtf+NIa/7HlYM3cy5XDFw4v5i4N/xfP1PLOtuSapI/BcKCNHjhS1JDz0nH+F8xcUz8HCHWXZa6+9JsrG/YW40yoPDeaAwr/Mue8Qn28OB7rFixeL8/z68BeaeQZlnlnZujNwXdxHioc5cz8prhngDs38vDwM2rqGgUMIvzezZ88WzY28H78nbcFBipvJ+LXgZkt+XH49OMjwMH3Gw6d5SD734+LXgDsU81w+HJTqak3ZuImOa6s4jPDwfvPQc64Rac/1wq666irREZtfS37vWzoTNM+NxGXhzwF34Of71536gJmDDNdSzZ0713I9B2yeuoD7/PBrURf3SeMh7NwhG+C8NTteC0Dl/vjjDzGsNyEhQfL19ZXc3d2l7t27i2He2dnZNvsuX75c6tevn+Tp6SnFxcVJr7/+uvTFF1/UG5pcd+g546HMvH/v3r0lDw8PKSgoSAwJfvnll6Xi4uIWD+G2Hsr85ptvtmiYMzt8+LAYrhwYGCjK37NnT+n555+32YePl4cTx8TESG5ublJkZKQ0ZswY6dNPP232deRy8/PyxkONeVg8H+uMGTOknTt3Nngf66HnPOz7iSeekPr37y+Gyfv4+IjzH374oc19ysrKpNtuu00cB9/fPNTbPBR86dKl9Z6nsaHnXL49e/aIKQf4NeHH+uCDD+rd/+TJk9LYsWPF+8ZDrZ955hlpzZo19R6zsbI19p6sXbtWuvjiiyUvLy/xek2aNEk6evSozT7moec8DYG1xobEN+Saa64R72ND99+9e3e9/QsLC6W77rpLCg0NFf8meHqF48ePi+OZNm1avf15qDk/lvW/ly1btojrLrnkkgbLlJiYKE2dOrXZsgO0BNbGAgBQOe4kzBMCck2iI3QI5tozrmXkWkNuzgM4Xwg7AAAgmsy4mbChfmP2Zh7VxU24AO0BYQcAAAAUDaOxAAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEwqWDtuj88LTxPY45F5wAAAJwDj7HiCUd5AtCG1lczQ9ipXf+m7kKLAAAA4Bx4HTWeOqExCDtEokbH/GL5+/vLXRwAAABogZKSElFZYf4ebwzCjtVKxBx0EHYAAACcS3NdUNBBGQAAABQNYQcAAAAUDWEHAAAAFA1hBwAAABQNYQcAAAAUDWEHAAAAFA1hBwAAABQNYQcAAAAUDWEHAAAAFA1hBwAAABQNYQcAAAAUDWEHAAAAFA1hBwAAABQNYQcAAAAUDWEHAAAAFE0rdwFAufoOGEhZmZlN7hMZFUWHkvbbrUwAAKA+CDvQYTjoPLN4U5P7zJ06ym7lAQAAdUIzFgAAACgawg4AAAAoGsIOAAAAKJqsYWfTpk00adIkio6OJhcXF1q2bJnN7XxdQ9ubb75p2ScuLq7e7a+99poMRwMAAACOSNawU15eTv3796cFCxY0eHtmZqbN9sUXX4gwM3nyZJv9XnnlFZv9HnzwQTsdAQAAADg6WUdjTZgwQWyNiYyMtLn866+/0mWXXUbx8fE21/v5+dXbFwAAAMCp+uxkZ2fT77//TtOnT693GzdbhYSE0MCBA0UTl16vl6WMAAAA4HicZp6dr776StTg3HDDDTbXP/TQQzRo0CAKDg6mbdu20Zw5c0RT1vz58xt9LJ1OJzazkpKSDi07AAAAyMdpwg7315kyZQp5enraXD979mzL+X79+pG7uzvde++9NG/ePPLw8Gjwsfi2l19+ucPLDAAAAPJzimaszZs3U3JyMt1zzz3N7puYmCiasdLS0hrdh2t/iouLLVtGRkY7lxgAAAAchVPU7CxcuJAGDx4sRm41JykpiTQaDYWHhze6D9f4NFbrAwAAAMoia9gpKyujlJQUy+XU1FQRVrj/TWxsrKU/zdKlS+ntt9+ud//t27fTzp07xQgt7s/Dlx999FGaOnUqBQUF2fVYAAAAwDHJGnb27Nkjgkrd/jfTpk2jL7/8UpxfsmQJSZJEt956a737c+0M3/7SSy+JDsddu3YVYce6Hw8AAACom4vESULluPYoICBA9N/x9/eXuziKERYR2aJVz3Ozs+xWJgAAUN/3t1N0UAYAAABoK4QdAAAAUDSEHQAAAFA0hB0AAABQNIQdAAAAUDSEHQAAAFA0hB0AAABQNIQdAAAAUDSEHQAAAFA0hB0AAABQNIQdAAAAUDSEHQAAAFA0hB0AAABQNK3cBQDn1HfAQMrKzGxyn6KiYruVBwAAoDEIO9AmHHSeWbypyX0en9jXbuUBAABoDJqxAAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDREHYAAABA0RB2AAAAQNEQdgAAAEDRZA07mzZtokmTJlF0dDS5uLjQsmXLbG6/8847xfXW25VXXmmzT0FBAU2ZMoX8/f0pMDCQpk+fTmVlZXY+EgAAAHBUsoad8vJy6t+/Py1YsKDRfTjcZGZmWrbvv//e5nYOOkeOHKE1a9bQihUrRICaOXOmHUoPAAAAzkAr55NPmDBBbE3x8PCgyMjIBm87duwYrVq1inbv3k1DhgwR173//vs0ceJEeuutt0SNEQAAAKibw/fZ+euvvyg8PJx69uxJ999/P+Xn51tu2759u2i6MgcdNnbsWNJoNLRz585GH1On01FJSYnNBh0jv0xHi7am0icbT9L/9p2h3WkFZDBKchcLAABUxKHDDjdhff3117Ru3Tp6/fXXaePGjaImyGAwiNuzsrJEELKm1WopODhY3NaYefPmUUBAgGWLiYnp8GNRI/fI7vTT3jNUUqWnKr2RzhRW0raT+fRXcg5JEgIPAACooBmrObfccovlfN++falfv37UrVs3UdszZsyYNj/unDlzaPbs2ZbLXLODwNO+ckt1FHbTyyLkRPp70iUXhFJWcRVtTsmjw+dKyN/LjS6KC5a7mAAAoAIOHXbqio+Pp9DQUEpJSRFhh/vy5OTk2Oyj1+vFCK3G+vmY+wHxBh1nZ2o+ady9qFOgF13TP5rctRqKDvQijcaFNv6dK2p4Qn3xHgAAgMqbseo6c+aM6LMTFRUlLg8fPpyKiopo7969ln3Wr19PRqOREhMTZSypuhWUV9PJ3HJx/vKEcBF0zAbEBFK/zgHi/JYTeUQuLrKVEwAA1EHWsMPz4SQlJYmNpaamivPp6enitieeeIJ27NhBaWlpot/OtddeS927d6fx48eL/Xv16iX69cyYMYN27dpFW7dupVmzZonmL4zEks/e04XitOLETgr2ca93+4huIeSh1VBBRTVp44fJUEIAAFATWcPOnj17aODAgWJj3I+Gz7/wwgvk6upKBw8epGuuuYZ69OghJgscPHgwbd682aYJ6ttvv6WEhATRrMVDzkeOHEmffvqpjEelbqVVNXQ8yzS6rXT3Lw3u46F1pSFxQeK828BrqVpvtGsZAQBAXWTtszN69OgmR+WsXr262cfgkVffffddO5cM2urAmWLikeXcVycj8+9G9+vfOZD2pxdRhV8Y/bA7nW4fHmfXcgIAgHo4VZ8dcGwcXE9kl1r65jTFzVVDQ2tHY326+RQZMfcOAAB0EIQdaDeFFTViTh1XjQvFBns3u/+F0f4k6Sooo6CStqTk2aWMAACgPgg70G5S80wjsDoHedmMwGqqdkd/cps4/+3O0x1ePgAAUCeEHWg3p/JMq813DfFp8X1qkjeK07XHcii7pKrDygYAAOqFsAPtoqrGQJlFprDSNbTlYUcqOkdDugSJ9bJ+3J3RgSUEAAC1QtiBdpGWX07cxTjEx10sBdEaU4bFitMluzPQURkAANodwg60a3+d1tTqmE3oE0V+nlo6W1RJu9IKOqB0AACgZgg70C5DztPzK8T5uDaEHU83V5rYx7QEyK9J59q9fAAAoG4IO9AuQ855dXMecs4rnLfFNQNMy3v8cTgTMyoDAEC7QtiB85ZVbOqYHOHnIQJPWwyLD6EwPw8qqqihzSdy27mEAACgZgg7cN4yiyvFaVSAV5sfg0PSpH6m2h00ZQEAQHtC2IHzllk7P05kQNuasMyurW3KWnM0m8p1+nYpGwAAAMIOnBfuX5NfVi3OR51n2OnXOYDiQrypssZA64/ntFMJAQBA7RB24Lxk1dbq8NBxHw/teT2Wi4sLXVk7Kmv1kax2KR8AAADCDrRL5+SoNo7Cqmt87whx+ldyLun0hnZ5TAAAUDeEHWiXzsnn21/HrH/nQIrw96AynZ62peS3y2MCAIC6IezAeU0maG7GOp+RWNY0Ghcad2GkOI+mLAAAaA8IO9BmRZU1VFVjmkyQ58hpL+N7R1pGZfECoQAAAOcDYQfaLK9UJ05Dfd3bPJlgQxLjgynAy43yy6tp7+nCdntcAABQJ4QdaLO82iHnob7tV6vD3Fw1NCYhXJxHUxYAAJwvhB1os7wyXYeEHTautilr1eEs0TcIAACgrRB2oM1yLWHHvd0f+9IeYeTppqGzRZV05FxJuz8+AACoB8IOtI2bF5VW6TusZsfL3VUEHvYnmrIAAOA8IOxAm2iCOolTXw8tebq5dshzmEdlrT6S3SGPDwAA6oCwA22iCY7psCYsszEJEaTVuFBydiml5ZV32PMAAICyIexAm2iCO3dYE5ZZgLcbDYsPEecxKgsAANoKYQfaRBNkqtlpz8kEm1or68+jaMoCAIC2QdiBVjMaJUufnY6s2WFjLzSFnX3phVRQbprXBwAAoDUQdqDV0gsqyMXNU8yaHOjl1qHPxWtuJUT6EU+1s/HvnA59LgAAUCaEHWi141mmeW9CfNzFwp0d7fLa2ZTXH8/t8OcCAADlQdiBVkvOKhOnIR04EquhsLMxOYf0BqNdnhMAAJQDYQdaLSXXFHaCfewTdgbGBlGgtxuVVOlpX3qRXZ4TAACUA2EHWu1kTm3Y8bZP2OG+QebZlNcfR78dAABoHW0r9weV45FYp/JMYSfITjU7fQcMpFyvWPK8dCZ9uGwjvX3n6Hr7REZF0aGk/XYpDwAAOBeEHWiVc8WVVFVjJMlQQwGeHTsSyywrM5NmL/qOPt10ijRBnWnW5+vIv85zz506yi5lAQAA54NmLGiVlNomLKkkxy4jscx4/a3IAE9xHktHAABAayDsQKuczDUFDWNxpt2fu2uojzhNRdgBAIBWQNiBVjlZOxLLWGz/tariQkxh50xhJYagAwCAc4SdTZs20aRJkyg6OppcXFxo2bJllttqamroqaeeor59+5KPj4/Y54477qBz587ZPEZcXJy4r/X22muvyXA06hqJZSyyf80Or7Du66ElvVGijMJKuz8/AAA4J1nDTnl5OfXv358WLFhQ77aKigrat28fPf/88+L0559/puTkZLrmmmvq7fvKK69QZmamZXvwwQftdATqbcaSZGjG4iAbF+otzqPfDgAAOMVorAkTJoitIQEBAbRmzRqb6z744AMaOnQopaenU2xsrOV6Pz8/ioyM7PDyqgUP9eYRUPW4e5PPlPfF2cL0v+1fMO63E+JDh8+WUGp+OY2WJBGAAAAAFDP0vLi4WHy5BQYG2lzPzVavvvqqCEC33XYbPfroo6TVNn5oOp1ObGYlJaa1nsCEg84zizfVuz6zuJJ+3HNGNCUZdBWylC0m2FtMMlhapReroId08KrrAADg/Jwm7FRVVYk+PLfeeiv5+/tbrn/ooYdo0KBBFBwcTNu2baM5c+aIpqz58+c3+ljz5s2jl19+2U4lVw4OFyzIxz7z6zTEzVVDnYO86HR+hdgQdgAAQBFhhzsr/+tf/yJJkuijjz6yuW327NmW8/369SN3d3e69957RaDx8Gj4i5ADkfX9uGYnJiamA49AGQorauy6TERjugR7m8JOQQUN6hIka1kAAMDxaZ0l6Jw+fZrWr19vU6vTkMTERNLr9ZSWlkY9e/ZscB8OQY0FIWhcoblmR+awExts6qR8tsg0BF3rihkUAACgcRpnCDonTpygtWvXUkhISLP3SUpKIo1GQ+Hh4XYpo5oUVpibseQNO7zauug3ZJRE4AEAAHDYmp2ysjJKSUmxXE5NTRVhhfvfREVF0Y033iiGna9YsYIMBgNlZZkmsuPbublq+/bttHPnTrrsssvEiCy+zJ2Tp06dSkFBaN5oT0ZJopJKvTgf6CVfnx3GndS5dudoZgmlF1RQl9rJBgEAABwu7OzZs0cEFTNzP5pp06bRSy+9RMuXLxeXBwwYYHO/DRs20OjRo0VT1JIlS8S+PLqqa9euIuxY98eB9sGjnwySJEZC+XnK3/ppHXYAAACaIuu3FgcW7nTcmKZuYzwKa8eOHR1QMqirqLYJi1c6b8+5bYqKiiksIrLZfRrrt5NXVk3lOlONEwAAQEPk/4kOTqGodiRWoHf7NmEZjcYG5/Sx9vjEvvWu83J3pXA/D8op1aF2BwAAmoSwAy1SVNkxYed8dAnxtoSdltQQRUZF0aGk/XYrHwAAOAaEHWhVM1agl7wjsazFBHnT7rRCyiisaFEN0dypo+xWNgAAcBwOPfQcHIcj1uxEBXiKDtPlOgNpgzvJXRwAAHBQCDvQLKORh507XtjhyQQ58DDPmPr9egAAABjCDjSrpKqGjBKJWhSezM+RcFMW84hF2AEAgIYh7EDLm7C82nfYeXuICfYSpx4xfZqdqgAAANQJYQdkG3beHiL8PMndVUOuXn6UW6aTuzgAAOCAEHbAKUdimWk0LtQpyFS7k1GAdbIAAKA+hB1wypFY1jqbw04hJhcEAID6EHbAqZuxrDspnyuqFCPHAAAArCHsQJMMPOy8yhR2AmRe7bwxIb7uZKwqoxqDhH47AABQD8IONKm0qoYkBx12bqZxcSHd2eOW2h0AAABrCDvQpOLKf2p1HG3YuTXd2WPi9CzCDgAA1IGwAy0OO45Md/aoOD1XVIX5dgAAwAbCDigi7FRnnRRNbZU1Biqs7VANAADAEHZAEWGHjHqK8jetk4V+OwAAYA1hB5QRdogoOtA03w767QAAgDWEHWgU931xrrBjqtlB2AEAAGsIO9Ao7v/Cc9cwf0/HHHZuLSrAi3jAWGmVXgyZBwAAYAg70ChzrQ7Pr6N1dfyPirtWQ+F+HuI8ancAAMDM8b/BQDbO1IRVt98OD0EHAABgCDugqLDTCZ2UAQCgDoQdUFTYiQ4whZ2C8mrR5wgAAABhBxQVdrzcXSnYx12cx3w7AADAEHZAUWHHegg6wg4AADCEHWiQ3mCkcp2pGSjA27nCDvrtAACANYQdaLJWh4dze2qd62NiHpGVU6qjar1R7uIAAIDMnOtbDGRpwnLhmfqciL+nG/l5aokXP88qwRB0AAC1Q9gBRfXXqT/fDpqyAADUDmEHlBl2AkydlDOLUbMDAKB2CDugyLDD62SxrOIqMnJ7FgAAqBbCDigy7IT4upObqwtVG4xigkEAAFAvhB1ogAuVVOrFuUAnDTsaFxeKNDdlYZ0sAABVQ9iBelx8AskgSaRxMa147qzMTVmZxeikDACgZm0KO/Hx8ZSfn1/v+qKiInEbODcXv3Bx6ufpRhpOPE7K3En5HDopAwCoWpvCTlpaGhkM9RdZ1Ol0dPbs2fYoF8hI4xfm1E1YZpH+npb+RxXVpmY5AABQn1a1USxfvtxyfvXq1RQQEGC5zOFn3bp1FBcX174lBLtzqQ07/k4edjzcXCnEx53yy6sxBB0AQMVaVbNz3XXXiY1n1J02bZrlMm+33HILrVmzht5+++0WP96mTZto0qRJFB0dLR5z2bJlNrdLkkQvvPACRUVFkZeXF40dO5ZOnDhhs09BQQFNmTKF/P39KTAwkKZPn05lZWWtOSyoQ1PbjOXsNTssCvPtAACoXqvCjtFoFFtsbCzl5ORYLvPGTVjJycl09dVXt/jxysvLqX///rRgwYIGb3/jjTfovffeo48//ph27txJPj4+NH78eKqq+ueLi4POkSNHRNBasWKFCFAzZ85szWFBHS5+oU65AGiTnZQxkzIAgGq1aahNampquzz5hAkTxNYQrtV599136bnnnqNrr71WXPf1119TRESEqAHimqRjx47RqlWraPfu3TRkyBCxz/vvv08TJ06kt956S9QYQdtrdniNKWcXFWiq2cku1RFpXOUuDgAAyKDN44q5fw5v5hoea1988cV5F4wDVVZWlmi6MuM+QomJibR9+3YRdviUm67MQYfx/hqNRtQEXX/99Q0+NtdC8WZWUlJy3uVVCu7M6+Lp69QTClrjpjhPNw1V1RhJExwrd3EAAMBZRmO9/PLLNG7cOBF28vLyqLCw0GZrDxx0GNfkWOPL5tv4NDzcVAthptVqKTg42LJPQ+bNmyeCk3mLiYlplzIrQUZBhTj1dncld63zT8PEfcHMTVma8O5yFwcAAJylZof70Hz55Zd0++23kzOaM2cOzZ4926ZmB4HH5HR+hWJqdaw7KafmlZMrwg4AgCq16ad7dXU1jRgxgjpSZGSkOM3Ozra5ni+bb+NTbkazptfrxQgt8z4N8fDwEKO3rDcwOV1QrriwE22p2ekm+oIBAIC6tCns3HPPPfTdd99RR+ratasILNxUZl0Dw31xhg8fLi7zKc/avHfvXss+69evF32IuG8PtL0ZS0lhJ9zfQyx9ofEJorMYlQUAoDptasbiod+ffvoprV27lvr160dubrZfjPPnz2/R4/B8OCkpKTadkpOSkkSfGx7e/sgjj9B//vMfuuCCC0T4ef7558UIK57Xh/Xq1YuuvPJKmjFjhmhaq6mpoVmzZonOyxiJ1TZKbMZyc9VQmJ8HZZfoaO/pQuoc5C13kQAAwNHDzsGDB2nAgAHi/OHDh+t1CG2pPXv20GWXXWa5bO5HwxMWcp+gJ598UszFw/PmcA3OyJEjxVBzT0/TcGL27bffioAzZswYMQpr8uTJYm4eaBslhh3GnZQ57Ow7XUjXDugkd3EAAMDRw86GDRva5clHjx7dZB8KDk6vvPKK2BrDtUAd3aSmFtV6o2WFcOWFHU9KyiDam94+owUBAMB5OP/YYmg33J/FKBFJNTox9FxJzMtGHMssxaKgAAAq06aaHW56aqq5ijsJg/M5nW8aiSWV5baqOdIZ+Hm6kbEsn8g3hA5kFNPwbiFyFwkAAOykTWHH3F/HjDsGc8di7r/D/W3AuUdiGUtySYmMOSdJ4xtC+9ILEXYAAFSkTWHnnXfeafD6l156CSuOK6BzslSqzLBjyEkhbfxQMSILAADUo1377EydOrVd1sUCeZw21+yU2k7UqBTGHNM0B1yzY+TOSQAAoArtGnZ4YU7rYeHgnM1YSq3ZMRacEYuCFlXU0Kk8U/8kAABQvjY1Y91www02l3n4eGZmppg3hyf+A+fD72G6pWZHmWGHJAP17xxIO1MLxHw73cNNq7sDAICytalmx3rFcN54rhueM2flypX04osvtn8pocPllVVTRbVBLKsgleWRUg3uEiRO0W8HAEA92lSzs2jRovYvCcgqvXYBUJ5puNRoIMWHHUwuCACgGm0KO2a8AOexY8fE+d69e9PAgQPbq1wg00is2GBv+puUa2CsKeyk5JRRUUU1BXq7y10kAABwxLCTk5MjFtv866+/KDAwUFzHa1fxZINLliyhsLCw9i4ndDBzf50uIcpeJDPYx53iw3zoVG457U8vossSwuUuEgAAOGKfnQcffJBKS0vpyJEjVFBQIDaeULCkpIQeeuih9i8ldLh0c82OwsMOG1Rbu4N+OwAA6tCmsMMrj3/44YfUq1cvy3UXXnghLViwgP7444/2LB/YeY4dbsZSOnRSBgBQlzaFHaPRSG5u9VfF5uv4NnDedbHiQnxILWEnKaOI9AZ8XgEAlK5NYefyyy+nhx9+mM6dO2e57uzZs/Too4/SmDFj2rN8YAelVTVi6LlamrG6h/mSn6eWKmsMdDyrVO7iAACAI4adDz74QPTPiYuLo27duomta9eu4rr333+//UsJdhmJFeLjTv6e9WvslEajcUG/HQAAFWnTaKyYmBjat28frV27lo4fPy6u4/47Y8eObe/ygR3DTlyo8puwzLgpa+PfuSLsTBsRJ3dxAADAUWp21q9fLzoicw2Oi4sLXXHFFWJkFm8XXXSRmGtn8+bNHVda6BBptf11lD7s3Bo6KQMAqEerws67775LM2bMIH9//3q38bIR9957L82fP789ywd2kJanns7JZv1jAsXSGGeLKimruEru4gAAgKOEnQMHDtCVV17Z6O3jxo0TsyqDczZjqalmx9dDSwmRptCO2h0AAGVrVdjJzs5ucMi5mVarpdxcha6YrYJmrK4q6rPDhsSZmrJ2pxXIXRQAAHCUsNOpUycxU3JjDh48SFFRUe1RLrCTcp2eckp14nyXYHWFnaFdg8XpzlSEHQAAJWtV2Jk4cSI9//zzVFVVv49DZWUlvfjii3T11Ve3Z/nATk1YQd5uFOCt/GHn1hK7hojT41klYlFQAABQplYNPX/uuefo559/ph49etCsWbOoZ8+e4noefs5LRRgMBnr22Wc7qqzQgTMnd1FR52SzMD8P6hbmQydzy2lXagGN6x0pd5EAAEDusBMREUHbtm2j+++/n+bMmUOSJInreRj6+PHjReDhfcB5pJnn2FFR52Rrw+JDRNjhpiyEHQAAZWr1pIJdunShlStXUmFhIaWkpIjAc8EFF1BQkKmzJzjpsHOVdU42S4wPoW93ptOOU/lyFwUAABxpBmXG4YYnEgRljMRS0xw71obVdlI+mllCxZU1FOClrn5LAABq0Ka1sUA51DjHjrVwf0+KD/UhbpHdjVFZAACKhLCjYpXVBsoqqVJ1zQ5LjDcPQUdTFgCAEiHsqFh6galWh5tugnzcSa24kzLbdhJhBwBAiRB2VCzVsiaWOpuwzEZ0C7X02ykox3w7AABKg7CjYmqeY6fufDsJkX6i387WlDy5iwMAAO0MYUfF1D7HjrWR3U21Owg7AADKg7CjYqjZ+cfFF5jCzuYTeZbJMgEAQBkQdlRM7RMKWkvsGkzurho6W1RpGY4PAADKgLCjUlU1BjpXbB52jmYsb3ctDeoSKM5vRlMWAICitHkGZXBuGbXDzv08tBSskmHnRUXFFBbR+PpXbv2uIvfBN9CWE7l0+7Audi0bAAB0HIQdlXdO7hLqLRZyVQOj0UjPLN7U6O1ZxVX0w54MMd+O3mAkrSsqPgEAlMDh/5rHxcWJL+O62wMPPCBuHz16dL3b7rvvPrmL7Tz9ddA52SLc34OkqlIqrdLT3tOFchcHAADUUrOze/duMhgMlsuHDx+mK664gm666SbLdTNmzKBXXnnFctnbG31QmqP2BUAbonFxIcOZw6TtPpzWJ+eIFdEBAMD5OXzNTlhYGEVGRlq2FStWULdu3ejSSy+1CTfW+/j7+8taZmeg9gVAG6M/c0Ccrj+WI3dRAABALWHHWnV1NS1evJjuvvtum34m3377LYWGhlKfPn1ozpw5VFHR9NBhnU5HJSUlNptqa3Yw7NyG4exhctW40ImcMksnbgAAcG5OFXaWLVtGRUVFdOedd1quu+2220QA2rBhgwg633zzDU2dOrXJx5k3bx4FBARYtpiYGFITnd5A54oqxXnU7NRRXUlDugSJs+uPo3YHAEAJHL7PjrWFCxfShAkTKDo62nLdzJkzLef79u1LUVFRNGbMGDp58qRo7moIh6LZs2dbLnPNjpoCT0ZBJRklIh93Vwrz9ZC7OA5nTK9w2plaQOuO59C0EXFyFwcAANRSs3P69Glau3Yt3XPPPU3ul5iYKE5TUlIa3cfDw0P067He1LhMRGyIj2qGnbfG5Qnh4nTHyXwq1+nlLg4AAKgl7CxatIjCw8PpqquuanK/pKQkcco1PNCwU7mmsBOP/joN6hbmS7HB3lRtMNKmv3PlLg4AAKgh7PBkcBx2pk2bRlrtPy1v3FT16quv0t69eyktLY2WL19Od9xxB40aNYr69esna5kd2am8MnEaH4aw0xCu7bqyj2mm5T8OZ8ldHAAAUEPY4ear9PR0MQrLmru7u7ht3LhxlJCQQI899hhNnjyZfvvtN9nK6gxOmmt2EHYaNaE27Kw7li3WEQMAAOflFB2UOcxIklTveu5UvHHjRlnKpIxmLF+5i+KwBsQEUnSAp1gslZuyxvVufE0tAABwbE5RswPtp6SqhvLKdOI8anaaa8oy9ftCUxYAgHND2FFprU6Ynwf5ebrJXRyHNrGvqTZn7dFsMTcRAAA4J4QdlTmVW9s5GSOxmjUoNogi/D2oVKenrSl5chcHAADaCGFHrf11wtBfpzkajQtNqG3KWp50Tu7iAABAGyHsqHTYeTf012mRaweYZutefSQbEwwCADgphB3V1uwg7LR0VFbXUB+qrDHQKnRUBgBwSgg7KmI0SpSah2HnrR2Vdf3ATuL8z/vPyF0cAABoA4QdFTlbVEk6vZHcXF2oc5CX3MVxGuaws+1kPmUWm1aLBwAA54GwoyKnamt1uoT4kNYVb31LxQR709C4YOJ5LX9FR2UAAKeDbzwVwbDztrt+kKl256e9ZxqczRsAABwXwo6KYNh5213dL4q83FwpJaeMdqcVyl0cAABoBYQdFeEvatY9HGGntXi26Wv6m4ahf78rXe7iAABAKyDsqEhKbTMWwk7b3JYYK05/P5RJheXVchcHAABaCGFHJYoraii31LQAKMJO2/TrHEAXRvlTtd5IP+8/K3dxAACghRB2VCIlt1ScRgV4kq+HVu7iOO2cO+bane92nkZHZQAAJ4FvPZVAf532Wz7iuZ/20slcosiBl5Mx81iD+0VGRdGhpP12Lx8AANSHsKMSCDvt11G55u/N5HbhWEqY8gJdN8A0JL2uuVNH2b1sAADQMDRjqcQJhJ12U3N0rTg9nV9BBeioDADg8BB21Fazgzl2zptUmmtZNX5/OubcAQBwdAg7KlBRrRfrYjHU7LSPgTFB4vRYVilVVhvkLg4AADQBfXYUpO+AgZSVmVnvek1ILHld8yJJVaU0euQwdJxtQlFRMYVFRDa7T3SgJ4X7eVBOqY4OnS2moV2D7VZGAABoHYQdBeGg88ziTfWuP55VQquPZFOnyDA60UAYgn8YjcYGX0Nrj0/sK4ahD4wNFK/rgTNFNKhLIGk1qCgFAHBE+OusAuZOtMHe7nIXRVEuCPcTcxZVVBvo7yxTnygAAHA8CDtqCjs+CDvtyVXjQv1jAsT5/RmFmGQQAMBBIeyoAMJOx+kTHUBajQvllVVTRqGpEzgAADgWhB2F0xuMVFRZI86H+HjIXRzF8XRzpd7R/uL83tMYhg4A4IjQQVnhCitqiFtXPLQa8vFwbfFoI2i5gbFBdPBsMaUXVFB2SRVF+HvKXSQAALCCsKNw+eWmlc5DfN3FCKKWjjaClgvwcqOeEX50PKuUdqcV0NX9ouUuEgAAWEEzlsLll5n666AJq2NdFGeaZ+dkbjnll5kCJgAAOAaEHYXLr+2czDU70HG487d5CYk96LsDAOBQEHYUzlzLEIqaHbvV7iRnl5KLb6jcxQEAgFoIOwpWrTdSSZVenA9GzU6H447JXYK9RYdwt75Xyl0cAACohbCjgvl1fNxdycvNVe7iqKp2R3vBSMopqZK7OAAAgLCjbHm1TVghvmjCspdOQV4UHeBJLq5u9NnmU3IXBwAAEHZU0jkZMyfLUrvz7c50S+0aAADIB2FHBZ2TMRLLvrqEeJMh/7RYIHThFtTuAADIDWFHFcPO0YxlTzx5Y03Sb+L8V9tOU1EFancAAOSEsKNQldUGUbPA0Ixlf4b0/dQryp/KdHpauCVV7uIAAKiaQ4edl156SfxKtt4SEhIst1dVVdEDDzxAISEh5OvrS5MnT6bs7GxZy+wocmubsHgpAzdXh36bFevhMd3F6Zdb06i4wrQYKwAA2J/Dfwv27t2bMjMzLduWLVsstz366KP022+/0dKlS2njxo107tw5uuGGG2Qtr6ONxApFfx3ZjLswkhIi/aiUa3e2onYHAEAuDh92tFotRUZGWrbQUNPMtMXFxbRw4UKaP38+XX755TR48GBatGgRbdu2jXbs2EFql1dqCjth6K8jG43GhR4ac4E4v2hrKhVXonYHAEAODh92Tpw4QdHR0RQfH09Tpkyh9PR0cf3evXuppqaGxo4da9mXm7hiY2Np+/btTT6mTqejkpISm02pzVhhfgg7crqyd6RYEb20Si8CDwAA2J9Dh53ExET68ssvadWqVfTRRx9RamoqXXLJJVRaWkpZWVnk7u5OgYGBNveJiIgQtzVl3rx5FBAQYNliYmJISQxGyTK/SyhqdmSv3Xmwtu/OF1tSqaQKtTsAAPbm0GFnwoQJdNNNN1G/fv1o/PjxtHLlSioqKqIff/zxvB53zpw5ohnMvGVkZJCScNAxSkQeWg35eWrlLo7qTewTRReE+4p1yhZtSZO7OAAAquPQYacursXp0aMHpaSkiP471dXVIvxY49FYfFtTPDw8yN/f32ZTZudkDzGCDeyvqKiYwiIixRYRFUWHfnxLXD9/ZRKFxXQT1/cdMFDuYgIAqIJT/ewvKyujkydP0u233y46JLu5udG6devEkHOWnJws+vQMHz6c1MzSXwdNWLIxGo30zOJNlsuSJNF3u9Ipr4zo0me+oYu7h9LcqaNkLSMAgFo4dM3O448/LoaUp6WliVFW119/Pbm6utKtt94q+tpMnz6dZs+eTRs2bBAdlu+66y4RdIYNG0ZqZh6JFeqHYeeOgmvYhseHiPNJGUVUrtPLXSQAANVw6JqdM2fOiGCTn59PYWFhNHLkSDGsnM+zd955hzQajajZ4RFW3K/nww8/JDXjGoS8MnROdkRdQ30o0t+TskqqaE9aodzFAQBQDYcOO0uWLGnydk9PT1qwYIHYwKRcZ6DKGgNxVx0sE+GAtTvdQuiX/Wfp0NlicvExrY4OAAAqbsaCtvfXCfJ2Jy2WiXA4scHe1DnIiwySRG4DJsldHAAAVcC3ocLkYuZkhzeim6nvjrb7xZSaVy53cQAAFA9hR2FySqvEabg/wo6jigrwEv13XDSu9M6av+UuDgCA4iHsKExObc1OOJaJcGjmkVm/HTxHR84Vy10cAABFQ9hREg9fsQYTw5pYjo3fH/3JHSRJRHNXHhOj6AAAoGMg7CiIa0gXcRro5UYeWle5iwPNqN73M7lrNbQ1JZ82JOfIXRwAAMVC2FEQTW3YQX8d5yCV5dNdF8eJ83NXHie9wSh3kQAAFAlhR0E0obVhx89T7qJAC/17dHcK8najlJwyWrJbWQvSAgA4CoQdJdbsoL+O0wjwcqNHxvYQ53lkVmlVjdxFAgBQHIQdhSgsryaNn2kZDYQd53JbYizFh/lQfnk1ffTXSbmLAwCgOAg7CnG4dvgy1xR4uKFzsjNxc9XQnAm9xPmFW1LpbFGl3EUCAFAUhB2F4LWWGGp1nNPYXuGU2DWYdHojvbHquNzFAQBQFIQdhTiMsOP0i4Q+f/WFYgHXX5PO0c5T+XIXCQBAMRB2FCIpvUicRvhjJJaz6tMpgG4dGivOv7j8CIaiAwC0E4QdBcgpqaJzxVUkSUaEHSf3xLieot/V8axS+m5XutzFAQBQBIQdBdifYarVkYrOiRl5wXkF+bjT4+N7ivNvrU6m/DLTWmcAANB2+GZUgKTasGPIPSV3UaAd3DY0li6M8qeSKj29uTpZ7uIAADg9hB0F9dcx5qbKXRRoB64aF3rl2t7i/A97MixhFgAA2gZhx8kZjBIdPIOaHaUZEhdMNwzqJFZFf/HXw2Q0YlV0AIC2QthxcidySqm82kDe7q4kFZ2VuzjQjp6ekEC+Hlo6cKaYvt+NzsoAAG2lbfM9waGasPp1DqB1XA0ATqOoqJjCIiKb3MfQbRT5j5pGzyzZSY/86wqiqpIG94uMiqJDSfs7qKQAAM4NYcfJmftzDIgJonVyFwZaxWg00jOLNzW5z+NX9afuV82kHCIa9MjndGWfhsPR3KmjOqiUAADOD81Yigk7gXIXBTqCZKTLE8LJhYiSs0vpdH653CUCAHA6CDtOrKSqRnwBsoGxCDtKxRNF9u9sen83JOdiZmUAgFZC2HFi+04XitE6scHemDlZ4YZ1CyYfD1cqrqyh3WmFchcHAMCpIOw4sT21X3oXxQXLXRToYB5aV7q0R5g4v+d0ARWUV8tdJAAAp4Gw48R2pxWI04viguQuCthB9zBfigvxJp5yZ/3xHJIw+g4AoEUQdpxUtd5o6ZzME9CB8rm4uNBlPcNJq3Ghs0WVdCzT1F8LAACahrDjpA6fKyad3kjBPu7ULcxH7uKAnfh7udGw+BBxfnNKLlVWG+QuEgCAw0PYcVK7U01NWEO6BIlf/KAePM1AiK87VdUYaUtKntzFAQBweAg7Tso8Igedk9W5UOiYhHBx/mhmCaUXVMhdJAAAh4aw44R4Uci9p2trdtA5WZWiAryof+cAcX7tsWwiN0w9AADQGIQdJ3Qyt4wKK2rI001DfTqZvvBAfS7uHkoBXm5UWqUn9yE3yV0cAACHhbDjhLadzBenQ7oEk5sr3kK14vd+bC9Tc5ZbwmjacgL9dwAAGoJvSie0tbZT6ojuplE5oF6dg7zFivfsqf8dpDKdXu4iAQA4HIQdJ2MwSrTjlKlmZ0S3ULmLAw7g4m6hZCzNFXPvzFt5TO7iAAA4HIQdJ3PkXDGVVOnJz1NLfdFfB4jIXash3ZZF4vy3O9PRnAUAUAfCjpPZmmKq1eGJ5XgIMgAzZiXT7cO6iPOzf0yi/DKd3EUCAHAYDh125s2bRxdddBH5+flReHg4XXfddZScnGyzz+jRo8WketbbfffdR0q17WRtf51u6K8DtuZMTBCzaeeU6uiJnw5i7SwAAGcIOxs3bqQHHniAduzYQWvWrKGamhoaN24clZeX2+w3Y8YMyszMtGxvvPEGKZFOb7As/snDjgGsebtr6YPbBolmLV4odOGWVLmLBADgELTkwFatWmVz+csvvxQ1PHv37qVRo0ZZrvf29qbIyEhSuv3pRWKJgFBfD7og3Ffu4oAD6hXlT89f1Yue//UIvfbHceodHUDDUQsIACrn0DU7dRUXF4vT4GDbJRK+/fZbCg0NpT59+tCcOXOooqLp6fN1Oh2VlJTYbM5g84lcSxMW1sOCxkwd1oWuGxBNeqNED3y3jzKwnAQAqJxD1+xYMxqN9Mgjj9DFF18sQo3ZbbfdRl26dKHo6Gg6ePAgPfXUU6Jfz88//9xkX6CXX36ZnM3646awM7pnmNxFAQdTVFRMYRFWtZuubuQ58WkqoDga8fTXVLXyNYoMDaJDSfubfJy+AwZSVmZmk/tERkU1+zgAAI7EacIO9905fPgwbdmyxeb6mTNnWs737duXoqKiaMyYMXTy5Enq1q1bg4/FtT+zZ8+2XOaanZiYGHJkWcVVdCyzhLhC59IeCDtQ/8fAM4s32VxXWlVD3+/KoMrgGOox6wv6+71pzT4OB526j1PX3Kn/NCEDADgDp2jGmjVrFq1YsYI2bNhAnTt3bnLfxMREcZqSktLoPh4eHuTv72+zOboNyTnidEBMIIX4eshdHHACfp5uojnL3VUjJhz0GH0f1RiMchcLAMDuHDrs8NBZDjq//PILrV+/nrp27drsfZKSksQp1/AoCY+uYZf3NK2FBNAS4f6eNKl/lJiTSRs7gO77Zi9VVhvkLhYAgF1pHL3pavHixfTdd9+JuXaysrLEVllZKW7npqpXX31VjM5KS0uj5cuX0x133CFGavXr14+UNOTcvB7WZQkIO9D69bOu7htFkr6a1h3PodsX7qTiihq5iwUAYDcOHXY++ugjMQKLJw7kmhrz9sMPP4jb3d3dae3atWLunYSEBHrsscdo8uTJ9Ntvv5GS7EotoIpqA4X7eVDvaMdvcgPHExfqQ1Wr3xbLjOw5XUiTPthCh8+aRjcCACidQ3dQbm4GWO5UzBMPKp25CeuynuEYcg5tZsxJoaX3Dad7vtpD6QUVdMNH28ScPFMSu5AGS48AgII5dM0OmALfn0eyxfnLe6EJC85PQqQ//f7gJTQmIZyq9UYx+eAtn+2gk7llchcNAKDDIOw4uKSMIjGSxsfdFUPOoV0EeLvRZ3cMoReuvpC83FxFM+mEdzfTf38/SuTuLXfxAADaHcKOg1t5yDTB2+W9IsjTzVXu4oBCcLPV3SO70p+PjhIhutpgpM82p5L35HkiYBuMWEQUAJQDYcfBm7BWHsoS56/qq/y1v8D+YoK96cu7LqJFd10k1ltz8fSljX/n0uIdpyklpwwrpwOAIiDsOLADZ4pFE5a3uyuNxvw60EG40zt3fv/j4UtIt+1r0bRVVFlDvx/KpP/tO0vZJVVyFxEA4Lwg7Diw3w+eE6dj0IQFdqB11ZA+eSPdOSKOLooLEhMRcthesjuDVh3JopIqzM0DAM7JoYeeq5nRiCYskIe7VkMjuoVS304BtP1kPh3LKqXkrFLRrDWiWwjXBcldRACAVkHNjoPakZovflX7eWjRhAWyra01rnck3XpRDHUK9BKdljefyCPPCU9SRkGF3MUDAGgxhB0H9ePuDHE6aUA0mrBA9vW1Jg/qRJcnhJObqwu5Rvagq97bTH8eMdU8AgA4OoQdB1RcWUN/HDZ9kdw8JEbu4gCITszcrDU1sQsZck5SSZWeZn6zl+atPIZh6gDg8BB2HNDyA+dIpzdSzwg/6tc5QO7iAFj4e7lR1vfPUs3h1eLyJ5tOUZep/6WwTl0oLCLSsvUdMFDuogIAWKCDsgNausfUhHXTkM5YCwscjlFfTY8/PEt0Wl5zLJsodiBF3b+QJvWPEv182Nypo+QuJgCABWp2HMyRc8V08Eyx6Btx/cBOchcHoFE9I/1EXx6elye3TEc/7M6gLMzJAwAOCGHHwSzckipOx/eOpBBfD7mLA9CkqAAvuuWiGArxcafyagP9tPcMncgplbtYAAA2EHYcSFZxFS1PMk0kOOOSeLmLA9Difjzc5BoX4i06K/P8UNre47DUBAA4DIQdB/LltjTSGyUaGhdM/WMC5S4OQIt5aF1pUr9oS4d6j6E303PLDpPeYJS7aAAA6KDsKMp0evpu52lxfsao+rU6PLolK9O0AnpjioqKO6x84Pz488EjpZrb53xWUh/dI4wCvNxo09859O3OdDEx5ge3DSJfD/ypAQD54C+Qg1iyK13MXRIf6kNjEurPmMxB55nFm5p8jMcn9u3AEoKzMxqNHf4Z4tGDg2KDaM3HL1HglQ/RX8m5dMOHW+njqYMpPsz3vB4bAKCt0IzlAEqraujDv06K8zNHxYtfyADOzJC+n36YOZzC/Dzo7+wyuvaDrbQaMy4DgEwQdhzAZ5tTqaC8muLDfOjGwZ3lLg5Au+B+Z78/OFKsoF6q09O93+ylOT8fFE22AAD2hGYsmeWW6ui91YeJtB509Ic3KeqNWxrcD/1xwGn7B7m4ktvgG8itzzj6flcGfbtuH1Xv+I5CDbl0OGl/k4/Tkr5qkVFRdKiZxwEAdUPYkdl7606IoBPh70E3/2d+ozMmoz8OOHv/oDOFFfTn0WwqpTDyvOJhKj57hA5kFDU58rAlfdUwWzMANAfNWDJKyiiixbUjsC7uFoqlIUDROgd505TEWBrcJYhcXVzItVNvunbBVvrXx9vptwPnqBzNWwDQQVCzI5Mag5Ge/t9B4nnX9CnbKWbMHXIXCcAu8/GM7B5KfaL96fNvvievHhfTrrQCsXloNeK2IXHBNDA2kLph9BYAtBOEHZl8uukUHc8qpSBvNzqzawnRvQg7oB6B3u5UvXkh7V34PC3ecZp+O3iOTudX0LrjOWIz857yPn2z4zR5u7uSj7uWvD1qT91dTdd5aKlEJzU7fxD69QCoG8KODA6dKab/W3tCnH/+6gvp3gVlchcJQBaRAZ70+Pie9Ni4HnQ0s4S2n8ynvacLxWK454oridy9xUjFgvLGHyPqvi/IXasR63OF+npQVICn2DhQmaFfD4C6IezYWXFFDf37u71UbTDS2F4RYmXze+UuFIDMuL9a7+gAsd1ziem6qhoDxfYeQlNfXUTl1XqqqDZQhc5gOS9OdQaqrDFQtd5ImcVVYjt01jRykWdy7hrqIzbSuMp7gAAgK4QdO+KFER9beoAyCiopJtiL3r6pPzolAzTC082VpOJMign2bnK/xycNpKe/30H5ZdWUU2oKPNklVVRcWSMGAfDmfdt79MB3++jqvlE0umc4ebkj/ACoCcKOHb32x3FaeyxbVLl/NGUwBXi7yV0kAOdn0IvmK956RvqJq3R6g/hRkZpXTmn55VRBnvT7wUyxcV8frlW9ql8UXdojTIQqAFA2hB07+XjjSfpk0ylxfu71falPJ9Pq0ADQMaO+uof7io1rVF9/9E565M0vaMXBTLE46fID58TGC5SO7RVOV/WLplE9QsX9AEB5EHbs4KttaaJWhz07sReWhACwI24qNual0pyJvejpCQl04EwxrThwjlYeyqRzxVW0LOmc2Pw8tHRF7wi6ul8UjeweJmpgAUAZEHY6EP+ifPvPv+mDDSni8v2ju9GMUfFyFwtA1cFnQEyg2J6Z2Iv2ZxSJpi0OPlklVfTzvrNi83F3pcT4EBrRLYQu7h5KPSP8sEAvgBND2OkgeoORnv3lMP2wJ0Ncrt63jN5a9Bu91cC+WPcKwI5rdTXIhUJ7DaWbZ88VwSenVEfrj+eIjYX6utOg2CCxtAUHpb6dA8jfE33uAJwFwk4HKa820N70QpKMRhpzYST1HfMEEfFWH9a9ArD/Wl118Vw8L13Tm164+kIx58+2k3m0NSWfdqUWUF5ZtVjXizez+FAfSojyo4RIf9ExulekP3UO8kINEIADQtjpIDzHx1d3D6XBY6+jvle8L3dxAJywtsW+tZ6NlkfjSprQrqQJiycpMIbcoy4gjV8YncorF9vKQ1mWXaWaKqrJTyeX4kwyFp4hY+FZMhZlElWV2DwkZnQGsC+EnQ7UKdCLDBkH5C4GgNPWttiz1rOl5Xlr5SGqqNZTbqlO1Pjkl5lOeaZng5snuUf2IOLNCq/7FeTtTkE+bhTs7U7rPn2JTuaWUWywN7m5oiM0QEdD2AEAaCVvdy11CeHNx3KdwShRUUU1vfv8wzRh1n8sQaikSk86vVF0gOaNeY55kMa8vZG0GheKDfGmmCBvMdEorwzPTWExtafBPu6YeBSgHSgm7CxYsIDefPNNysrKov79+9P7779PQ4cOlbtYAKASrhoXCvH1oMrkrTSiW6jNYIWiyhoq5DW+KqqpsLyGjh45RL5R3cRSF6dyy8XWEC83VxF6eIsM8KJIf9O6XxEBnuI8ry3m76lFIAJQQ9j54YcfaPbs2fTxxx9TYmIivfvuuzR+/HhKTk6m8PBwuYsHACqmddVYZng2W//0eAoMDCQXn0By8Y8kjW8IufiGksYvVJyK8z5BIgydyCkTW2M4EEVahZ8IPvX3EOEozM9DLJAa7Osu5hGyZyjiqTe4/LyOmd4gWa4fM24c5eb8s7K9ZNATGWqIDNV8J7v3aeo7YCBlZWY2uQ/6WDn/a6iIsDN//nyaMWMG3XXXXeIyh57ff/+dvvjiC3r66aflLh4AQAP9gzY2uc/cOy6nXYeS6UxhBZ0prKSs2jW/zGt/cZNYUUWNCBS8LAZvTXF31Zj6DPl4ULCPm5g9mpvjeLkMXkKDQxOvGcaXeUAZ5w7JqnaKn4e3qmrTaWWNkSrF+X8Waa2o0YvrxOVqQ8MFuewpamy1M35erUZDxaWFNPL19aIsnm4a8tSaysbHwH2ctK4uplONC7lpNeSmcRGhkq/jLlAu/J8Ln4rJlUynprM2t/FpftggGvvAjH/2sfyvdl8iWvv1fPo1iedf0pKvp1a8dj4eplPeuIxKr12TasNrmU5P5bwgr05fe15PuV6xNOm1T6nGaDR9biSJjLX34VeQ39f1338omnkDvd1lKb/Th53q6mrau3cvzZkzx3KdRqOhsWPH0vbt22UtGwBAWxUV5NPQ3t2a3KdMV0N+oZ3IxZtriYJI4x0kTsVlPu/lT+ThRxp3T6o2GCm7RCc2e+NQYlajryFX13++eoz/VPqI81xOjXeACHj24D74Btp+Mr/JfTxG3EEPL0lqsgmTA6OPu5a8PWpP3V1NgZKDkTsHSi25aV3ITVMnrImQZgprfFlTG5rM2clyWpvA6mYqc8gyX22UJNF/jDc+r+dTY+11EgdtPjVd5r5kldWmsGoKroY65023lVXpqbxab/NeWfO8dCatT85p+jUcerPoxI+w00Z5eXlkMBgoIiLC5nq+fPy4aYmGunQ6ndjMiotNw1tLSmyHh7bXL7iq8saroKk2/WIf7NPWfRyxTNjn/Pfhv2uzP1nZ5D7P3jiMXvjyy2b3efmHbVSh/6dWpqrGQDUGI+kNplqbrb//QHfePb32Nv5NblvL4eriQj//9AMNvnyS5cuav+BNX9rmL3ANLX3jMVr56/9ELQzXFPEXPJ9azz3UtVt3evyzVTavBX8h6/nUYBRfwgtfuJ9+XraMdDVG8YWs43LpDeKyeb+X/zOXRt04w/LlzV/ExtovePG4RJS04TeaOnVK7fOYrjPdLJlbzGjJjz9Sn5FXmktj9Sb9s/+xvVvp4lGXmWozOABwjUZt7RXfzq9YcSWRGqaHdXHhDvoc6FxF7ZaPu5YO7N1N3foMFJ8HDmui5qy2Rs30Gkp0ZNt6ouqhVFLyz+erPZi/t/k5miQ5ubNnz4rXctu2bTbXP/HEE9LQoUMbvM+LL74o7oMNGzZs2LBhI6ffMjIymswKTl+zExoaSq6urpSd/c/MpowvR0Y2PGEZN3lxh2azoqIi6tKlC6Wnp1NAgLpWI+dUHBMTQxkZGeTv709qotZjV+txq/nY1XrcDMeu7GPnGp3S0lKKjo5ucj+nDzvu7u40ePBgWrduHV133XWWpiO+PGvWrAbv4+HhIba6OOgo9QPRHD5uHLu6qPW41Xzsaj1uhmP3J6VqSSWF04cdxrU006ZNoyFDhoi5dXjoeXl5uWV0FgAAAKiXIsLOzTffTLm5ufTCCy+ISQUHDBhAq1atqtdpGQAAANRHEWGHcZNVY81WzeEmrRdffLHBpi2lw7Gr79jVetxqPna1HjfDsavz2Oty4V7KchcCAAAAoKNguV0AAABQNIQdAAAAUDSEHQAAAFA0hB0AAABQNIQdIlqwYAHFxcWRp6cnJSYm0q5du8hRbNq0iSZNmiRmh+S1RpYtW2ZzO/cv5yH3UVFR5OXlJRZAPXHihM0+BQUFNGXKFDGpVGBgIE2fPp3KymzX5Tl48CBdcskl4jXgGTffeOONemVZunQpJSQkiH369u1LK1eubHVZWmrevHl00UUXkZ+fH4WHh4sJI5OTk232qaqqogceeIBCQkLI19eXJk+eXG8mbZ4V+6qrriJvb2/xOE888QTp9Xqbff766y8aNGiQGLHQvXt3+rKBtYaa+4y0pCwt9dFHH1G/fv0sE4ENHz6c/vjjD8Ufd12vvfaa+Mw/8sgjij/2l156ybSWkNXG/9aUftxmZ8+epalTp4rH5L8d/Pdlz549iv87x69z3fedN3591fC+25WkckuWLJHc3d2lL774Qjpy5Ig0Y8YMKTAwUMrOzpYcwcqVK6Vnn31W+vnnn8X6H7/88ovN7a+99poUEBAgLVu2TDpw4IB0zTXXSF27dpUqKyst+1x55ZVS//79pR07dkibN2+WunfvLt16662W24uLi6WIiAhpypQp0uHDh6Xvv/9e8vLykj755BPLPlu3bpVcXV2lN954Qzp69Kj03HPPSW5ubtKhQ4daVZaWGj9+vLRo0SJRnqSkJGnixIlSbGysVFZWZtnnvvvuk2JiYqR169ZJe/bskYYNGyaNGDHCcrter5f69OkjjR07Vtq/f794LUNDQ6U5c+ZY9jl16pTk7e0tzZ49WxzX+++/L45z1apVrfqMNFeW1li+fLn0+++/S3///beUnJwsPfPMM+K15tdCycdtbdeuXVJcXJzUr18/6eGHH27x8znrsfN6fb1795YyMzMtW25uruKPmxUUFEhdunSR7rzzTmnnzp2inKtXr5ZSUlIU/3cuJyfH5j1fs2aN+Du/YcMGxb/v9qb6sMOLhT7wwAOWywaDQYqOjpbmzZsnOZq6YcdoNEqRkZHSm2++abmuqKhI8vDwEP+QGX+4+X67d++27PPHH39ILi4uYhFV9uGHH0pBQUGSTqez7PPUU09JPXv2tFz+17/+JV111VU25UlMTJTuvffeFpflfPAfBT6OjRs3Wh6b/wgtXbrUss+xY8fEPtu3bxeX+R++RqORsrKyLPt89NFHkr+/v+VYn3zySfElY+3mm28WYauln5GWlOV88fvz+eefq+K4S0tLpQsuuED84b/00kstYUfJx85hh7+oG6Lk4zb/rRk5cmSjt6vp7xx/1rt16yaeR+nvu72puhmrurqa9u7dK6ohzTQajbi8fft2cnSpqalixmjr8vMaIVwFaS4/n3KVLi+lYcb783Hu3LnTss+oUaPEOmNm48ePF81GhYWFln2sn8e8j/l5WlKW81FcXCxOg4ODxSm/bzU1NTbPx1XPsbGxNsfO1dDWM2lzmXlxvCNHjrTouFryGWlJWdrKYDDQkiVLxPIn3JylhuPmqnKulq9bPqUfOzeFcHN1fHy8aI7h5gk1HPfy5cvF36ebbrpJNMMMHDiQPvvsM9X9nePXf/HixXT33XeLpiylv+/2puqwk5eXJ75M6i4rwZf5A+3ozGVsqvx8yn9ArGm1WhEarPdp6DGsn6Oxfaxvb64sbcULu3K/jYsvvpj69OljeT7+o8V/4JoqU1uPi/9YVFZWtugz0pKytNahQ4dEuzi3sd933330yy+/0IUXXqj44+Zgt2/fPtFnqy4lHzt/WXI/Cl7mhvts8Zcq9y3h1ZyVfNzs1KlT4pgvuOACWr16Nd1///300EMP0VdffaWqv3PcH7OoqIjuvPNOy3Mp+X23N8UsFwHKxb/0Dx8+TFu2bCG16NmzJyUlJYkarZ9++kksdLtx40ZSsoyMDHr44YdpzZo1opOkmkyYMMFynjunc/jp0qUL/fjjj6ITrJLxjxmukZk7d664zDU7/O/9448/Fp97tVi4cKH4HHDtHrQ/VdfshIaGkqura70e5Xw5MjKSHJ25jE2Vn09zcnJsbuee+jxywXqfhh7D+jka28f69ubK0ha83tmKFStow4YN1LlzZ5tj5+pX/iXUVJnaelw8ooO/ZFryGWlJWVqLf0XxqInBgweLWo7+/fvT//3f/yn6uLmqnD+rPGqEf5XzxgHvvffeE+f5V6RSj70u/gXdo0cPSklJUfR7znhUE9daWuvVq5elGU8Nf+dOnz5Na9eupXvuucdyndLfd3tTddjhLxT+Mlm3bp3Nrwy+zP0jHF3Xrl3FB826/Fw1yW3U5vLzKX9A+YvEbP369eI4+dejeR8e4s5tsmb865prF4KCgiz7WD+PeR/z87SkLK3B/bE56HDzDZeXH98av29ubm42z8dt7/wH0vrYuTnI+o8gl5n/kZv/uDZ3XC35jLSkLOeLn1On0yn6uMeMGSPKzTVa5o1/8XP/FfN5pR57XTxk+uTJkyIIKPk9Z9w8XXdaib///lvUbCn975zZokWLRDMc91UzU/r7bneSyvGQO+5J/+WXX4oe/TNnzhRD7qx7t8uJR6bwkELe+O2aP3++OH/69GnLMEgu76+//iodPHhQuvbaaxsckjlw4EAxrHPLli1ipIv1kEzuac9DMm+//XYxJJNfEx6qWHdIplarld566y3RC59HjzQ0JLO5srTU/fffL4Z3/vXXXzZDMysqKmyGQvJw9PXr14uhkMOHDxdb3WGZ48aNE8PXeahlWFhYg8Myn3jiCXFcCxYsaHBYZnOfkebK0hpPP/20GHWWmpoqXke+zKNK/vzzT0Ufd0OsR2Mp+dgfe+wx8Vnn95z/rfFQYh5CzKMQlXzc5mkG+G/Lf//7X+nEiRPSt99+K8q5ePFiyz5K/TtnHvnEryePDKtLye+7vak+7DCed4DfRJ5ngIfg8TwNjoLnW+CQU3ebNm2auJ2HKD7//PPiHzF/WMeMGSPmZrGWn58v/tH7+vqKIYl33XWXCFHWeL4IHv7Jj9GpUyfxD7quH3/8UerRo4d4nXgoI88FY60lZWmpho6ZN557x4z/uPz73/8Ww0n5H/P1118vApG1tLQ0acKECWI+Df7y4C+Vmpqaeq/xgAEDxHHFx8fbPEdLPyMtKUtL3X333WLeEX4u/sPFr6M56Cj5uFsSdpR67DwUOCoqSjwX//vjy9bzzCj1uM1+++038aXNfzcSEhKkTz/91OZ2pf6dYzynEP9ta+gxlP6+25ML/8/+9UkAAAAA9qHqPjsAAACgfAg7AAAAoGgIOwAAAKBoCDsAAACgaAg7AAAAoGgIOwAAAKBoCDsAAACgaAg7AOA0eGXwuisvd4S0tDRycXERy1QAgPND2AEAu8nNzaX777+fYmNjycPDQ6wzNH78eNq6dWuHPWdcXJwILrz5+PiIhUaXLl3a5H1iYmIoMzOT+vTp02HlAgD7QdgBALuZPHky7d+/n7766iux2OPy5ctp9OjRlJ+f36HP+8orr4jwws990UUX0c0330zbtm1rcF9e3ZlXgeYgxqutA4DzQ9gBALvgVak3b95Mr7/+Ol122WViVeuhQ4fSnDlz6JprrhH7zJ8/n/r27StqYLh25d///rdYAbwpv/76q6it8fT0pPj4eHr55ZdJr9fb7OPn5yfCS48ePWjBggXk5eVFv/32m6Xm59VXX6U77rhDrBY9c+bMBpuxjhw5QldffbXYhx/vkksuESuTm33++efUq1cvUY6EhAT68MMP2/kVBIC2QtgBALvw9fUV27Jly0in0zW4j0ajoffee08EC679Wb9+PT355JONPiaHJw4pDz/8MB09epQ++eQT0a/nv//9b6P34doaNzc3UYNj9tZbb1H//v1Fzc/zzz9f7z5nz56lUaNGiaY3LtPevXvp7rvvtoSqb7/9ll544QXxvMeOHaO5c+eKx+FjAAAHYNdlRwFA1X766SexarKnp6c0YsQIac6cOWIl6sYsXbpUCgkJsVzm1ZoDAgIsl3nF6blz59rc55tvvhEriJvxCvLvvPOOOK/T6cT+/KdvxYoVltuvu+46m8dITU0V++zfv19c5nJ27dpVqq6ubrCc3bp1k7777jub61599VVp+PDhLXpdAKBjYdVzALCrqqoqUSOzY8cO+uOPP2jXrl2iCejOO++ktWvX0rx58+j48eNUUlIiak54//LycvL29ha1No888ohoEmNhYWGimYv72JgZDAab+3AzFffX4docvp5rl7jp7KmnnhL78+0zZsygZ5991vIY3IzVtWtXUdMzYMAAmjhxoniuhmpq+Hn4MblpjGumzLjsAQEBlJ2d3cGvKAA0B73vAMCuuE/LFVdcITZu6rnnnnvoxRdfFB2VuU8Mj9bi5qDg4GDasmULTZ8+XTQ5cXCpi4MO99G54YYbGnwesyeeeEKEKQ4lERERoj+ONe4j1BQOMo0x9yn67LPPKDEx0eY26xAGAPJB2AEAWV144YWiHw/3gzEajfT2229bakh+/PHHJu/LHZOTk5Ope/fuTe4XGhra7D5N6devn6jVqampETVE1jg8RUdH06lTp2jKlCltfg4A6DgIOwBgFzy8/KabbhIdezk88IimPXv20BtvvEHXXnutCCMcJt5//32aNGmSmHvn448/bvIxuVMw1wbxvD033nijCEkHDhygw4cP03/+8592K/usWbNEuW655RbRBMbNU9wMx6PJevbsKWqXHnroIXH9lVdeKTpg87EVFhbS7Nmz260cANA2GI0FAHbBTUjczPPOO++IkU08YR83Y3F/mQ8++ECMhuKh5zw0nW/jEU7cf6cpPCHhihUr6M8//xTz5wwbNkw8Pg9rb08hISFiFBY3WV166aU0ePBg0WxlruXhpjjud7Ro0SIxdJ734f5F3O8HAOSHDsoAAACgaKjZAQAAAEVD2AEAAABFQ9gBAAAARUPYAQAAAEVD2AEAAABFQ9gBAAAARUPYAQAAAEVD2AEAAABFQ9gBAAAARUPYAQAAAEVD2AEAAABFQ9gBAAAAUrL/B7ZDNhZCmdgaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins=50, kde=True)\n",
    "plt.title('SalePrice Distribution (raw)')\n",
    "\n",
    "print(F\"SalePrice skewness(raw): {df['SalePrice'].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#already Log-transformed target\n",
    "\n",
    "sns.histplot(y_log, bins=50, kde=True)\n",
    "\n",
    "plt.title('SalePrice Distribution (log1p transformed)')\n",
    "plt.xlabel('log1p(SalePrice)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 121 candidates, totalling 1210 fits\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.887e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.688e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.615e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.409e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.839e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e-02, tolerance: 1.459e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e-02, tolerance: 1.404e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e-02, tolerance: 1.460e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e-01, tolerance: 1.378e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e-02, tolerance: 1.436e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.783e-02, tolerance: 1.445e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e-02, tolerance: 1.438e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.544e-01, tolerance: 1.431e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.015e-02, tolerance: 1.441e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e-02, tolerance: 1.459e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.788e-02, tolerance: 1.460e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e-01, tolerance: 1.431e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e-02, tolerance: 1.460e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 1.431e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e-02, tolerance: 1.460e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e-02, tolerance: 1.431e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.918e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.604e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.869e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.788e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.400e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.152e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.951e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.029e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.628e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.433e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.275e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.097e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.875e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.186e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.363e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.299e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.894e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e+00, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+00, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+00, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.405e+00, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.663e+00, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+00, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e+00, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e+00, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.366e+00, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.517e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.380e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.355e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.423e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.389e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.426e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.417e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.381e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.540e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.468e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.304e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.439e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.483e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.488e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.460e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.454e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.577e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.787e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.674e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.673e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.720e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.709e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.696e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.422e+01, tolerance: 1.459e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e+01, tolerance: 1.404e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.436e+01, tolerance: 1.460e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.296e+01, tolerance: 1.424e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.086e+01, tolerance: 1.378e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.316e+01, tolerance: 1.436e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.364e+01, tolerance: 1.445e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.344e+01, tolerance: 1.438e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.312e+01, tolerance: 1.431e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.343e+01, tolerance: 1.441e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">ElasticNet()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;alpha&#x27;: [0.0001, 0.001, ...], &#x27;l1_ratio&#x27;: [0, 0.1, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: ElasticNet</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>ElasticNet(alpha=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">precompute&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">selection&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 1437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.019914312603960607\n",
      "MAE:  0.08626002107829255\n",
      "RMSE:  0.14111808035811926\n",
      "Mean:  12.024057394918406\n"
     ]
    }
   ],
   "source": [
    "print('MSE: ', mean_squared_error(y_valid_log, y_pred))\n",
    "\n",
    "print('MAE: ', mean_absolute_error(y_valid_log, y_pred))\n",
    "\n",
    "print('RMSE: ', root_mean_squared_error(y_valid_log, y_pred))\n",
    "\n",
    "print('Mean: ', y_log.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE FINAL STEPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform the data using the scaler \n",
    "# both \n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_final_test = scaler.transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 121 candidates, totalling 1210 fits\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.512e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.778e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.686e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.011e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.178e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.222e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.541e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.766e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.389e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 2.119e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e-01, tolerance: 2.100e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e+00, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 2.063e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+00, tolerance: 2.027e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.896e+00, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+00, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+00, tolerance: 2.123e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+00, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+00, tolerance: 2.091e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e-01, tolerance: 2.119e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e-02, tolerance: 2.100e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.108e-01, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.1s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.504e-01, tolerance: 2.063e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.044e-01, tolerance: 2.027e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.526e-01, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e-01, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.176e-01, tolerance: 2.123e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.292e-01, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.478e-01, tolerance: 2.091e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.694e-01, tolerance: 2.119e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e-02, tolerance: 2.100e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e-01, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.593e-01, tolerance: 2.063e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.470e-01, tolerance: 2.027e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e-01, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.042e-01, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.167e-01, tolerance: 2.123e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.323e-01, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-01, tolerance: 2.091e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e-01, tolerance: 2.119e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-01, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e-01, tolerance: 2.063e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e-01, tolerance: 2.027e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.428e-02, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.175e-02, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e-02, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.596e-02, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e-02, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e-02, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e-02, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .........................alpha=0.0001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.0001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.644e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.886e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.810e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.137e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.306e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.341e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.848e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.513e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.103e-02, tolerance: 2.119e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e-02, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e-02, tolerance: 2.063e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.207e-02, tolerance: 2.027e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e-01, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.682e-02, tolerance: 2.106e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e-02, tolerance: 2.123e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.285e-02, tolerance: 2.118e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.1s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e-02, tolerance: 2.091e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e-02, tolerance: 2.065e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e-02, tolerance: 2.139e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..........................alpha=0.001, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.001, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.341e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.555e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.506e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.837e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.1s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.050e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.317e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.495e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.322e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.01, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=0.01, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.584e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.859e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.753e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.095e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.336e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.482e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.551e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.781e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.252e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.507e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.1s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.494e+00, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.765e+00, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.670e+00, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e+00, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+00, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.207e+00, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e+00, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+00, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.754e+00, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\base.py:1365: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+00, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=1, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.735e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.645e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.700e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.150e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.122e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.968e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.160e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.080e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.091e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=10, l1_ratio=0; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.634e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.502e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.429e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.706e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.608e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.688e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.620e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.601e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=0; total time=   0.1s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=20, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=20, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.457e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.390e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.273e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.509e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.382e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.467e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.351e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=0; total time=   0.1s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.375e+01, tolerance: 2.119e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.297e+01, tolerance: 2.100e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e+01, tolerance: 2.065e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.131e+01, tolerance: 2.063e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.983e+01, tolerance: 2.027e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.446e+01, tolerance: 2.139e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.303e+01, tolerance: 2.106e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.389e+01, tolerance: 2.123e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.347e+01, tolerance: 2.118e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "d:\\PYTHON DATA SCIENCE\\Stepik Course\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.255e+01, tolerance: 2.091e-02\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ..............................alpha=100, l1_ratio=0; total time=   0.1s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.2; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.4; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.6; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.8; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">ElasticNet()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;alpha&#x27;: [0.0001, 0.001, ...], &#x27;l1_ratio&#x27;: [0, 0.1, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: ElasticNet</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>ElasticNet(alpha=0.01, l1_ratio=0.4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">0.4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">precompute&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">selection&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 0, 1, 5, 10, 20,\n",
       "                                   50, 100],\n",
       "                         'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 1466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet_model = ElasticNet(alpha=0.01, l1_ratio=0.4)\n",
    "\n",
    "final_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = final_model.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112991.63190833, 157311.78610199, 183438.72521983, ...,\n",
       "       167781.82890069, 121097.29114555, 224194.49072188], shape=(1459,))"
      ]
     },
     "execution_count": 1485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponential transformation to get the original values of SalePrice\n",
    "\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>112991.631908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>157311.786102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>183438.725220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>196003.387094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>199566.689375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  112991.631908\n",
       "1  1462  157311.786102\n",
       "2  1463  183438.725220\n",
       "3  1464  196003.387094\n",
       "4  1465  199566.689375"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = pd.DataFrame({\"Id\": range(1461, 2920), \"SalePrice\": y_pred})\n",
    "predicted_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
